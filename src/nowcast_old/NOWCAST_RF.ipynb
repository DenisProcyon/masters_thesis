{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd35f235",
   "metadata": {},
   "source": [
    "# Random Forest Regression for Multidimensional Poverty Estimation\n",
    "\n",
    "This notebook implements a full modeling pipeline for nowcasting multidimensional poverty indicators using Random Forest Regression. The goal is to predict CONEVAL’s official poverty statistics for each Mexican state, using text-derived indicators from various sources (YouTube, Telegram, Google Trends, and News).\n",
    "\n",
    "## Data Integration\n",
    "\n",
    "Six sources of text-based indicators are integrated across two years (2020 and 2022):\n",
    "\n",
    "- **Google Trends**: Search volume patterns for poverty-related keywords\n",
    "- **YouTube Comments**: Sentiment score and share of comments about each dimension of poverty \n",
    "- **Telegram Posts**: Share of posts about each dimension of poverty \n",
    "- **News Outlets**: LDA topic modeling of media coverage\n",
    "- **Official Statistics**: CONEVAL poverty measurements (ground truth)\n",
    "\n",
    "**Geographic Scope**: All 32 Mexican states.  \n",
    "**Temporal Scope**: Two reference years — 2020 (training) and 2022 (validation).\n",
    "\n",
    "\n",
    "## Methodology: Random Forest Regression\n",
    "\n",
    "Random Forest is particularly well suited for this task because:\n",
    "\n",
    "- It captures **nonlinear relationships** and **interactions** between predictors.\n",
    "- It is robust to **multicollinearity** and **feature noise**, which is crucial given the diversity of data sources.\n",
    "- It performs **implicit feature selection** through node-splitting and feature sampling.\n",
    "- It handles **small datasets with high-dimensional input** well (p > n scenarios), making it appropriate for this 32-observation, 37-feature setup.\n",
    "\n",
    "\n",
    "## Feature Engineering and Model Training\n",
    "\n",
    "- All numeric indicators (except the targets, `state` and `year`) are used as features.\n",
    "- No feature scaling is applied, as Random Forest is scale-invariant.\n",
    "- A separate model is trained for each poverty dimension.\n",
    "\n",
    "We implemented two training-validation strategies:\n",
    "\n",
    "1. **In-Sample Setting**: Model trained on both 2020 and 2022 data, validated on 2022.\n",
    "2. **Out-of-Sample Setting**: Model trained only on 2020, validated on 2022.\n",
    "\n",
    "## Hyperparameter Selection\n",
    "\n",
    "### Fixed Parameters (Final Configuration)\n",
    "\n",
    "After extensive testing, the following hyperparameters were selected and fixed across all models:\n",
    "\n",
    "- `n_estimators = 100`: A good balance between variance reduction and computational cost.\n",
    "- `max_depth = 4`: Limits overfitting while allowing enough complexity.\n",
    "- `min_samples_leaf = 2`: Prevents overly specific splits, which are risky with small datasets.\n",
    "\n",
    "This configuration was initially chosen based on its strong and consistent performance in predicting 2022 values. It showed better generalization and robustness than any parameter combination obtained through automated tuning.\n",
    "\n",
    "\n",
    "### Why We Avoided Full Hyperparameter Tuning\n",
    "\n",
    "We experimented with both **GridSearchCV** and **RandomizedSearchCV** using **Leave-One-Out Cross-Validation (LOOCV)**. However, the results obtained through automatic tuning were systematically **worse than the fixed configuration**. This outcome can be explained by several factors:\n",
    "\n",
    "- **High variance of LOOCV**: Leave-One-Out Cross-Validation evaluates the model on a single observation at a time. Although this method maximizes the training data per fold, it also makes the validation highly sensitive to individual outliers or noisy samples. A single unusual observation can disproportionately influence the model selection process, leading to unstable or misleading validation results.\n",
    "\n",
    "- **Instability of the optimization process**: With only 32 observations available, the metric used for tuning (such as cross-validated R² or MSE) becomes highly unstable. Small variations in the data or the model's structure can lead to significant fluctuations in performance estimates. As a result, the search process may favor hyperparameters that appear optimal due to noise rather than true predictive power, resulting in poor generalization on unseen data.\n",
    "\n",
    "- **Underfitting caused by conservative tuning**: The tuning procedure tends to prefer simpler models to avoid overfitting in cross-validation. In practice, this led to the selection of configurations with overly shallow trees or high minimum leaf sizes. These choices limited the model’s ability to capture relevant structure in the data, resulting in underfitting and worse predictive accuracy on the 2022 validation set. Given the relative stability of poverty indicators over time, more expressive models are required to leverage the available signal effectively.\n",
    "\n",
    "\n",
    "Thus, **manual tuning based on validation performance on 2022**, combined with domain knowledge and empirical results, provided a more stable and generalizable solution.\n",
    "\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "Each model was evaluated on 2022 using:\n",
    "\n",
    "- **R-squared (R²)**: Measures explained variance.\n",
    "- **Mean Absolute Error (MAE)**: Captures average prediction error.\n",
    "\n",
    "Results are stored in:\n",
    "- `results.csv`: contains actual vs predicted values for each state and dimension.\n",
    "- `metrics.csv`: includes model performance and the list of important features (with importances).\n",
    "- Scatter plots: for each poverty dimension, we visualize predicted vs actual values and overlay the perfect prediction line.\n",
    "\n",
    "\n",
    "## Generalizability to Future Years\n",
    "\n",
    "The chosen parameter configuration (`n_estimators=100`, `max_depth=4`, `min_samples_leaf=2`) is simple, stable, and empirically effective. It is robust across poverty dimensions and expected to generalize well in repeated analyses across different years because:\n",
    "\n",
    "- It is **not tailored to 2022** but performs well on it.\n",
    "- It avoids overfitting through conservative tree growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df03cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e113ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "tg_2020 = pd.read_csv('clean_data/tg_2020.csv')\n",
    "tg_2022 = pd.read_csv('clean_data/tg_2022.csv')\n",
    "gt_2020 = pd.read_csv('clean_data/gt_2020.csv')\n",
    "gt_2022 = pd.read_csv('clean_data/gt_2022.csv')\n",
    "yt_2020 = pd.read_csv('clean_data/yt_2020.csv')\n",
    "yt_2022 = pd.read_csv('clean_data/yt_2022.csv')\n",
    "news_2020 = pd.read_csv('clean_data/news_2020.csv')\n",
    "news_2022 = pd.read_csv('clean_data/news_2022.csv')\n",
    "off_2020 = pd.read_csv('clean_data/off_2020.csv')\n",
    "off_2022 = pd.read_csv('clean_data/off_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were inconsistencies in the state names, so this mapping standardizes the state names across all datasets\n",
    "state_name_map = {\n",
    "    \"México\": \"Estado de México\",\n",
    "    \"Mexico\": \"Estado de México\",\n",
    "    \"Estados Unidos Mexicanos\": \"Estado de México\",\n",
    "    \"Michoacán de Ocampo\": \"Michoacán\",\n",
    "    \"Veracruz de Ignacio de la Llave\": \"Veracruz\",\n",
    "    \"Coahuila de Zaragoza\": \"Coahuila\",\n",
    "    \"Yucatan\": \"Yucatán\",\n",
    "    \"Queretaro\": \"Querétaro\",\n",
    "    \"San Luis Potosi\": \"San Luis Potosí\",\n",
    "    \"Nuevo Leon\": \"Nuevo León\",\n",
    "    \"Michoacan\": \"Michoacán\",\n",
    "    \"Michoacán de Ocampo\": \"Michoacán\"}\n",
    "\n",
    "# aplply the mapping\n",
    "for df in [off_2020, off_2022, gt_2020, gt_2022, yt_2020, yt_2022, tg_2020, tg_2022, news_2020, news_2022]:\n",
    "    df['state'] = df['state'].astype(str).str.strip()\n",
    "    df['state'] = df['state'].replace(state_name_map)\n",
    "    df['state'] = df['state'].replace(\"nan\", None)  \n",
    "\n",
    "# 'state' columns as strings in all dataframes\n",
    "for df in [off_2020, off_2022, gt_2020, gt_2022, yt_2020, yt_2022, tg_2020, tg_2022, news_2020, news_2022]:\n",
    "    df['state'] = df['state'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b6adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 64\n"
     ]
    }
   ],
   "source": [
    "# create dataset for 2020\n",
    "data_2020 = off_2020.copy()\n",
    "data_2020['year'] = 2020\n",
    "\n",
    "# merge Google Trends\n",
    "data_2020 = data_2020.merge(gt_2020, on='state', how='inner')\n",
    "\n",
    "# merge YouTube\n",
    "data_2020 = data_2020.merge(yt_2020, on='state', how='inner')\n",
    "\n",
    "# merge Telegram\n",
    "data_2020 = data_2020.merge(tg_2020, on='state', how='inner')\n",
    "\n",
    "# merge News (=LDA topics)\n",
    "data_2020 = data_2020.merge(news_2020, on='state', how='inner')\n",
    "\n",
    "\n",
    "# create dataset for 2022\n",
    "data_2022 = off_2022.copy()\n",
    "data_2022['year'] = 2022\n",
    "\n",
    "# merge Google Trends\n",
    "data_2022 = data_2022.merge(gt_2022, on='state', how='inner')\n",
    "\n",
    "# merge YouTube\n",
    "data_2022 = data_2022.merge(yt_2022, on='state', how='inner')\n",
    "\n",
    "# merge Telegram\n",
    "data_2022 = data_2022.merge(tg_2022, on='state', how='inner')\n",
    "\n",
    "# merge News (=LDA topics)\n",
    "data_2022 = data_2022.merge(news_2022, on='state', how='inner')\n",
    "\n",
    "# combine datasets for 2020 and 2022\n",
    "combined_data = pd.concat([data_2020, data_2022], ignore_index=True)\n",
    "\n",
    "# check that we have all the states in both years (32 states * 2 years = 64 observations)\n",
    "print(f\"Number of observations: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cc4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map poverty dimensions to target columns\n",
    "POVERTY_DIMENSIONS = {\n",
    "    'income': 'income_target',\n",
    "    'health': 'health_target',\n",
    "    'education': 'educ_target',\n",
    "    'social_security': 'social_target',\n",
    "    'housing': 'housing_target',\n",
    "    'food': 'food_target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4379940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features to use \n",
    "def get_all_feature_columns(data, target_columns, exclude_cols=['state', 'year']):\n",
    "    return [col for col in data.columns if col not in target_columns + exclude_cols and data[col].dtype in [np.float64, np.int64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e802ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train on all data (2020+2022) \n",
    "def train_all_data(data, dimension, target_col):\n",
    "    all_targets = list(POVERTY_DIMENSIONS.values())\n",
    "    feature_cols = get_all_feature_columns(data, all_targets)\n",
    "\n",
    "    X = data[feature_cols].values\n",
    "    y = data[target_col].values\n",
    "\n",
    "    mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))\n",
    "    X, y = X[mask], y[mask]\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=4, min_samples_leaf=2, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    return {\n",
    "        'dimension': dimension,\n",
    "        'model': rf,\n",
    "        'feature_cols': feature_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45da8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to validate on 2022\n",
    "def validate_2022(data, rf_results):\n",
    "    data_2022 = data[data['year'] == 2022].copy()\n",
    "    results = {}\n",
    "\n",
    "    for dim, res in rf_results.items():\n",
    "        print(f\"\\n--- {dim.upper()} ---\")\n",
    "        model = res['model']\n",
    "        features = res['feature_cols']\n",
    "        target = POVERTY_DIMENSIONS.get(dim)\n",
    "\n",
    "        if target not in data_2022.columns:\n",
    "            continue\n",
    "\n",
    "        X_test = data_2022[features].values\n",
    "        y_test = data_2022[target].values\n",
    "\n",
    "        mask = ~(np.isnan(X_test).any(axis=1) | np.isnan(y_test))\n",
    "        X_test, y_test = X_test[mask], y_test[mask]\n",
    "        states = data_2022['state'].values[mask]\n",
    "\n",
    "        if len(X_test) == 0:\n",
    "            continue\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        print(f\"R² = {r2:.3f}, MAE = {mae:.3f}\")\n",
    "\n",
    "        results[dim] = {\n",
    "            'states': states,\n",
    "            'y_true': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'r2': r2,\n",
    "            'mae': mae}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd945041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all results \n",
    "def save_rf_results(results_dict, models_dict, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # 1. save predictions (results.csv)\n",
    "    preds = {'state': next(iter(results_dict.values()))['states']}\n",
    "    for dim, res in results_dict.items():\n",
    "        preds[f'{dim}_actual'] = res['y_true']\n",
    "        preds[f'{dim}_predicted'] = res['y_pred']\n",
    "    pd.DataFrame(preds).to_csv(f\"{folder_name}/results.csv\", index=False)\n",
    "\n",
    "    # 2. save metrics (metrics.csv)\n",
    "    rows = []\n",
    "    for dim, res in results_dict.items():\n",
    "        model = models_dict[dim]['model']\n",
    "        features_used = models_dict[dim]['feature_cols']\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        important_features = [\n",
    "            (f, round(imp, 4)) for f, imp in zip(features_used, importances) if imp > 0]\n",
    "\n",
    "        num_used = len(important_features)\n",
    "\n",
    "        rows.append({\n",
    "            'dimension': dim,\n",
    "            'r2': res['r2'],\n",
    "            'mae': res['mae'],\n",
    "            'n_features_used': num_used,\n",
    "            'important_features': sorted(important_features, key=lambda x: -x[1])})\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(f\"{folder_name}/metrics.csv\", index=False)\n",
    "\n",
    "    # 3. scatter plot for each dimension\n",
    "    for dim, res in results_dict.items():\n",
    "        y_true = res['y_true']\n",
    "        y_pred = res['y_pred']\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.scatter(\n",
    "            y_true, y_pred,\n",
    "            color='royalblue',\n",
    "            edgecolor='black',\n",
    "            s=250,  \n",
    "            alpha=0.9)\n",
    "\n",
    "        min_val = min(min(y_true), min(y_pred))\n",
    "        max_val = max(max(y_true), max(y_pred))\n",
    "        plt.plot(\n",
    "            [min_val, max_val], [min_val, max_val],\n",
    "            'r--', linewidth=3, label='Perfect prediction')\n",
    "\n",
    "        plt.xlabel(\"CONEVAL's statistics\", fontsize=24, fontweight='bold')\n",
    "        plt.ylabel(\"Predicted Values\", fontsize=24, fontweight='bold')\n",
    "        plt.title(f\"{dim.replace('_', ' ').title()}\\n$R^2$ = {res['r2']:.3f}\", fontsize=28, fontweight='bold')\n",
    "\n",
    "        plt.xticks(fontsize=20, fontweight='bold')\n",
    "        plt.yticks(fontsize=20, fontweight='bold')\n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{folder_name}/{dim}_plot.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1b5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== In-Sample Validation) ===\n",
      "\n",
      "--- INCOME ---\n",
      "R² = 0.873, MAE = 3.742\n",
      "\n",
      "--- HEALTH ---\n",
      "R² = 0.841, MAE = 4.024\n",
      "\n",
      "--- EDUCATION ---\n",
      "R² = 0.888, MAE = 1.283\n",
      "\n",
      "--- SOCIAL_SECURITY ---\n",
      "R² = 0.890, MAE = 3.870\n",
      "\n",
      "--- HOUSING ---\n",
      "R² = 0.952, MAE = 1.701\n",
      "\n",
      "--- FOOD ---\n",
      "R² = 0.866, MAE = 1.666\n"
     ]
    }
   ],
   "source": [
    "rf_all_results = {}\n",
    "for dim, target in POVERTY_DIMENSIONS.items():\n",
    "    if target in combined_data.columns:\n",
    "        result = train_all_data(combined_data, dim, target)\n",
    "        if result:\n",
    "            rf_all_results[dim] = result\n",
    "\n",
    "print(\"\\n=== In-Sample Validation) ===\")\n",
    "validation_rf_all = validate_2022(combined_data, rf_all_results)\n",
    "\n",
    "save_rf_results(validation_rf_all, rf_all_results, \"rf_in_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a26824be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train on 2020 only\n",
    "def train_2020(data, dimension, target_col):\n",
    "    train_data = data[data['year'] == 2020].copy()\n",
    "    all_targets = list(POVERTY_DIMENSIONS.values())\n",
    "    feature_cols = get_all_feature_columns(train_data, all_targets)\n",
    "\n",
    "    X_train = train_data[feature_cols].values\n",
    "    y_train = train_data[target_col].values\n",
    "\n",
    "    mask = ~(np.isnan(X_train).any(axis=1) | np.isnan(y_train))\n",
    "    X_train, y_train = X_train[mask], y_train[mask]\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=4, min_samples_leaf=2, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    return {\n",
    "        'dimension': dimension,\n",
    "        'model': rf,\n",
    "        'feature_cols': feature_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d28bf54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Out-Of-Sample Validation) ===\n",
      "\n",
      "--- INCOME ---\n",
      "R² = 0.225, MAE = 9.838\n",
      "\n",
      "--- HEALTH ---\n",
      "R² = -0.602, MAE = 11.767\n",
      "\n",
      "--- EDUCATION ---\n",
      "R² = 0.116, MAE = 3.850\n",
      "\n",
      "--- SOCIAL_SECURITY ---\n",
      "R² = 0.360, MAE = 9.500\n",
      "\n",
      "--- HOUSING ---\n",
      "R² = 0.585, MAE = 5.410\n",
      "\n",
      "--- FOOD ---\n",
      "R² = 0.145, MAE = 4.558\n"
     ]
    }
   ],
   "source": [
    "rf_2020_results = {}\n",
    "for dim, target in POVERTY_DIMENSIONS.items():\n",
    "    if target in combined_data.columns:\n",
    "        result = train_2020(combined_data, dim, target)\n",
    "        if result:\n",
    "            rf_2020_results[dim] = result\n",
    "\n",
    "print(\"\\n=== Out-Of-Sample Validation) ===\")\n",
    "validation_rf_2020 = validate_2022(combined_data, rf_2020_results)\n",
    "\n",
    "save_rf_results(validation_rf_2020, rf_2020_results, \"rf_out_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afaa52b",
   "metadata": {},
   "source": [
    "# Construction of the *Social Cohesion* Index (2022) using PCA\n",
    "\n",
    "Since we do not have a direct target variable to measure social cohesion, we apply an **unsupervised method** based on **Principal Component Analysis (PCA)** to extract a latent index that summarizes the information from a set of proxy variables.\n",
    "\n",
    "## Data Selection and Preprocessing\n",
    "\n",
    "We select all variables in the dataset whose names contain the word `\"cohesion\"`. These are the components we previously constructed from different textual data sources (YouTube, Telegram, News, Google Trends) to capture aspects of social cohesion. Each of these variables reflects a proxy derived from textual analysis, so these are not raw inputs but already-processed indicators explicitly built to inform the social cohesion dimension. \n",
    "\n",
    "To ensure comparability across variables and to satisfy PCA assumptions, we standardize the selected features using `StandardScaler`, which centers them around zero and rescales them to unit variance.\n",
    "\n",
    "## PCA: Extracting the Latent Dimension\n",
    "\n",
    "We perform a PCA and retain only the **first principal component (PC1)**. This component captures the direction of maximum variance in the standardized feature space. Since all selected features aim to reflect some aspect of social cohesion, PC1 can be interpreted as a **latent index** summarizing the shared signal across them.\n",
    "\n",
    "We chose this approach because:\n",
    "\n",
    "- By reducing dimensionality, we capture the dominant underlying pattern in a single score.\n",
    "- Since we don't have a target for this dimension, our possibilities were limited but we still believe this approach allows to define weights in a robust and non-arbitrary way\n",
    "- Reflects the empirical correlation structure of the data, which is appropriate in the absence of a predefined ground truth.\n",
    "\n",
    "## Handle the Sign\n",
    "\n",
    "One limitation of PCA is that the sign of the components is not uniquely identified — multiplying all loadings and scores by -1 yields an equivalent solution.\n",
    "\n",
    "To ensure consistency in interpretation (i.e., **higher scores mean worse social cohesion**), we compute the **sum of the loadings** for the first component:\n",
    "- If the sum is **negative**, it means that high raw scores are associated with **better** social cohesion. In this case, we **invert the sign** of the PCA scores so that higher values reflect **higher deprivation**.\n",
    "- If the sum is **positive**, we keep the scores as they are.\n",
    "\n",
    "This correction guarantees that a value of 100 consistently means \"lowest social cohesion\" — in line with the interpretation of other poverty indicators.\n",
    "\n",
    "## Normalization to a 0–100 Scale\n",
    "\n",
    "After sign correction, the scores are normalized to a 0–100 scale using `MinMaxScaler`. This is aligned with the conventions adopted by CONEVAL and our other dimensional estimates, which express deprivation as a **percentage of the population** affected.\n",
    "\n",
    "The resulting index can thus be interpreted as a relative measure of social cohesion deprivation, comparable across Mexican states.\n",
    "\n",
    "## Observed Anomalies: 5 States with Extreme Values\n",
    "\n",
    "In the final normalized scores, we observe the presence of unrealistic values:\n",
    "- One state receives a score of exactly **0**.\n",
    "- Four states have scores **above 80**, with one state reaching exactly **100**.\n",
    "\n",
    "While these results are not computationally incorrect, they may appear questionable — especially given that we do not observe such extreme values in any of the other dimensions. However, several technical factors can explain this behavior:\n",
    "\n",
    "- **Outliers in the original features**: some states may exhibit near-zero values across multiple cohesion-related components, particularly in cases where textual data coverage was sparse or unbalanced. This can drive their PCA score toward the lower bound of the distribution.\n",
    "\n",
    "- **High-leverage observations**: PCA is inherently sensitive to atypical combinations of feature values. A single state with an unusual profile — even if not extreme in any single component — can strongly influence the orientation of the principal component and receive a disproportionately high or low score.\n",
    "\n",
    "- **Scaling effects**: the use of `MinMaxScaler` maps the minimum and maximum PCA scores to 0 and 100 by design. As a result, there will always be at least one state assigned **0** and one assigned **100**, regardless of how realistic those values are in substantive terms.\n",
    "\n",
    "Ultimately, these extreme scores should be interpreted as **relative positions**: they indicate how a state ranks within the empirical distribution of social cohesion *as captured by the PCA*, rather than representing absolute levels of deprivation. A score of 100 does not imply that 100% of the population experiences cohesion poverty — it simply reflects that the state ranks at the very bottom in relative terms.\n",
    "\n",
    "To avoid producing exact 0 and 100 values, one option would have been to restrict the output range during normalization, for example:\n",
    "\n",
    "```python\n",
    "scaler_pct = MinMaxScaler(feature_range=(5, 80))\n",
    "````\n",
    "\n",
    "However, we opted not to implement this adjustment, for two main reasons:\n",
    "\n",
    "- The choice of an alternative range would have been arbitrary and thus methodologically debatable;\n",
    "- Compressing the score range would have reduced the spread of the values, limiting the model's ability to differentiate between intermediate cases.\n",
    "\n",
    "We therefore retained the full [0, 100] scale, acknowledging that the extremes reflect model mechanics as much as underlying variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4da9c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA loadings (PC1):\n",
      "cohesion_gt: -0.382\n",
      "social_cohesion_avg_sentiment: -0.373\n",
      "social_cohesion_pct_yt: 0.619\n",
      "social_cohesion_pct_tg: 0.576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>social_cohesion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2022</td>\n",
       "      <td>34.618119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baja California</td>\n",
       "      <td>2022</td>\n",
       "      <td>88.612437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baja California Sur</td>\n",
       "      <td>2022</td>\n",
       "      <td>43.232871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Campeche</td>\n",
       "      <td>2022</td>\n",
       "      <td>16.569366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coahuila</td>\n",
       "      <td>2022</td>\n",
       "      <td>41.210944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colima</td>\n",
       "      <td>2022</td>\n",
       "      <td>31.376835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chiapas</td>\n",
       "      <td>2022</td>\n",
       "      <td>92.302337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>2022</td>\n",
       "      <td>24.930064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>2022</td>\n",
       "      <td>24.701380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Durango</td>\n",
       "      <td>2022</td>\n",
       "      <td>36.179750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 state  year  social_cohesion_score\n",
       "0       Aguascalientes  2022              34.618119\n",
       "1      Baja California  2022              88.612437\n",
       "2  Baja California Sur  2022              43.232871\n",
       "3             Campeche  2022              16.569366\n",
       "4             Coahuila  2022              41.210944\n",
       "5               Colima  2022              31.376835\n",
       "6              Chiapas  2022              92.302337\n",
       "7            Chihuahua  2022              24.930064\n",
       "8     Ciudad de México  2022              24.701380\n",
       "9              Durango  2022              36.179750"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select social cohesion features\n",
    "social_features = [col for col in data_2022.columns if 'cohesion' in col.lower()]\n",
    "X_social_2022 = data_2022[social_features].dropna()\n",
    "\n",
    "# standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_2022 = scaler.fit_transform(X_social_2022)\n",
    "\n",
    "# PCA to extract the first component\n",
    "pca = PCA(n_components=1)\n",
    "social_cohesion_score_2022 = pca.fit_transform(X_scaled_2022)\n",
    "\n",
    "# get and print loadings \n",
    "loadings = dict(zip(social_features, pca.components_[0]))\n",
    "print(\"PCA loadings (PC1):\")\n",
    "for feature, weight in loadings.items():\n",
    "    print(f\"{feature}: {weight:.3f}\")\n",
    "\n",
    "# invert the sign of the PCA scores if necessary\n",
    "# (this is to ensure that a higher score indicates worse cohesion)\n",
    "# (if the sum of loadings is negative, invert the sign to have: 100 = worst cohesion)\n",
    "if np.sum(pca.components_[0]) < 0:\n",
    "    print(\" inverting sign of PCA scores to have: 100 = worse cohesion\")\n",
    "    social_cohesion_score_2022 = -social_cohesion_score_2022\n",
    "\n",
    "# normalize the scores to a 0-100 scale\n",
    "scaler_pct = MinMaxScaler(feature_range=(0, 100))\n",
    "social_cohesion_normalized = scaler_pct.fit_transform(social_cohesion_score_2022)\n",
    "\n",
    "# final df \n",
    "cohesion_df = data_2022.loc[X_social_2022.index, ['state', 'year']].copy()\n",
    "cohesion_df['social_cohesion_score'] = social_cohesion_normalized\n",
    "\n",
    "# save \n",
    "os.makedirs(\"PCA\", exist_ok=True)\n",
    "cohesion_df.to_csv(\"PCA/score.csv\", index=False)\n",
    "\n",
    "cohesion_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
