{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd35f235",
   "metadata": {},
   "source": [
    "# Random Forest Regression for Multidimensional Poverty Estimation\n",
    "\n",
    "This notebook implements a complete modeling pipeline for nowcasting multidimensional poverty indicators using Random Forest Regression. The objective is to predict CONEVAL’s official poverty statistics for each Mexican state by leveraging text-derived indicators from various digital sources, including YouTube, Telegram, Google Trends, and online news outlets.\n",
    "\n",
    "## Data Integration\n",
    "\n",
    "The analysis integrates six categories of text-based features across two reference years (2020 and 2022):\n",
    "\n",
    "- **Google Trends**: Normalized search interest on poverty-related keywords.\n",
    "- **YouTube Comments**: Share of comments related to each poverty dimension and their average sentiment.\n",
    "- **Telegram Posts**: Share of negatively connoted posts about each dimension.\n",
    "- **News Outlets**: Share of LDA-derived topics aligned with poverty-related themes.\n",
    "- **Official Statistics**: CONEVAL’s ground truth multidimensional poverty indicators.\n",
    "\n",
    "**Geographic Scope**: All 32 Mexican states.  \n",
    "**Temporal Scope**: 2020 (training) and 2022 (validation).\n",
    "\n",
    "## Methodology: Random Forest Regression\n",
    "\n",
    "Random Forest is a particularly suitable method for this task due to its:\n",
    "\n",
    "- Ability to capture **nonlinear relationships** and **interactions** between features.\n",
    "- Robustness to **multicollinearity** and **noisy predictors**, especially when combining multiple heterogeneous sources.\n",
    "- Built-in mechanism for **feature importance estimation**, allowing implicit selection of relevant variables.\n",
    "- Strong performance in **high-dimensional, low-sample-size (p > n)** contexts, such as the current setting with 32 observations and 37 features.\n",
    "\n",
    "## Feature Engineering and Model Training\n",
    "\n",
    "- All numeric indicators, excluding `state`, `year`, and the target column, were included as predictors.\n",
    "- No feature scaling was applied, as Random Forest is inherently scale-invariant.\n",
    "- A separate model was trained for each dimension of poverty.\n",
    "\n",
    "Two training-validation strategies were implemented:\n",
    "\n",
    "1. **In-Sample**: Models were trained on both 2020 and 2022 data, with evaluation on 2022 only.\n",
    "2. **Out-of-Sample**: Models were trained solely on 2020 and tested on 2022, simulating a real-world nowcasting scenario.\n",
    "\n",
    "## Hyperparameter Selection\n",
    "\n",
    "Initially, the following configuration was manually selected based on its strong empirical performance:\n",
    "\n",
    "- `n_estimators = 100`: Provides stable ensemble averaging without overfitting.\n",
    "- `max_depth = 4`: Controls model complexity and prevents overly deep trees.\n",
    "- `min_samples_leaf = 2`: Avoids over-specialization on very small sample splits.\n",
    "\n",
    "Subsequently, we introduced hyperparameter tuning via **GridSearchCV** using **Leave-One-Out Cross-Validation (LOOCV)**. The following search space was explored:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [90, 100, 110],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3]}\n",
    "```\n",
    "\n",
    "This grid was intentionally narrow and centered around the manual baseline configuration. Broader or more dispersed parameter ranges were initially tested but led to a degradation in model performance. The grid was thus refined to reflect values empirically known to work well, while still allowing for some tuning flexibility.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "Each model was evaluated on 2022 using:\n",
    "\n",
    "- **R-squared (R²)**: Measures explained variance.\n",
    "- **Mean Absolute Error (MAE)**: Captures average prediction error.\n",
    "\n",
    "Results are stored in:\n",
    "- `results.csv`: contains actual vs predicted values for each state and dimension.\n",
    "- `metrics.csv`: includes model performance and the list of important features (with importances).\n",
    "- Scatter plots: for each poverty dimension, we visualize predicted vs actual values and overlay the perfect prediction line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df03cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e113ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "tg_2020 = pd.read_csv('clean_data/tg_2020.csv')\n",
    "tg_2022 = pd.read_csv('clean_data/tg_2022.csv')\n",
    "gt_2020 = pd.read_csv('clean_data/gt_2020.csv')\n",
    "gt_2022 = pd.read_csv('clean_data/gt_2022.csv')\n",
    "yt_2020 = pd.read_csv('clean_data/yt_2020.csv')\n",
    "yt_2022 = pd.read_csv('clean_data/yt_2022.csv')\n",
    "news_2020 = pd.read_csv('clean_data/news_2020.csv')\n",
    "news_2022 = pd.read_csv('clean_data/news_2022.csv')\n",
    "off_2020 = pd.read_csv('clean_data/off_2020.csv')\n",
    "off_2022 = pd.read_csv('clean_data/off_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were inconsistencies in the state names, so this mapping standardizes the state names across all datasets\n",
    "state_name_map = {\n",
    "    \"México\": \"Estado de México\",\n",
    "    \"Mexico\": \"Estado de México\",\n",
    "    \"Estados Unidos Mexicanos\": \"Estado de México\",\n",
    "    \"Michoacán de Ocampo\": \"Michoacán\",\n",
    "    \"Veracruz de Ignacio de la Llave\": \"Veracruz\",\n",
    "    \"Coahuila de Zaragoza\": \"Coahuila\",\n",
    "    \"Yucatan\": \"Yucatán\",\n",
    "    \"Queretaro\": \"Querétaro\",\n",
    "    \"San Luis Potosi\": \"San Luis Potosí\",\n",
    "    \"Nuevo Leon\": \"Nuevo León\",\n",
    "    \"Michoacan\": \"Michoacán\",\n",
    "    \"Michoacán de Ocampo\": \"Michoacán\"}\n",
    "\n",
    "# aplply the mapping\n",
    "for df in [off_2020, off_2022, gt_2020, gt_2022, yt_2020, yt_2022, tg_2020, tg_2022, news_2020, news_2022]:\n",
    "    df['state'] = df['state'].astype(str).str.strip()\n",
    "    df['state'] = df['state'].replace(state_name_map)\n",
    "    df['state'] = df['state'].replace(\"nan\", None)  \n",
    "\n",
    "# 'state' columns as strings in all dataframes\n",
    "for df in [off_2020, off_2022, gt_2020, gt_2022, yt_2020, yt_2022, tg_2020, tg_2022, news_2020, news_2022]:\n",
    "    df['state'] = df['state'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b6adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: 64\n"
     ]
    }
   ],
   "source": [
    "# create dataset for 2020\n",
    "data_2020 = off_2020.copy()\n",
    "data_2020['year'] = 2020\n",
    "\n",
    "# merge Google Trends\n",
    "data_2020 = data_2020.merge(gt_2020, on='state', how='inner')\n",
    "\n",
    "# merge YouTube\n",
    "data_2020 = data_2020.merge(yt_2020, on='state', how='inner')\n",
    "\n",
    "# merge Telegram\n",
    "data_2020 = data_2020.merge(tg_2020, on='state', how='inner')\n",
    "\n",
    "# merge News (=LDA topics)\n",
    "data_2020 = data_2020.merge(news_2020, on='state', how='inner')\n",
    "\n",
    "\n",
    "# create dataset for 2022\n",
    "data_2022 = off_2022.copy()\n",
    "data_2022['year'] = 2022\n",
    "\n",
    "# merge Google Trends\n",
    "data_2022 = data_2022.merge(gt_2022, on='state', how='inner')\n",
    "\n",
    "# merge YouTube\n",
    "data_2022 = data_2022.merge(yt_2022, on='state', how='inner')\n",
    "\n",
    "# merge Telegram\n",
    "data_2022 = data_2022.merge(tg_2022, on='state', how='inner')\n",
    "\n",
    "# merge News (=LDA topics)\n",
    "data_2022 = data_2022.merge(news_2022, on='state', how='inner')\n",
    "\n",
    "# combine datasets for 2020 and 2022\n",
    "combined_data = pd.concat([data_2020, data_2022], ignore_index=True)\n",
    "\n",
    "# check that we have all the states in both years (32 states * 2 years = 64 observations)\n",
    "print(f\"Number of observations: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cc4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map poverty dimensions to target columns\n",
    "POVERTY_DIMENSIONS = {\n",
    "    'income': 'income_target',\n",
    "    'health': 'health_target',\n",
    "    'education': 'educ_target',\n",
    "    'social_security': 'social_target',\n",
    "    'housing': 'housing_target',\n",
    "    'food': 'food_target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4379940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features to use \n",
    "def get_all_feature_columns(data, target_columns, exclude_cols=['state', 'year']):\n",
    "    return [col for col in data.columns if col not in target_columns + exclude_cols and data[col].dtype in [np.float64, np.int64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e802ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_data_grid(data, dimension, target_col):\n",
    "    all_targets = list(POVERTY_DIMENSIONS.values())\n",
    "    feature_cols = get_all_feature_columns(data, all_targets)\n",
    "\n",
    "    X = data[feature_cols].values\n",
    "    y = data[target_col].values\n",
    "    mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))\n",
    "    X, y = X[mask], y[mask]\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [90, 100, 110],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    search = GridSearchCV(\n",
    "        rf, param_grid, scoring='neg_mean_squared_error', cv=LeaveOneOut(),\n",
    "        n_jobs=-1, verbose=0)\n",
    "    search.fit(X, y)\n",
    "\n",
    "    return {\n",
    "        'dimension': dimension,\n",
    "        'model': search.best_estimator_,\n",
    "        'feature_cols': feature_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45da8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to validate on 2022\n",
    "def validate_2022(data, rf_results):\n",
    "    data_2022 = data[data['year'] == 2022].copy()\n",
    "    results = {}\n",
    "\n",
    "    for dim, res in rf_results.items():\n",
    "        print(f\"\\n--- {dim.upper()} ---\")\n",
    "        model = res['model']\n",
    "        features = res['feature_cols']\n",
    "        target = POVERTY_DIMENSIONS.get(dim)\n",
    "\n",
    "        if target not in data_2022.columns:\n",
    "            continue\n",
    "\n",
    "        X_test = data_2022[features].values\n",
    "        y_test = data_2022[target].values\n",
    "\n",
    "        mask = ~(np.isnan(X_test).any(axis=1) | np.isnan(y_test))\n",
    "        X_test, y_test = X_test[mask], y_test[mask]\n",
    "        states = data_2022['state'].values[mask]\n",
    "\n",
    "        if len(X_test) == 0:\n",
    "            continue\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        print(f\"R² = {r2:.3f}, MAE = {mae:.3f}\")\n",
    "\n",
    "        results[dim] = {\n",
    "            'states': states,\n",
    "            'y_true': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'r2': r2,\n",
    "            'mae': mae}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd945041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all results \n",
    "def save_rf_results(results_dict, models_dict, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # 1. save predictions (results.csv)\n",
    "    preds = {'state': next(iter(results_dict.values()))['states']}\n",
    "    for dim, res in results_dict.items():\n",
    "        preds[f'{dim}_actual'] = res['y_true']\n",
    "        preds[f'{dim}_predicted'] = res['y_pred']\n",
    "    pd.DataFrame(preds).to_csv(f\"{folder_name}/results.csv\", index=False)\n",
    "\n",
    "    # 2. save metrics (metrics.csv)\n",
    "    rows = []\n",
    "    for dim, res in results_dict.items():\n",
    "        model = models_dict[dim]['model']\n",
    "        features_used = models_dict[dim]['feature_cols']\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        important_features = [\n",
    "            (f, round(imp, 4)) for f, imp in zip(features_used, importances) if imp > 0]\n",
    "\n",
    "        num_used = len(important_features)\n",
    "\n",
    "        rows.append({\n",
    "            'dimension': dim,\n",
    "            'r2': res['r2'],\n",
    "            'mae': res['mae'],\n",
    "            'n_features_used': num_used,\n",
    "            'important_features': sorted(important_features, key=lambda x: -x[1])})\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(f\"{folder_name}/metrics.csv\", index=False)\n",
    "\n",
    "    # 3. scatter plot for each dimension\n",
    "    for dim, res in results_dict.items():\n",
    "        y_true = res['y_true']\n",
    "        y_pred = res['y_pred']\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.scatter(\n",
    "            y_true, y_pred,\n",
    "            color='royalblue',\n",
    "            edgecolor='black',\n",
    "            s=250,  \n",
    "            alpha=0.9)\n",
    "\n",
    "        min_val = min(min(y_true), min(y_pred))\n",
    "        max_val = max(max(y_true), max(y_pred))\n",
    "        plt.plot(\n",
    "            [min_val, max_val], [min_val, max_val],\n",
    "            'r--', linewidth=3, label='Perfect prediction')\n",
    "\n",
    "        plt.xlabel(\"CONEVAL's statistics\", fontsize=24, fontweight='bold')\n",
    "        plt.ylabel(\"Predicted Values\", fontsize=24, fontweight='bold')\n",
    "        plt.title(f\"{dim.replace('_', ' ').title()}\\n$R^2$ = {res['r2']:.3f}\", fontsize=28, fontweight='bold')\n",
    "\n",
    "        plt.xticks(fontsize=20, fontweight='bold')\n",
    "        plt.yticks(fontsize=20, fontweight='bold')\n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{folder_name}/{dim}_plot.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1b5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== In-Sample Validation) ===\n",
      "\n",
      "--- INCOME ---\n",
      "R² = 0.896, MAE = 3.580\n",
      "\n",
      "--- HEALTH ---\n",
      "R² = 0.840, MAE = 4.041\n",
      "\n",
      "--- EDUCATION ---\n",
      "R² = 0.867, MAE = 1.384\n",
      "\n",
      "--- SOCIAL_SECURITY ---\n",
      "R² = 0.900, MAE = 3.697\n",
      "\n",
      "--- HOUSING ---\n",
      "R² = 0.952, MAE = 1.698\n",
      "\n",
      "--- FOOD ---\n",
      "R² = 0.907, MAE = 1.450\n"
     ]
    }
   ],
   "source": [
    "rf_all_results = {}\n",
    "for dim, target in POVERTY_DIMENSIONS.items():\n",
    "    if target in combined_data.columns:\n",
    "        result = train_all_data_grid(combined_data, dim, target)\n",
    "        if result:\n",
    "            rf_all_results[dim] = result\n",
    "\n",
    "print(\"\\n=== In-Sample Validation) ===\")\n",
    "validation_rf_all = validate_2022(combined_data, rf_all_results)\n",
    "\n",
    "save_rf_results(validation_rf_all, rf_all_results, \"rf_in_sample_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a26824be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2020_grid(data, dimension, target_col):\n",
    "    train_data = data[data['year'] == 2020].copy()\n",
    "    all_targets = list(POVERTY_DIMENSIONS.values())\n",
    "    feature_cols = get_all_feature_columns(train_data, all_targets)\n",
    "\n",
    "    X = train_data[feature_cols].values\n",
    "    y = train_data[target_col].values\n",
    "    mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))\n",
    "    X, y = X[mask], y[mask]\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [90, 100, 110],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    search = GridSearchCV(\n",
    "        rf, param_grid, scoring='neg_mean_squared_error', cv=LeaveOneOut(),\n",
    "        n_jobs=-1, verbose=0)\n",
    "    search.fit(X, y)\n",
    "\n",
    "    return {\n",
    "        'dimension': dimension,\n",
    "        'model': search.best_estimator_,\n",
    "        'feature_cols': feature_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d28bf54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Out-Of-Sample Validation) ===\n",
      "\n",
      "--- INCOME ---\n",
      "R² = 0.198, MAE = 9.927\n",
      "\n",
      "--- HEALTH ---\n",
      "R² = -0.618, MAE = 11.936\n",
      "\n",
      "--- EDUCATION ---\n",
      "R² = 0.076, MAE = 3.951\n",
      "\n",
      "--- SOCIAL_SECURITY ---\n",
      "R² = 0.368, MAE = 9.457\n",
      "\n",
      "--- HOUSING ---\n",
      "R² = 0.573, MAE = 5.441\n",
      "\n",
      "--- FOOD ---\n",
      "R² = 0.139, MAE = 4.598\n"
     ]
    }
   ],
   "source": [
    "rf_2020_results = {}\n",
    "for dim, target in POVERTY_DIMENSIONS.items():\n",
    "    if target in combined_data.columns:\n",
    "        result = train_2020_grid(combined_data, dim, target)\n",
    "        if result:\n",
    "            rf_2020_results[dim] = result\n",
    "\n",
    "print(\"\\n=== Out-Of-Sample Validation) ===\")\n",
    "validation_rf_2020 = validate_2022(combined_data, rf_2020_results)\n",
    "\n",
    "save_rf_results(validation_rf_2020, rf_2020_results, \"rf_out_sample_grid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
