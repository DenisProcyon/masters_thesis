{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a404597",
   "metadata": {},
   "source": [
    "## newest: search at state level things such as 'jalisco news' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce775ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noemilucchi/miniforge3/envs/new/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Guanajuato...\n",
      "  Searching for 'Guanajuato noticias'...\n",
      "Found 100 videos for query 'Guanajuato noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Guanajuato noticias': 100%|██████████| 100/100 [04:10<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Guanajuato news'...\n",
      "Found 100 videos for query 'Guanajuato news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Guanajuato news': 100%|██████████| 100/100 [12:31<00:00,  7.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Guanajuato economía'...\n",
      "Found 100 videos for query 'Guanajuato economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Guanajuato economía': 100%|██████████| 100/100 [01:33<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Analyzed 300 videos and 18446 comments for Guanajuato\n",
      "Saved results to yt_keyword_sentiment/guanajuato.csv\n",
      "\n",
      "Analyzing Michoacán...\n",
      "  Searching for 'Michoacán noticias'...\n",
      "Found 100 videos for query 'Michoacán noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Michoacán noticias': 100%|██████████| 100/100 [04:26<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Michoacán new'...\n",
      "Found 100 videos for query 'Michoacán new'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Michoacán new': 100%|██████████| 100/100 [05:49<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Michoacán economía'...\n",
      "Found 100 videos for query 'Michoacán economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Michoacán economía': 100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Analyzed 300 videos and 13810 comments for Michoacán\n",
      "Saved results to yt_keyword_sentiment/michoacán.csv\n",
      "\n",
      "Analyzing Sinaloa...\n",
      "  Searching for 'Sinaloa noticias'...\n",
      "Found 100 videos for query 'Sinaloa noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sinaloa noticias': 100%|██████████| 100/100 [02:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Sinaloa news'...\n",
      "Found 100 videos for query 'Sinaloa news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sinaloa news': 100%|██████████| 100/100 [07:14<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Sinaloa economía'...\n",
      "Found 100 videos for query 'Sinaloa economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sinaloa economía': 100%|██████████| 100/100 [01:32<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Analyzed 300 videos and 12499 comments for Sinaloa\n",
      "Saved results to yt_keyword_sentiment/sinaloa.csv\n",
      "\n",
      "Analyzing Chihuahua...\n",
      "  Searching for 'Chihuahua noticias'...\n",
      "Found 100 videos for query 'Chihuahua noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Chihuahua noticias': 100%|██████████| 100/100 [02:14<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Chihuahua news'...\n",
      "Found 100 videos for query 'Chihuahua news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Chihuahua news': 100%|██████████| 100/100 [02:57<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Chihuahua economía'...\n",
      "Found 100 videos for query 'Chihuahua economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Chihuahua economía': 100%|██████████| 100/100 [06:01<00:00,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Analyzed 300 videos and 10891 comments for Chihuahua\n",
      "Saved results to yt_keyword_sentiment/chihuahua.csv\n",
      "\n",
      "Analyzing Guerrero...\n",
      "  Searching for 'Guerrero noticias'...\n",
      "Found 100 videos for query 'Guerrero noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Guerrero noticias': 100%|██████████| 100/100 [03:07<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Guerrero news'...\n",
      "Found 100 videos for query 'Guerrero news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Guerrero news': 100%|██████████| 100/100 [05:14<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Guerrero economía'...\n",
      "Found 100 videos for query 'Guerrero economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Guerrero economía': 100%|██████████| 100/100 [04:10<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Analyzed 300 videos and 12278 comments for Guerrero\n",
      "Saved results to yt_keyword_sentiment/guerrero.csv\n",
      "\n",
      "Analyzing Tamaulipas...\n",
      "  Searching for 'Tamaulipas noticias'...\n",
      "Found 100 videos for query 'Tamaulipas noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tamaulipas noticias': 100%|██████████| 100/100 [03:23<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tamaulipas news'...\n",
      "Found 100 videos for query 'Tamaulipas news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tamaulipas news':  33%|███▎      | 33/100 [01:43<03:29,  3.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 289\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved combined results to yt_keyword_sentiment/all_states_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[43manalyze_all_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 254\u001b[0m, in \u001b[0;36manalyze_all_states\u001b[0;34m()\u001b[0m\n\u001b[1;32m    251\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state, search_terms \u001b[38;5;129;01min\u001b[39;00m STATES_SEARCH_TERMS\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 254\u001b[0m     stats, total_videos, total_comments \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_state_by_keywords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_terms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_terms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_range\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Create dataframe for this state\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\n\u001b[1;32m    262\u001b[0m         {\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m: state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m dim, v \u001b[38;5;129;01min\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    271\u001b[0m     ])\n",
      "Cell \u001b[0;32mIn[1], line 233\u001b[0m, in \u001b[0;36mYouTubeAnalyzer.analyze_state_by_keywords\u001b[0;34m(self, state_name, search_terms, date_range)\u001b[0m\n\u001b[1;32m    231\u001b[0m dimension, confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mclassify_dimension(clean)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.1\u001b[39m:  \u001b[38;5;66;03m# Only count if confidence is high enough\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sentiment_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     dimension_stats[dimension][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sentiment\n\u001b[1;32m    235\u001b[0m     dimension_stats[dimension][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 114\u001b[0m, in \u001b[0;36mTextProcessor.get_sentiment_score\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    112\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 114\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m stars \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (stars \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1564\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:436\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[0;32m--> 436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:386\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 386\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    388\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "\n",
    "# Define states and search terms\n",
    "STATES_SEARCH_TERMS = {\n",
    "    \"Guanajuato\": [\n",
    "        \"Guanajuato noticias\", \n",
    "        \"Guanajuato news\", \n",
    "        \"Guanajuato economía\"\n",
    "    ],\n",
    "    \"Michoacán\": [\n",
    "        \"Michoacán noticias\", \n",
    "        \"Michoacán new\", \n",
    "        \"Michoacán economía\"\n",
    "    ],\n",
    "    \"Sinaloa\": [\n",
    "        \"Sinaloa noticias\", \n",
    "        \"Sinaloa news\", \n",
    "        \"Sinaloa economía\"\n",
    "    ],\n",
    "    \"Chihuahua\": [\n",
    "        \"Chihuahua noticias\", \n",
    "        \"Chihuahua news\", \n",
    "        \"Chihuahua economía\"\n",
    "    ],\n",
    "    \"Guerrero\": [\n",
    "        \"Guerrero noticias\", \n",
    "        \"Guerrero news\", \n",
    "        \"Guerrero economía\"\n",
    "    ],\n",
    "    \"Tamaulipas\": [\n",
    "        \"Tamaulipas noticias\", \n",
    "        \"Tamaulipas news\", \n",
    "        \"Tamaulipas economía\"\n",
    "    ],\n",
    "    \"Baja California\": [\n",
    "        \"Baja California noticias\", \n",
    "        \"Baja California news\", \n",
    "        \"Baja California economía\"\n",
    "    ],\n",
    "    \"Zacatecas\": [\n",
    "        \"Zacatecas noticias\", \n",
    "        \"Zacatecas new\", \n",
    "        \"Zacatecas economía\"\n",
    "    ],\n",
    "    \"Colima\": [\n",
    "        \"Colima noticias\", \n",
    "        \"Colima news\", \n",
    "        \"Colima economía\"\n",
    "    ],\n",
    "    \"Jalisco\": [\n",
    "        \"Jalisco noticias\", \n",
    "        \"Jalisco news\", \n",
    "        \"Jalisco economía\"]}\n",
    "\n",
    "# Neutral keyword-based descriptions for poverty dimensions\n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"empleo trabajo ingreso dinero salario estabilidad ocupación oportunidades\",\n",
    "    \"ACCESS TO HEALTH SERVICES\": \"salud hospital médico medicina tratamiento atención clínica seguro\",\n",
    "    \"EDUCATIONAL LAG\": \"educación escuela maestro estudiante aprendizaje clases universidad formación\",\n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"seguridad social pensión jubilación contrato derechos prestaciones protección laboral\",\n",
    "    \"HOUSING\": \"vivienda casa habitación servicios básicos infraestructura hogar alquiler agua luz\",\n",
    "    \"ACCESS TO FOOD\": \"alimentación comida nutrición alimentos dieta mercado hambre acceso\",\n",
    "    \"SOCIAL COHESION\": \"comunidad inclusión integración participación convivencia respeto diversidad solidaridad\"\n",
    "}\n",
    "\n",
    "# limits for scraping\n",
    "MAX_VIDEOS_PER_SEARCH = 100  \n",
    "MAX_COMMENTS_PER_VIDEO = 300  \n",
    "API_SLEEP_TIME = 0.5  \n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.dimension_embeddings = self.embedder.encode(list(POVERTY_DIMENSIONS.values()), convert_to_tensor=True)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "    def classify_dimension(self, text):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        embedding = self.embedder.encode(text, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(embedding, self.dimension_embeddings)[0]\n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        return self.dimension_names[max_idx], cosine_scores[max_idx].item()\n",
    "\n",
    "    def get_sentiment_score(self, text):\n",
    "        if not text:\n",
    "            return 0.0\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        stars = torch.argmax(outputs.logits, dim=1).item() + 1\n",
    "        return (stars - 3) / 2  # Normalize to [-1, 1]\n",
    "\n",
    "class YouTubeAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "        self.processor = TextProcessor()\n",
    "\n",
    "    def search_videos(self, query, published_after, published_before, max_results=MAX_VIDEOS_PER_SEARCH):\n",
    "        \"\"\"Search for videos using a keyword query.\"\"\"\n",
    "        videos = []\n",
    "        next_page_token = None\n",
    "        \n",
    "        try:\n",
    "            while len(videos) < max_results:\n",
    "                response = self.youtube.search().list(\n",
    "                    q=query,\n",
    "                    part=\"snippet\",\n",
    "                    maxResults=min(50, max_results - len(videos)),  # YouTube API allows max 50 per request\n",
    "                    pageToken=next_page_token,\n",
    "                    type=\"video\",\n",
    "                    order=\"relevance\",\n",
    "                    publishedAfter=published_after,\n",
    "                    publishedBefore=published_before,\n",
    "                    relevanceLanguage=\"es\"\n",
    "                ).execute()\n",
    "                \n",
    "                for item in response.get(\"items\", []):\n",
    "                    if item[\"id\"][\"kind\"] == \"youtube#video\":\n",
    "                        videos.append({\n",
    "                            \"id\": item[\"id\"][\"videoId\"],\n",
    "                            \"title\": item[\"snippet\"][\"title\"],\n",
    "                            \"description\": item[\"snippet\"].get(\"description\", \"\"),\n",
    "                            \"published_at\": item[\"snippet\"][\"publishedAt\"]\n",
    "                        })\n",
    "                \n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token or len(videos) >= max_results:\n",
    "                    break\n",
    "                \n",
    "                sleep(API_SLEEP_TIME)  # Avoid quota exceeded errors\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{query}': {e}\")\n",
    "        \n",
    "        print(f\"Found {len(videos)} videos for query '{query}'\")\n",
    "        return videos\n",
    "\n",
    "    def get_video_comments(self, video_id, max_comments=MAX_COMMENTS_PER_VIDEO):\n",
    "        \"\"\"Get comments for a specific video.\"\"\"\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "        \n",
    "        try:\n",
    "            while len(comments) < max_comments:\n",
    "                response = self.youtube.commentThreads().list(\n",
    "                    part=\"snippet\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=min(100, max_comments - len(comments)),  # YouTube API allows max 100 per request\n",
    "                    pageToken=next_page_token\n",
    "                ).execute()\n",
    "                \n",
    "                for item in response.get(\"items\", []):\n",
    "                    comment_text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                    comments.append(comment_text)\n",
    "                \n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token or len(comments) >= max_comments:\n",
    "                    break\n",
    "                \n",
    "                sleep(API_SLEEP_TIME)  # Avoid quota exceeded errors\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Many videos have comments disabled, so we'll just pass silently\n",
    "            pass\n",
    "        \n",
    "        return comments\n",
    "\n",
    "    def analyze_state_by_keywords(self, state_name, search_terms, date_range):\n",
    "        \"\"\"Analyze a state by searching for videos using specified search terms.\"\"\"\n",
    "        print(f\"\\nAnalyzing {state_name}...\")\n",
    "        dimension_stats = {dim: {\"sentiment_sum\": 0.0, \"count\": 0} for dim in POVERTY_DIMENSIONS}\n",
    "        total_videos = 0\n",
    "        total_comments = 0\n",
    "        \n",
    "        # Search for videos with each search term\n",
    "        for search_term in search_terms:\n",
    "            print(f\"  Searching for '{search_term}'...\")\n",
    "            videos = self.search_videos(\n",
    "                query=search_term,\n",
    "                published_after=date_range[\"published_after\"],\n",
    "                published_before=date_range[\"published_before\"],\n",
    "                max_results=MAX_VIDEOS_PER_SEARCH\n",
    "            )\n",
    "            \n",
    "            if not videos:\n",
    "                continue\n",
    "                \n",
    "            total_videos += len(videos)\n",
    "            \n",
    "            # Process videos\n",
    "            for video in tqdm(videos, desc=f\"Processing videos for '{search_term}'\"):\n",
    "                # Get video comments\n",
    "                comments = self.get_video_comments(video[\"id\"], MAX_COMMENTS_PER_VIDEO)\n",
    "                total_comments += len(comments)\n",
    "                \n",
    "                # Concatenate title, description and comments for analysis\n",
    "                all_texts = [video[\"title\"] + \". \" + video[\"description\"]] + comments\n",
    "                \n",
    "                # Analyze each text\n",
    "                for text in all_texts:\n",
    "                    clean = self.processor.clean_text(text)\n",
    "                    if len(clean) < 10:  # Skip very short texts\n",
    "                        continue\n",
    "                        \n",
    "                    dimension, confidence = self.processor.classify_dimension(clean)\n",
    "                    if confidence > 0.1:  # Only count if confidence is high enough\n",
    "                        sentiment = self.processor.get_sentiment_score(clean)\n",
    "                        dimension_stats[dimension][\"sentiment_sum\"] += sentiment\n",
    "                        dimension_stats[dimension][\"count\"] += 1\n",
    "        \n",
    "        print(f\"  Analyzed {total_videos} videos and {total_comments} comments for {state_name}\")\n",
    "        return dimension_stats, total_videos, total_comments\n",
    "\n",
    "def analyze_all_states():\n",
    "    analyzer = YouTubeAnalyzer(YT_API_KEY)\n",
    "    date_range = {\n",
    "        \"published_after\": \"2022-01-01T00:00:00Z\",\n",
    "        \"published_before\": \"2022-12-31T23:59:59Z\"\n",
    "    }\n",
    "    \n",
    "    # Create directories for results\n",
    "    os.makedirs(\"yt_keyword_sentiment\", exist_ok=True)\n",
    "    \n",
    "    # Store overall stats for summary\n",
    "    all_results = []\n",
    "    \n",
    "    for state, search_terms in STATES_SEARCH_TERMS.items():\n",
    "        stats, total_videos, total_comments = analyzer.analyze_state_by_keywords(\n",
    "            state_name=state,\n",
    "            search_terms=search_terms,\n",
    "            date_range=date_range\n",
    "        )\n",
    "        \n",
    "        # Create dataframe for this state\n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                \"state\": state,\n",
    "                \"dimension\": dim.replace(\"_\", \" \").title(),\n",
    "                \"avg_sentiment\": v[\"sentiment_sum\"] / v[\"count\"] if v[\"count\"] else 0,\n",
    "                \"mentions_count\": v[\"count\"],\n",
    "                \"videos_analyzed\": total_videos,\n",
    "                \"comments_analyzed\": total_comments\n",
    "            }\n",
    "            for dim, v in stats.items()\n",
    "        ])\n",
    "        \n",
    "        # Save state-specific results\n",
    "        output_file = f\"yt_keyword_sentiment/{state.replace(' ', '_').lower()}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved results to {output_file}\")\n",
    "        \n",
    "        # Add to overall results\n",
    "        all_results.append(df)\n",
    "    \n",
    "    # Combine all results into one dataframe\n",
    "    if all_results:\n",
    "        all_df = pd.concat(all_results)\n",
    "        all_df.to_csv(\"yt_keyword_sentiment/all_states_results.csv\", index=False)\n",
    "        print(\"Saved combined results to yt_keyword_sentiment/all_states_results.csv\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084b34e",
   "metadata": {},
   "source": [
    "## 1) sentiment conditional on the dimension - define dimensions just in a descrptive/neutral way \n",
    "Define the 7 dimensions of poverty using neutral words - for instance for income use words such as employment, work, income, money, salary, financial stability, opportunities - and then do the word embedding for them to find comments that talk about the specific dimension. Once all comments are categorized into the corresponding dimension, compute the average sentiment per dimension. \n",
    "\n",
    "In this way we avoid any bias as we are just categorizing by dimension of poverty and then computing the sentiment score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf111d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noemilucchi/miniforge3/envs/new/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Tamaulipas...\n",
      "Saved yt_channels_sentiment/tamaulipas.csv\n",
      "Analyzing Baja California...\n",
      "Saved yt_channels_sentiment/baja_california.csv\n",
      "Analyzing Zacatecas...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 178\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved yt_channels_sentiment/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[43manalyze_all_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 165\u001b[0m, in \u001b[0;36manalyze_all_states\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myt_channels_sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state, channels \u001b[38;5;129;01min\u001b[39;00m STATES_CHANNELS_NAMES\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 165\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_range\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\n\u001b[1;32m    167\u001b[0m         {\n\u001b[1;32m    168\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m: dim\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtitle(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m dim, v \u001b[38;5;129;01min\u001b[39;00m stats\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    173\u001b[0m     ])\n\u001b[1;32m    174\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myt_channels_sentiment/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 145\u001b[0m, in \u001b[0;36mYouTubeAnalyzer.analyze_state\u001b[0;34m(self, state_name, channel_infos, date_range)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m channel_id:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m videos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_channel_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_range\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpublished_after\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_range\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpublished_before\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m videos:\n\u001b[1;32m    147\u001b[0m     all_texts \u001b[38;5;241m=\u001b[39m [video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_video_comments(video[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m, in \u001b[0;36mYouTubeAnalyzer.get_channel_videos\u001b[0;34m(self, channel_id, published_after, published_before)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m next_page_token:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m videos\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "\n",
    "# Define states and channel names to search for\n",
    "STATES_CHANNELS_NAMES = {\n",
    "    \"Guanajuato\": [\n",
    "        {\"name\": \"TV4 Guanajuato\"},\n",
    "        {\"name\": \"Periódico Correo\"},\n",
    "        {\"name\": \"Gobierno de Guanajuato\"}\n",
    "    ],\n",
    "    \"Michoacán\": [\n",
    "        {\"name\": \"CB Televisión\"},\n",
    "        {\"name\": \"Noticias Michoacán\"},\n",
    "        {\"name\": \"Gobierno de Michoacán\"}\n",
    "    ],\n",
    "    \"Sinaloa\": [\n",
    "        {\"name\": \"Noticiero Altavoz\"},\n",
    "        {\"name\": \"TVP Culiacán\"},\n",
    "        {\"name\": \"Gobierno de Sinaloa\"}\n",
    "    ],\n",
    "    \"Chihuahua\": [\n",
    "        {\"name\": \"Canal 28 Chihuahua\"},\n",
    "        {\"name\": \"Noticias de Chihuahua\"},\n",
    "        {\"name\": \"Gobierno de Chihuahua\"}\n",
    "    ],\n",
    "    \"Guerrero\": [\n",
    "        {\"name\": \"Noticiero Acapulco\"},\n",
    "        {\"name\": \"Televisa Acapulco\"},\n",
    "        {\"name\": \"Gobierno de Guerrero\"}\n",
    "    ],\n",
    "    \"Tamaulipas\": [\n",
    "        {\"name\": \"Noticias Tamaulipas\"},\n",
    "        {\"name\": \"Televisa Tamaulipas\"},\n",
    "        {\"name\": \"Gobierno de Tamaulipas\"}\n",
    "    ],\n",
    "    \"Baja California\": [\n",
    "        {\"name\": \"Síntesis TV\"},\n",
    "        {\"name\": \"PSN Televisión\"},\n",
    "        {\"name\": \"Gobierno de Baja California\"}\n",
    "    ],\n",
    "    \"Zacatecas\": [\n",
    "        {\"name\": \"NTR Zacatecas\"},\n",
    "        {\"name\": \"Zacatecas Online\"},\n",
    "        {\"name\": \"Gobierno de Zacatecas\"}\n",
    "    ],\n",
    "    \"Colima\": [\n",
    "        {\"name\": \"AF Medios\"},\n",
    "        {\"name\": \"Colima Noticias\"},\n",
    "        {\"name\": \"Gobierno de Colima\"}\n",
    "    ],\n",
    "    \"Jalisco\": [\n",
    "        {\"name\": \"Canal 44\"},\n",
    "        {\"name\": \"Televisa Guadalajara\"},\n",
    "        {\"name\": \"Gobierno de Jalisco\"}]}\n",
    "\n",
    "# Neutral keyword-based descriptions for poverty dimensions\n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"empleo trabajo ingreso dinero salario estabilidad ocupación oportunidades\",\n",
    "    \"ACCESS TO HEALTH SERVICES\": \"salud hospital médico medicina tratamiento atención clínica seguro\",\n",
    "    \"EDUCATIONAL LAG\": \"educación escuela maestro estudiante aprendizaje clases universidad formación\",\n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"seguridad social pensión jubilación contrato derechos prestaciones protección laboral\",\n",
    "    \"HOUSING\": \"vivienda casa habitación servicios básicos infraestructura hogar alquiler agua luz\",\n",
    "    \"ACCESS TO FOOD\": \"alimentación comida nutrición alimentos dieta mercado hambre acceso\",\n",
    "    \"SOCIAL COHESION\": \"comunidad inclusión integración participación convivencia respeto diversidad solidaridad\"\n",
    "}\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.dimension_embeddings = self.embedder.encode(list(POVERTY_DIMENSIONS.values()), convert_to_tensor=True)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "    def classify_dimension(self, text):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        embedding = self.embedder.encode(text, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(embedding, self.dimension_embeddings)[0]\n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        return self.dimension_names[max_idx], cosine_scores[max_idx].item()\n",
    "\n",
    "    def get_sentiment_score(self, text):\n",
    "        if not text:\n",
    "            return 0.0\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        stars = torch.argmax(outputs.logits, dim=1).item() + 1\n",
    "        return (stars - 3) / 2  # Normalize to [-1, 1]\n",
    "\n",
    "class YouTubeAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "        self.processor = TextProcessor()\n",
    "\n",
    "    def get_channel_id_by_name(self, name, state):\n",
    "        query = f\"{name} {state}\"\n",
    "        response = self.youtube.search().list(q=query, part=\"id\", maxResults=1, type=\"channel\").execute()\n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        return None\n",
    "\n",
    "    def get_channel_videos(self, channel_id, published_after, published_before):\n",
    "        videos = []\n",
    "        uploads_id = self.youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            response = self.youtube.playlistItems().list(\n",
    "                playlistId=uploads_id, part=\"snippet\", maxResults=50, pageToken=next_page_token\n",
    "            ).execute()\n",
    "            for item in response['items']:\n",
    "                published = item['snippet']['publishedAt']\n",
    "                if published_after <= published <= published_before:\n",
    "                    videos.append({\n",
    "                        \"id\": item['snippet']['resourceId']['videoId'],\n",
    "                        \"title\": item['snippet']['title'],\n",
    "                        \"description\": item['snippet'].get('description', '')\n",
    "                    })\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "            sleep(0.5)\n",
    "        return videos\n",
    "\n",
    "    def get_video_comments(self, video_id):\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            try:\n",
    "                response = self.youtube.commentThreads().list(\n",
    "                    part=\"snippet\", videoId=video_id, maxResults=100, pageToken=next_page_token\n",
    "                ).execute()\n",
    "                for item in response.get(\"items\", []):\n",
    "                    comments.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token:\n",
    "                    break\n",
    "                sleep(0.5)\n",
    "            except Exception:\n",
    "                break\n",
    "        return comments\n",
    "\n",
    "    def analyze_state(self, state_name, channel_infos, date_range):\n",
    "        print(f\"Analyzing {state_name}...\")\n",
    "        dimension_stats = {dim: {\"sentiment_sum\": 0.0, \"count\": 0} for dim in POVERTY_DIMENSIONS}\n",
    "        for channel in channel_infos:\n",
    "            channel_id = self.get_channel_id_by_name(channel[\"name\"], state_name)\n",
    "            if not channel_id:\n",
    "                continue\n",
    "            videos = self.get_channel_videos(channel_id, date_range[\"published_after\"], date_range[\"published_before\"])\n",
    "            for video in videos:\n",
    "                all_texts = [video[\"title\"] + \". \" + video[\"description\"]] + self.get_video_comments(video[\"id\"])\n",
    "                for text in all_texts:\n",
    "                    clean = self.processor.clean_text(text)\n",
    "                    dimension, confidence = self.processor.classify_dimension(clean)\n",
    "                    if confidence > 0.1:\n",
    "                        sentiment = self.processor.get_sentiment_score(clean)\n",
    "                        dimension_stats[dimension][\"sentiment_sum\"] += sentiment\n",
    "                        dimension_stats[dimension][\"count\"] += 1\n",
    "        return dimension_stats\n",
    "\n",
    "def analyze_all_states():\n",
    "    analyzer = YouTubeAnalyzer(YT_API_KEY)\n",
    "    date_range = {\n",
    "        \"published_after\": \"2022-01-01T00:00:00Z\",\n",
    "        \"published_before\": \"2022-12-31T23:59:59Z\"\n",
    "    }\n",
    "    os.makedirs(\"yt_channels_sentiment\", exist_ok=True)\n",
    "    for state, channels in STATES_CHANNELS_NAMES.items():\n",
    "        stats = analyzer.analyze_state(state, channels, date_range)\n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                \"dimension\": dim.replace(\"_\", \" \").title(),\n",
    "                \"avg_sentiment\": v[\"sentiment_sum\"] / v[\"count\"] if v[\"count\"] else 0\n",
    "            }\n",
    "            for dim, v in stats.items()\n",
    "        ])\n",
    "        df.to_csv(f\"yt_channels_sentiment/{state.replace(' ', '_').lower()}.csv\", index=False)\n",
    "        print(f\"Saved yt_channels_sentiment/{state.replace(' ', '_').lower()}.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b26e5",
   "metadata": {},
   "source": [
    "## 2) only count of comments related to each dimension of poverty to avoid any bias \n",
    "\n",
    "Here we are categorizing by negative attributes related to each poverty dimension - for instance for income we are now using unemployment, economic crisis, low salary, unstable jobs - and then we are just counting the occurences of 'negative' words per dimension.\n",
    "\n",
    "We avoid the bias since we don't do the sentiment analysis - which would lean towards negative scores as we are filtering for negative things in the first place - but we just count how much each dimension of poverty is discussed. We could assume that, the more a dimension of poverty is discussed, the higher that 'type' of poverty is. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "load_dotenv()\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "\n",
    "# Expanded poverty dimensions\n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"Desempleo, salario bajo, crisis económica, sin ingresos suficientes, trabajos temporales, vivir al día, situación precaria, inflación, deuda, sueldo de hambre, precariedad laboral, no alcanza, buscar trabajo, sin chamba.\",\n",
    "    \"ACCESS TO HEALTH SERVICES\": \"Sin medicinas, hospital lejano, largas esperas, sin seguro médico, mala atención, falta de doctores, centros de salud cerrados, salud pública colapsada, servicios de urgencia deficientes, tratamientos caros, automedicación.\",\n",
    "    \"EDUCATIONAL LAG\": \"Rezago escolar, analfabetismo, sin maestros, abandono escolar, escuelas en mal estado, falta de útiles, deserción, educación de baja calidad, falta de acceso educativo, desigualdad educativa, jóvenes sin estudiar.\",\n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"Trabajo informal, sin contrato, sin prestaciones, sin IMSS, falta de protección laboral, empleo sin derechos, sin jubilación, condiciones precarias, trabajadores explotados, empleo sin seguridad social.\",\n",
    "    \"HOUSING\": \"Vivienda precaria, sin agua o luz, hacinamiento, casa insegura, techos de lámina, casas de cartón, renta cara, falta de drenaje, zonas de riesgo, sin baño, construcciones vulnerables, viviendas abandonadas.\",\n",
    "    \"ACCESS TO FOOD\": \"Inseguridad alimentaria, hambre, comida escasa, sin alimentos básicos, malnutrición, dieta pobre, precios altos, ni para frijoles, dependencia alimentaria, comer una vez al día, alimentos inaccesibles.\",\n",
    "    \"SOCIAL COHESION\": \"Fragmentación social, discriminación, exclusión, desigualdad, tensiones comunitarias, racismo, violencia entre barrios, marginación, falta de integración, odio de clase, polarización social.\"\n",
    "}\n",
    "\n",
    "STATES_CHANNELS_NAMES = {\n",
    "    \"Guanajuato\": [\n",
    "        {\"name\": \"TV4 Guanajuato\"},\n",
    "        {\"name\": \"Periódico Correo\"},\n",
    "        {\"name\": \"Gobierno de Guanajuato\"}\n",
    "    ],\n",
    "    \"Michoacán\": [\n",
    "        {\"name\": \"CB Televisión\"},\n",
    "        {\"name\": \"Noticias Michoacán\"},\n",
    "        {\"name\": \"Gobierno de Michoacán\"}\n",
    "    ],\n",
    "    \"Sinaloa\": [\n",
    "        {\"name\": \"Noticiero Altavoz\"},\n",
    "        {\"name\": \"TVP Culiacán\"},\n",
    "        {\"name\": \"Gobierno de Sinaloa\"}\n",
    "    ],\n",
    "    \"Chihuahua\": [\n",
    "        {\"name\": \"Canal 28 Chihuahua\"},\n",
    "        {\"name\": \"Noticias de Chihuahua\"},\n",
    "        {\"name\": \"Gobierno de Chihuahua\"}\n",
    "    ],\n",
    "    \"Guerrero\": [\n",
    "        {\"name\": \"Noticiero Acapulco\"},\n",
    "        {\"name\": \"Televisa Acapulco\"},\n",
    "        {\"name\": \"Gobierno de Guerrero\"}\n",
    "    ],\n",
    "    \"Tamaulipas\": [\n",
    "        {\"name\": \"Noticias Tamaulipas\"},\n",
    "        {\"name\": \"Televisa Tamaulipas\"},\n",
    "        {\"name\": \"Gobierno de Tamaulipas\"}\n",
    "    ],\n",
    "    \"Baja California\": [\n",
    "        {\"name\": \"Síntesis TV\"},\n",
    "        {\"name\": \"PSN Televisión\"},\n",
    "        {\"name\": \"Gobierno de Baja California\"}\n",
    "    ],\n",
    "    \"Zacatecas\": [\n",
    "        {\"name\": \"NTR Zacatecas\"},\n",
    "        {\"name\": \"Zacatecas Online\"},\n",
    "        {\"name\": \"Gobierno de Zacatecas\"}\n",
    "    ],\n",
    "    \"Colima\": [\n",
    "        {\"name\": \"AF Medios\"},\n",
    "        {\"name\": \"Colima Noticias\"},\n",
    "        {\"name\": \"Gobierno de Colima\"}\n",
    "    ],\n",
    "    \"Jalisco\": [\n",
    "        {\"name\": \"Canal 44\"},\n",
    "        {\"name\": \"Televisa Guadalajara\"},\n",
    "        {\"name\": \"Gobierno de Jalisco\"}]}\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        self.dimensions = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.embeddings = self.embedder.encode(list(POVERTY_DIMENSIONS.values()), convert_to_tensor=True)\n",
    "\n",
    "    def clean(self, text):\n",
    "        text = re.sub(r\"<.*?>\", \" \", text)\n",
    "        text = re.sub(r\"http\\\\S+\", \"\", text)\n",
    "        text = re.sub(r\"[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]\", \" \", text)\n",
    "        return re.sub(r\"\\s+\", \" \", text).strip().lower()\n",
    "\n",
    "    def classify(self, text):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        emb = self.embedder.encode(text, convert_to_tensor=True)\n",
    "        scores = util.cos_sim(emb, self.embeddings)[0]\n",
    "        best_idx = torch.argmax(scores).item()\n",
    "        return self.dimensions[best_idx], scores[best_idx].item()\n",
    "\n",
    "class YouTubeAnalyzer:\n",
    "    def __init__(self, key):\n",
    "        self.youtube = build(\"youtube\", \"v3\", developerKey=key)\n",
    "        self.processor = TextProcessor()\n",
    "\n",
    "    def get_channel_id(self, name, state):\n",
    "        q = f\"{name} {state}\"\n",
    "        res = self.youtube.search().list(q=q, part=\"id\", maxResults=1, type=\"channel\").execute()\n",
    "        return res[\"items\"][0][\"id\"][\"channelId\"] if res[\"items\"] else None\n",
    "\n",
    "    def get_videos(self, channel_id, after, before):\n",
    "        vids = []\n",
    "        uploads_id = self.youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "        token = None\n",
    "        while True:\n",
    "            res = self.youtube.playlistItems().list(playlistId=uploads_id, part=\"snippet\", maxResults=50, pageToken=token).execute()\n",
    "            for item in res[\"items\"]:\n",
    "                pub = item[\"snippet\"][\"publishedAt\"]\n",
    "                if after <= pub <= before:\n",
    "                    vids.append({\n",
    "                        \"id\": item[\"snippet\"][\"resourceId\"][\"videoId\"],\n",
    "                        \"title\": item[\"snippet\"][\"title\"],\n",
    "                        \"description\": item[\"snippet\"].get(\"description\", \"\")\n",
    "                    })\n",
    "            token = res.get(\"nextPageToken\")\n",
    "            if not token:\n",
    "                break\n",
    "            sleep(0.5)\n",
    "        return vids\n",
    "\n",
    "    def get_comments(self, video_id):\n",
    "        coms = []\n",
    "        token = None\n",
    "        while True:\n",
    "            try:\n",
    "                res = self.youtube.commentThreads().list(videoId=video_id, part=\"snippet\", maxResults=100, pageToken=token).execute()\n",
    "                for item in res.get(\"items\", []):\n",
    "                    coms.append(item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"])\n",
    "                token = res.get(\"nextPageToken\")\n",
    "                if not token:\n",
    "                    break\n",
    "                sleep(0.5)\n",
    "            except Exception:\n",
    "                break\n",
    "        return coms\n",
    "\n",
    "    def analyze(self, state, channels, drange):\n",
    "        print(f\"\\nAnalyzing {state}...\")\n",
    "        counts = {d: 0 for d in POVERTY_DIMENSIONS}\n",
    "        for ch in channels:\n",
    "            cid = self.get_channel_id(ch[\"name\"], state)\n",
    "            if not cid:\n",
    "                continue\n",
    "            videos = self.get_videos(cid, drange[\"after\"], drange[\"before\"])\n",
    "            for v in videos:\n",
    "                texts = [v[\"title\"] + \". \" + v[\"description\"]] + self.get_comments(v[\"id\"])\n",
    "                for t in texts:\n",
    "                    dim, conf = self.processor.classify(self.processor.clean(t))\n",
    "                    if conf > 0.1:\n",
    "                        counts[dim] += 1\n",
    "        return counts\n",
    "\n",
    "def run_analysis():\n",
    "    yt = YouTubeAnalyzer(YT_API_KEY)\n",
    "    drange = {\"after\": \"2022-01-01T00:00:00Z\", \"before\": \"2022-12-31T23:59:59Z\"}\n",
    "    os.makedirs(\"yt_channels\", exist_ok=True)\n",
    "    for state, chs in STATES_CHANNELS_NAMES.items():\n",
    "        results = yt.analyze(state, chs, drange)\n",
    "        df = pd.DataFrame([{\"dimension\": k, \"comment_count\": v} for k, v in results.items()])\n",
    "        df.to_csv(f\"yt_channels/{state.lower().replace(' ', '_')}.csv\", index=False)\n",
    "        print(f\"Saved yt_channels/{state.lower().replace(' ', '_')}.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff550f",
   "metadata": {},
   "source": [
    "## 3) standard approach of filtering for negative words + sentiment score + counts of words \n",
    "This could potentially lead to bias results, although I compared results of this approach with results from approach 1 and they are more or less aligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "\n",
    "# Define states and channel names to search for\n",
    "STATES_CHANNELS_NAMES = {\n",
    "    \"Guanajuato\": [\n",
    "        {\"name\": \"TV4 Guanajuato\"},\n",
    "        {\"name\": \"Periódico Correo\"},\n",
    "        {\"name\": \"Gobierno de Guanajuato\"}\n",
    "    ],\n",
    "    \"Michoacán\": [\n",
    "        {\"name\": \"CB Televisión\"},\n",
    "        {\"name\": \"Noticias Michoacán\"},\n",
    "        {\"name\": \"Gobierno de Michoacán\"}\n",
    "    ],\n",
    "    \"Sinaloa\": [\n",
    "        {\"name\": \"Noticiero Altavoz\"},\n",
    "        {\"name\": \"TVP Culiacán\"},\n",
    "        {\"name\": \"Gobierno de Sinaloa\"}\n",
    "    ],\n",
    "    \"Chihuahua\": [\n",
    "        {\"name\": \"Canal 28 Chihuahua\"},\n",
    "        {\"name\": \"Noticias de Chihuahua\"},\n",
    "        {\"name\": \"Gobierno de Chihuahua\"}\n",
    "    ],\n",
    "    \"Guerrero\": [\n",
    "        {\"name\": \"Noticiero Acapulco\"},\n",
    "        {\"name\": \"Televisa Acapulco\"},\n",
    "        {\"name\": \"Gobierno de Guerrero\"}\n",
    "    ],\n",
    "    \"Tamaulipas\": [\n",
    "        {\"name\": \"Noticias Tamaulipas\"},\n",
    "        {\"name\": \"Televisa Tamaulipas\"},\n",
    "        {\"name\": \"Gobierno de Tamaulipas\"}\n",
    "    ],\n",
    "    \"Baja California\": [\n",
    "        {\"name\": \"Síntesis TV\"},\n",
    "        {\"name\": \"PSN Televisión\"},\n",
    "        {\"name\": \"Gobierno de Baja California\"}\n",
    "    ],\n",
    "    \"Zacatecas\": [\n",
    "        {\"name\": \"NTR Zacatecas\"},\n",
    "        {\"name\": \"Zacatecas Online\"},\n",
    "        {\"name\": \"Gobierno de Zacatecas\"}\n",
    "    ],\n",
    "    \"Colima\": [\n",
    "        {\"name\": \"AF Medios\"},\n",
    "        {\"name\": \"Colima Noticias\"},\n",
    "        {\"name\": \"Gobierno de Colima\"}\n",
    "    ],\n",
    "    \"Jalisco\": [\n",
    "        {\"name\": \"Canal 44\"},\n",
    "        {\"name\": \"Televisa Guadalajara\"},\n",
    "        {\"name\": \"Gobierno de Jalisco\"}]}\n",
    "\n",
    "# Spanish descriptions of poverty dimensions\n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INGRESOS\": \"Empleo, salarios, estabilidad financiera, desigualdad de ingresos, oportunidades económicas, seguridad laboral.\",\n",
    "    \"ACCESO A SALUD\": \"Acceso a servicios de salud, calidad médica, medicamentos, seguros, infraestructura hospitalaria.\",\n",
    "    \"REZAGO EDUCATIVO\": \"Acceso a la educación, calidad escolar, alfabetización, abandono escolar, recursos educativos.\",\n",
    "    \"SEGURIDAD SOCIAL\": \"Derechos laborales, protección social, empleo informal, prestaciones, jubilación, seguridad en el empleo.\",\n",
    "    \"VIVIENDA\": \"Calidad de vivienda, acceso a servicios, hacinamiento, asequibilidad, condiciones, desalojos, instalaciones.\",\n",
    "    \"ALIMENTACIÓN\": \"Seguridad alimentaria, hambre, asequibilidad de alimentos, calidad alimentaria, malnutrición, disponibilidad, asistencia.\",\n",
    "    \"COHESIÓN SOCIAL\": \"Integración social, exclusión, marginación, discriminación, confianza, apoyo comunitario.\"\n",
    "}\n",
    "\n",
    "SPANISH_STOPWORDS = [\"de\", \"la\", \"que\", \"el\", \"en\"]\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.dimension_embeddings = self.embedder.encode(list(POVERTY_DIMENSIONS.values()), convert_to_tensor=True)\n",
    "        self.sentiment_model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "        self.sentiment_tokenizer = AutoTokenizer.from_pretrained(self.sentiment_model_name)\n",
    "        self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(self.sentiment_model_name)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "    def get_sentiment_score(self, text):\n",
    "        if not text:\n",
    "            return 0.0\n",
    "        inputs = self.sentiment_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.sentiment_model(**inputs)\n",
    "        stars = torch.argmax(outputs.logits, dim=1).item() + 1\n",
    "        return (stars - 3) / 2\n",
    "\n",
    "    def classify_dimension(self, text):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        embedding = self.embedder.encode(text, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(embedding, self.dimension_embeddings)[0]\n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        return self.dimension_names[max_idx], cosine_scores[max_idx].item()\n",
    "\n",
    "class YouTubeAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "        self.processor = TextProcessor()\n",
    "\n",
    "    def get_channel_id_by_name(self, name, state):\n",
    "        query = f\"{name} {state}\"\n",
    "        response = self.youtube.search().list(q=query, part=\"id\", maxResults=1, type=\"channel\").execute()\n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        return None\n",
    "\n",
    "    def get_channel_videos(self, channel_id, published_after, published_before):\n",
    "        videos = []\n",
    "        uploads_id = self.youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            response = self.youtube.playlistItems().list(\n",
    "                playlistId=uploads_id, part=\"snippet\", maxResults=50, pageToken=next_page_token\n",
    "            ).execute()\n",
    "            for item in response['items']:\n",
    "                published = item['snippet']['publishedAt']\n",
    "                if published_after <= published <= published_before:\n",
    "                    videos.append({\n",
    "                        \"id\": item['snippet']['resourceId']['videoId'],\n",
    "                        \"title\": item['snippet']['title'],\n",
    "                        \"description\": item['snippet'].get('description', '')\n",
    "                    })\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "            sleep(0.5)\n",
    "        return videos\n",
    "\n",
    "    def get_video_comments(self, video_id):\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            try:\n",
    "                response = self.youtube.commentThreads().list(\n",
    "                    part=\"snippet\", videoId=video_id, maxResults=100, pageToken=next_page_token\n",
    "                ).execute()\n",
    "                for item in response.get(\"items\", []):\n",
    "                    comments.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token:\n",
    "                    break\n",
    "                sleep(0.5)\n",
    "            except Exception:\n",
    "                break\n",
    "        return comments\n",
    "\n",
    "    def analyze_state(self, state_name, channel_infos, date_range):\n",
    "        print(f\"Analyzing {state_name}...\")\n",
    "        dimension_stats = {dim: {\"count\": 0, \"sentiment_sum\": 0.0} for dim in POVERTY_DIMENSIONS}\n",
    "        for channel in channel_infos:\n",
    "            channel_id = self.get_channel_id_by_name(channel[\"name\"], state_name)\n",
    "            if not channel_id:\n",
    "                continue\n",
    "            videos = self.get_channel_videos(channel_id, date_range[\"published_after\"], date_range[\"published_before\"])\n",
    "            for video in videos:\n",
    "                all_texts = [video[\"title\"] + \". \" + video[\"description\"]] + self.get_video_comments(video[\"id\"])\n",
    "                for text in all_texts:\n",
    "                    clean = self.processor.clean_text(text)\n",
    "                    sentiment = self.processor.get_sentiment_score(clean)\n",
    "                    dimension, confidence = self.processor.classify_dimension(clean)\n",
    "                    if confidence > 0.1:\n",
    "                        dimension_stats[dimension][\"count\"] += 1\n",
    "                        dimension_stats[dimension][\"sentiment_sum\"] += sentiment\n",
    "        return dimension_stats\n",
    "\n",
    "\n",
    "def analyze_all_states():\n",
    "    analyzer = YouTubeAnalyzer(YT_API_KEY)\n",
    "    date_range = {\n",
    "        \"published_after\": \"2022-01-01T00:00:00Z\",\n",
    "        \"published_before\": \"2022-12-31T23:59:59Z\"\n",
    "    }\n",
    "    os.makedirs(\"yt_channels\", exist_ok=True)\n",
    "    for state, channels in STATES_CHANNELS_NAMES.items():\n",
    "        stats = analyzer.analyze_state(state, channels, date_range)\n",
    "        df = pd.DataFrame([{ \"dimension\": dim, \"comment_count\": v[\"count\"], \"avg_sentiment\": v[\"sentiment_sum\"]/v[\"count\"] if v[\"count\"] else 0 } for dim, v in stats.items()])\n",
    "        df.to_csv(f\"yt_channels/{state.replace(' ', '_').lower()}.csv\", index=False)\n",
    "        print(f\"Saved yt_channels/{state.replace(' ', '_').lower()}.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e41e2",
   "metadata": {},
   "source": [
    "## 4) same as above but with just more words to define the embedding \n",
    "Technically the embedding, since takes the context, should be able to generalize and so shouldn't be necessary to give too many words. But still this might improve the generalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")\n",
    "\n",
    "# Define states and channel names to search for\n",
    "STATES_CHANNELS_NAMES = {\n",
    "    \"Guanajuato\": [\n",
    "        {\"name\": \"TV4 Guanajuato\"},\n",
    "        {\"name\": \"Periódico Correo\"},\n",
    "        {\"name\": \"Gobierno de Guanajuato\"}\n",
    "    ],\n",
    "    \"Michoacán\": [\n",
    "        {\"name\": \"CB Televisión\"},\n",
    "        {\"name\": \"Noticias Michoacán\"},\n",
    "        {\"name\": \"Gobierno de Michoacán\"}\n",
    "    ],\n",
    "    \"Sinaloa\": [\n",
    "        {\"name\": \"Noticiero Altavoz\"},\n",
    "        {\"name\": \"TVP Culiacán\"},\n",
    "        {\"name\": \"Gobierno de Sinaloa\"}\n",
    "    ],\n",
    "    \"Chihuahua\": [\n",
    "        {\"name\": \"Canal 28 Chihuahua\"},\n",
    "        {\"name\": \"Noticias de Chihuahua\"},\n",
    "        {\"name\": \"Gobierno de Chihuahua\"}\n",
    "    ],\n",
    "    \"Guerrero\": [\n",
    "        {\"name\": \"Noticiero Acapulco\"},\n",
    "        {\"name\": \"Televisa Acapulco\"},\n",
    "        {\"name\": \"Gobierno de Guerrero\"}\n",
    "    ],\n",
    "    \"Tamaulipas\": [\n",
    "        {\"name\": \"Noticias Tamaulipas\"},\n",
    "        {\"name\": \"Televisa Tamaulipas\"},\n",
    "        {\"name\": \"Gobierno de Tamaulipas\"}\n",
    "    ],\n",
    "    \"Baja California\": [\n",
    "        {\"name\": \"Síntesis TV\"},\n",
    "        {\"name\": \"PSN Televisión\"},\n",
    "        {\"name\": \"Gobierno de Baja California\"}\n",
    "    ],\n",
    "    \"Zacatecas\": [\n",
    "        {\"name\": \"NTR Zacatecas\"},\n",
    "        {\"name\": \"Zacatecas Online\"},\n",
    "        {\"name\": \"Gobierno de Zacatecas\"}\n",
    "    ],\n",
    "    \"Colima\": [\n",
    "        {\"name\": \"AF Medios\"},\n",
    "        {\"name\": \"Colima Noticias\"},\n",
    "        {\"name\": \"Gobierno de Colima\"}\n",
    "    ],\n",
    "    \"Jalisco\": [\n",
    "        {\"name\": \"Canal 44\"},\n",
    "        {\"name\": \"Televisa Guadalajara\"},\n",
    "        {\"name\": \"Gobierno de Jalisco\"}]}\n",
    "\n",
    "# Expanded poverty dimensions \n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"Desempleo, salario bajo, crisis económica, sin ingresos suficientes, trabajos temporales, vivir al día, situación precaria, inflación, deuda, sueldo de hambre, precariedad laboral, no alcanza, buscar trabajo, sin chamba.\",\n",
    "    \"ACCESS TO HEALTH SERVICES\": \"Sin medicinas, hospital lejano, largas esperas, sin seguro médico, mala atención, falta de doctores, centros de salud cerrados, salud pública colapsada, servicios de urgencia deficientes, tratamientos caros, automedicación.\",\n",
    "    \"EDUCATIONAL LAG\": \"Rezago escolar, analfabetismo, sin maestros, abandono escolar, escuelas en mal estado, falta de útiles, deserción, educación de baja calidad, falta de acceso educativo, desigualdad educativa, jóvenes sin estudiar.\",\n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"Trabajo informal, sin contrato, sin prestaciones, sin IMSS, falta de protección laboral, empleo sin derechos, sin jubilación, condiciones precarias, trabajadores explotados, empleo sin seguridad social.\",\n",
    "    \"HOUSING\": \"Vivienda precaria, sin agua o luz, hacinamiento, casa insegura, techos de lámina, casas de cartón, renta cara, falta de drenaje, zonas de riesgo, sin baño, construcciones vulnerables, viviendas abandonadas.\",\n",
    "    \"ACCESS TO FOOD\": \"Inseguridad alimentaria, hambre, comida escasa, sin alimentos básicos, malnutrición, dieta pobre, precios altos, ni para frijoles, dependencia alimentaria, comer una vez al día, alimentos inaccesibles.\",\n",
    "    \"SOCIAL COHESION\": \"Fragmentación social, discriminación, exclusión, desigualdad, tensiones comunitarias, racismo, violencia entre barrios, marginación, falta de integración, odio de clase, polarización social.\"\n",
    "}\n",
    "\n",
    "SPANISH_STOPWORDS = [\"de\", \"la\", \"que\", \"el\", \"en\"]\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.dimension_embeddings = self.embedder.encode(list(POVERTY_DIMENSIONS.values()), convert_to_tensor=True)\n",
    "        self.sentiment_model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "        self.sentiment_tokenizer = AutoTokenizer.from_pretrained(self.sentiment_model_name)\n",
    "        self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(self.sentiment_model_name)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "    def get_sentiment_score(self, text):\n",
    "        if not text:\n",
    "            return 0.0\n",
    "        inputs = self.sentiment_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.sentiment_model(**inputs)\n",
    "        stars = torch.argmax(outputs.logits, dim=1).item() + 1\n",
    "        return (stars - 3) / 2\n",
    "\n",
    "    def classify_dimension(self, text):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        embedding = self.embedder.encode(text, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(embedding, self.dimension_embeddings)[0]\n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        return self.dimension_names[max_idx], cosine_scores[max_idx].item()\n",
    "\n",
    "class YouTubeAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "        self.processor = TextProcessor()\n",
    "\n",
    "    def get_channel_id_by_name(self, name, state):\n",
    "        query = f\"{name} {state}\"\n",
    "        response = self.youtube.search().list(q=query, part=\"id\", maxResults=1, type=\"channel\").execute()\n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        return None\n",
    "\n",
    "    def get_channel_videos(self, channel_id, published_after, published_before):\n",
    "        videos = []\n",
    "        uploads_id = self.youtube.channels().list(part=\"contentDetails\", id=channel_id).execute()['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            response = self.youtube.playlistItems().list(\n",
    "                playlistId=uploads_id, part=\"snippet\", maxResults=50, pageToken=next_page_token\n",
    "            ).execute()\n",
    "            for item in response['items']:\n",
    "                published = item['snippet']['publishedAt']\n",
    "                if published_after <= published <= published_before:\n",
    "                    videos.append({\n",
    "                        \"id\": item['snippet']['resourceId']['videoId'],\n",
    "                        \"title\": item['snippet']['title'],\n",
    "                        \"description\": item['snippet'].get('description', '')\n",
    "                    })\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "            sleep(0.5)\n",
    "        return videos\n",
    "\n",
    "    def get_video_comments(self, video_id):\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "        while True:\n",
    "            try:\n",
    "                response = self.youtube.commentThreads().list(\n",
    "                    part=\"snippet\", videoId=video_id, maxResults=100, pageToken=next_page_token\n",
    "                ).execute()\n",
    "                for item in response.get(\"items\", []):\n",
    "                    comments.append(item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token:\n",
    "                    break\n",
    "                sleep(0.5)\n",
    "            except Exception:\n",
    "                break\n",
    "        return comments\n",
    "\n",
    "    def analyze_state(self, state_name, channel_infos, date_range):\n",
    "        print(f\"Analyzing {state_name}...\")\n",
    "        dimension_stats = {dim: {\"count\": 0, \"sentiment_sum\": 0.0} for dim in POVERTY_DIMENSIONS}\n",
    "        for channel in channel_infos:\n",
    "            channel_id = self.get_channel_id_by_name(channel[\"name\"], state_name)\n",
    "            if not channel_id:\n",
    "                continue\n",
    "            videos = self.get_channel_videos(channel_id, date_range[\"published_after\"], date_range[\"published_before\"])\n",
    "            for video in videos:\n",
    "                all_texts = [video[\"title\"] + \". \" + video[\"description\"]] + self.get_video_comments(video[\"id\"])\n",
    "                for text in all_texts:\n",
    "                    clean = self.processor.clean_text(text)\n",
    "                    sentiment = self.processor.get_sentiment_score(clean)\n",
    "                    dimension, confidence = self.processor.classify_dimension(clean)\n",
    "                    if confidence > 0.1:\n",
    "                        dimension_stats[dimension][\"count\"] += 1\n",
    "                        dimension_stats[dimension][\"sentiment_sum\"] += sentiment\n",
    "        return dimension_stats\n",
    "\n",
    "\n",
    "def analyze_all_states():\n",
    "    analyzer = YouTubeAnalyzer(YT_API_KEY)\n",
    "    date_range = {\n",
    "        \"published_after\": \"2022-01-01T00:00:00Z\",\n",
    "        \"published_before\": \"2022-12-31T23:59:59Z\"\n",
    "    }\n",
    "    os.makedirs(\"yt_channels\", exist_ok=True)\n",
    "    for state, channels in STATES_CHANNELS_NAMES.items():\n",
    "        stats = analyzer.analyze_state(state, channels, date_range)\n",
    "        df = pd.DataFrame([{ \"dimension\": dim.replace(\"_\", \" \").title(), \"comment_count\": v[\"count\"], \"avg_sentiment\": v[\"sentiment_sum\"]/v[\"count\"] if v[\"count\"] else 0 } for dim, v in stats.items()])\n",
    "        df.to_csv(f\"yt_channels/{state.replace(' ', '_').lower()}.csv\", index=False)\n",
    "        print(f\"Saved yt_channels/{state.replace(' ', '_').lower()}.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_states()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
