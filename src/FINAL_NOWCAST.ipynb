{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd35f235",
   "metadata": {},
   "source": [
    "# Stacked Regression Approach for Nowcasting Multidimensional Poverty\n",
    "\n",
    "This notebook implements a three-stage method to nowcast multidimensional poverty for Mexican states using text-derived features. To address the *small n, large p* challenge, the pipeline includes:\n",
    "\n",
    "- **Feature Selection via LASSO:** this regularized linear model is used to identify a parsimonious subset of relevant predictors. This step mitigates overfitting risks common in high-dimensional, low-sample-size settings.\n",
    "- **Base Learners:** predictions are generated using **Random Forest Regression** and **Partial Least Squares Regression** (PLS). These models offer complementary strengths: RF captures complex non-linear relationships, while PLS provides stable linear modeling effective in small-sample scenarios.\n",
    "- **Meta-Learner:** we chose a simple Linear Regression to combine individual model's predictions and generate the final output. \n",
    "\n",
    "The rationale for adopting this stacking strategy is rooted in evidence from [Han et al., 2021](https://doi.org/10.1186/s12911-021-01688-3), who show that combining RF and Generalized Linear Models through stacking improves prediction in small-sample, high-dimensional biomedical datasets. Notably, stacking was most effective when the base learners produced dissimilar prediction profiles, allowing the meta-learner to integrate complementary information. Inspired by this, we stack RF and PLS, which are structurally highly distinct, to exploit their modeling capabilities.\n",
    "\n",
    "## Data Integration\n",
    "\n",
    "Six sources of text-based indicators are integrated across two years (2020 and 2022):\n",
    "\n",
    "- **Google Trends**: Search volume patterns for poverty-related keywords\n",
    "- **YouTube Comments**: Sentiment score and share of comments about each dimension of poverty \n",
    "- **Telegram Posts**: Share of posts about each dimension of poverty \n",
    "- **News Outlets**: LDA topic shares of media coverage\n",
    "- **Official Statistics**: CONEVAL poverty measurements (ground truth)\n",
    "\n",
    "**Geographic Scope**: All 32 Mexican states.  \n",
    "**Temporal Scope**: Two reference years — 2020 and 2022.\n",
    "\n",
    "## Feature Engineering and Model Training\n",
    "\n",
    "- All numeric indicators (except the targets, `state` and `year`) are used as features.\n",
    "- We are scaling features before implementing LASSO. Random Forest, since it's a tree-based model, would not need scaling, but since it is necessary for all the other models, we scaled features. However, this won't affect Random Forest performance. \n",
    "- A separate model is trained for each poverty dimension.\n",
    "\n",
    "We implemented two training-validation strategies:\n",
    "\n",
    "1. **In-Sample Setting**: Model trained on both 2020 and 2022 data, validated on 2022.\n",
    "2. **Out-of-Sample Setting**: Model trained only on 2020, validated on 2022.\n",
    "\n",
    "## Model Architecture: LASSO + RF + PLS (Stacked)\n",
    "\n",
    "### 1. **Feature Selection via LASSO Regression**\n",
    "```python\n",
    "# Apply LASSO independently for each poverty dimension\n",
    "lasso = Lasso(\n",
    "    alpha=1.0,  # Fixed regularization strength\n",
    "    random_state=42,\n",
    "    max_iter=10000\n",
    ").fit(X_scaled, y)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_mask = lasso.coef_ != 0\n",
    "selected_features = features[selected_mask]\n",
    "```\n",
    "\n",
    "- LASSO is applied independently for each of the six poverty dimensions\n",
    "- Selects a parsimonious subset of informative predictors from the full feature set (39 variables), driving irrelevant coefficients exactly to zero\n",
    "- **Fixed α = 1.0**: Provides strong regularization, ensuring aggressive feature selection suitable for high-dimensional, small-sample settings\n",
    "\n",
    "### 2. **Base Learners**\n",
    "```python\n",
    "base_learners = [\n",
    "    ('rf', RandomForestRegressor(\n",
    "        n_estimators=100,      # sufficient trees for stable predictions\n",
    "        max_depth=4,           # prevents overfitting in small samples\n",
    "        min_samples_leaf=2,    # ensures sufficient observations per leaf\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('pls', PLSRegression(\n",
    "        n_components=2         # always use two latent components \n",
    "    ))\n",
    "]\n",
    "```\n",
    "\n",
    "**Random Forest Regressor**: Captures complex non-linear patterns and feature interactions through ensemble of decision trees. We applied fixed hyperparameters, specifically chosen to prevent overfitting:\n",
    "  - `max_depth=4`: A shallow tree depth limits the model's ability to fit highly specific patterns that may not generalize beyond the sample. This value was selected to strike a balance between model flexibility and the risk of overfitting on sparse or noisy signals, which are common in high-dimensional text-derived features.\n",
    "  - `min_samples_leaf=2`: Requiring at least two samples per leaf prevents the model from creating overly specific splits that isolate single observations, which would otherwise increase variance and reduce generalization. While this threshold is low, it is appropriate given the extremely small sample we have. \n",
    "  - `n_estimators=100`: Using 100 trees provides sufficient averaging to stabilize predictions without making the model unnecessarily expensive. \n",
    "\n",
    "**Partial Least Squares (PLS) Regression**: Well-suited for high-dimensional settings where predictors are highly correlated, as it extracts latent components that summarize the most relevant variation in both predictors and the response. We applied a fixed number of components, equal to 2, across all poverty dimensions. We believe this is appropriate since:\n",
    "  - **Overfitting control**: Limiting the number of components is critical given the small sample size (32 states), helping prevent the model from fitting noise.\n",
    "  - **Interpretability**: Two components strike a balance between capturing key socioeconomic variation and maintaining a model structure that can be interpreted across dimensions.\n",
    "  - **Empirically validated**: We tried with different number of components, and 2 yielded the best results on average. \n",
    "\n",
    "### 3. **Stacking Layer with Cross-Validation**\n",
    "```python\n",
    "# Create StackingRegressor with automatic CV handling\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LinearRegression(),\n",
    "    cv=5,                    # 5-fold CV for meta-learner training only\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train with automatic out-of-fold prediction generation\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Key advantages of StackingRegressor**:\n",
    "- **Automatic cross-validation**: Generates out-of-fold predictions to train the meta-learner, preventing data leakage\n",
    "- **Robust generalization**: Each base learner is trained on k-1 folds and predicts on the held-out fold\n",
    "- **Meta-learner training**: Linear regression learns optimal weights to combine base learner predictions\n",
    "\n",
    "### 4. **Final Nowcasts**\n",
    "\n",
    "The stacked model produces final predictions by optimally combining the complementary strengths of Random Forest and PLS. We believe that the main two advantages of combining these models are:\n",
    "\n",
    "- **Balancing Bias and Variance:** Random Forest has low bias but moderate variance:\n",
    "  - The absence of assumptions about the functional form of the relationship between features and poverty indicators allows it to capture complex interactions -> low bias. \n",
    "  - Its predictions are sensitive to small changes in the training data. With only 32 states, different random samples or slight data modifications can lead to substantially different tree structures and predictions -> moderate variance (This is partially overcome given the averaging over multiple trees that RF does, so we don't say 'high variance', typical of simple trees, but 'moderate variance')\n",
    "\n",
    "   By contrast, PLS has low variance but high bias:\n",
    "  - PLS is constrained to linear combinations of latent components, so it can potentially miss important patterns when relationships are non-linear -> high bias.\n",
    "  - PLS produces stable, consistent predictions across different samples. Reducing dimensionality to 2 components makes predictions less sensitive to small changes in training data, which is crucial in small samples -> low variance. \n",
    "\n",
    "- **Different functional form:** as already mentioned, PLS captures linear relationships while RF captures non-linear patterns:\n",
    "    - When poverty-feature relationships are approximately linear, PLS provides reliable estimates while RF might overfit noise\n",
    "    - When relationships are genuinely non-linear, RF captures these patterns while PLS misses them \n",
    "\n",
    "### Why We Avoided Full Hyperparameter Tuning\n",
    "\n",
    "Given the limited sample size, we adopt a **fixed hyperparameter approach** rather than relying on automatic tuning through cross-validation (CV). Although CV is a standard procedure for model selection, in small-*n* contexts it can introduce more instability than benefit.\n",
    "\n",
    "We initially experimented with **GridSearchCV** and **RandomizedSearchCV** under various CV strategies, including **Leave-One-Out (LOOCV)**, **K-Fold**, and **Repeated K-Fold**. However, across all configurations, the models tuned via CV consistently performed much **worse** than our fixed-parameter baseline. \n",
    "\n",
    "To understand this behavior, we inspected the **variance in performance across CV folds**, and found it to be remarkably high. This high variance indicates that model performance is **sensitive to small changes in training data**.\n",
    "\n",
    "Indeed, with only 32 training points (we are specifically focusing on the out-of-sample performance as it is the most important one), the model evaluation metric fluctuates substantially due to small differences in training subsets. As a result, hyperparameter search tends to select configurations that **appear optimal due to chance** rather than generalizable performance.\n",
    "\n",
    "These findings are consistent with [Han et al., 2021](https://doi.org/10.1186/s12911-021-01688-3), who demonstrate that traditional CV-based hyperparameter selection can be **ineffective** in small-samples.\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "Each model was evaluated on 2022 using:\n",
    "\n",
    "- **R-squared (R²)**: Measures explained variance.\n",
    "- **Mean Absolute Error (MAE)**: Captures average prediction error.\n",
    "\n",
    "Results are stored in:\n",
    "- `results.csv`: contains actual vs predicted values for each state and dimension.\n",
    "- `metrics.csv`: includes model performance and the list of important features (with importances).\n",
    "- Scatter plots: for each poverty dimension, we visualize predicted vs actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df03cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e113ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "tg_2020 = pd.read_csv('clean_data/tg_2020.csv')\n",
    "tg_2022 = pd.read_csv('clean_data/tg_2022.csv')\n",
    "gt_2020 = pd.read_csv('clean_data/gt_2020.csv')\n",
    "gt_2022 = pd.read_csv('clean_data/gt_2022.csv')\n",
    "yt_2020 = pd.read_csv('clean_data/yt_2020.csv')\n",
    "yt_2022 = pd.read_csv('clean_data/yt_2022.csv')\n",
    "news_2020 = pd.read_csv('clean_data/news_2020.csv')\n",
    "news_2022 = pd.read_csv('clean_data/news_2022.csv')\n",
    "off_2020 = pd.read_csv('clean_data/off_2020.csv')\n",
    "off_2022 = pd.read_csv('clean_data/off_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were inconsistencies in the state names, so this mapping standardizes the state names across all datasets\n",
    "state_name_map = {\n",
    "    \"México\": \"Estado de México\",\n",
    "    \"Mexico\": \"Estado de México\",\n",
    "    \"Estados Unidos Mexicanos\": \"Estado de México\",\n",
    "    \"Michoacán de Ocampo\": \"Michoacán\",\n",
    "    \"Veracruz de Ignacio de la Llave\": \"Veracruz\",\n",
    "    \"Coahuila de Zaragoza\": \"Coahuila\",\n",
    "    \"Yucatan\": \"Yucatán\",\n",
    "    \"Queretaro\": \"Querétaro\",\n",
    "    \"San Luis Potosi\": \"San Luis Potosí\",\n",
    "    \"Nuevo Leon\": \"Nuevo León\",\n",
    "    \"Michoacan\": \"Michoacán\",\n",
    "    \"Michoacán de Ocampo\": \"Michoacán\"}\n",
    "\n",
    "# aplply the mapping\n",
    "for df in [off_2020, off_2022, gt_2020, gt_2022, yt_2020, yt_2022, tg_2020, tg_2022, news_2020, news_2022]:\n",
    "    df['state'] = df['state'].astype(str).str.strip()\n",
    "    df['state'] = df['state'].replace(state_name_map)\n",
    "    df['state'] = df['state'].replace(\"nan\", None)  \n",
    "\n",
    "# 'state' columns as strings in all dataframes\n",
    "for df in [off_2020, off_2022, gt_2020, gt_2022, yt_2020, yt_2022, tg_2020, tg_2022, news_2020, news_2022]:\n",
    "    df['state'] = df['state'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b6adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in 2020 dataframe: 32\n",
      "Number of observations in 2022 dataframe: 32\n",
      "Number of observations in combined dataframe: 64\n"
     ]
    }
   ],
   "source": [
    "# create dataset for 2020\n",
    "data_2020 = off_2020.copy()\n",
    "data_2020['year'] = 2020\n",
    "\n",
    "# merge Google Trends\n",
    "data_2020 = data_2020.merge(gt_2020, on='state', how='inner')\n",
    "\n",
    "# merge YouTube\n",
    "data_2020 = data_2020.merge(yt_2020, on='state', how='inner')\n",
    "\n",
    "# merge Telegram\n",
    "data_2020 = data_2020.merge(tg_2020, on='state', how='inner')\n",
    "\n",
    "# merge News (=LDA topics)\n",
    "data_2020 = data_2020.merge(news_2020, on='state', how='inner')\n",
    "\n",
    "\n",
    "# create dataset for 2022\n",
    "data_2022 = off_2022.copy()\n",
    "data_2022['year'] = 2022\n",
    "\n",
    "# merge Google Trends\n",
    "data_2022 = data_2022.merge(gt_2022, on='state', how='inner')\n",
    "\n",
    "# merge YouTube\n",
    "data_2022 = data_2022.merge(yt_2022, on='state', how='inner')\n",
    "\n",
    "# merge Telegram\n",
    "data_2022 = data_2022.merge(tg_2022, on='state', how='inner')\n",
    "\n",
    "# merge News (=LDA topics)\n",
    "data_2022 = data_2022.merge(news_2022, on='state', how='inner')\n",
    "\n",
    "# combine datasets for 2020 and 2022\n",
    "combined_data = pd.concat([data_2020, data_2022], ignore_index=True)\n",
    "\n",
    "# check that we have the correct number of observations in each year\n",
    "print(f\"Number of observations in 2020 dataframe: {len(data_2020)}\")\n",
    "print(f\"Number of observations in 2022 dataframe: {len(data_2022)}\")\n",
    "\n",
    "# check that we have all the states in both years (32 states * 2 years = 64 observations)\n",
    "print(f\"Number of observations in combined dataframe: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cc4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map poverty dimensions to target columns\n",
    "POVERTY_DIMENSIONS = {\n",
    "    'income': 'income_target',\n",
    "    'health': 'health_target',\n",
    "    'education': 'educ_target',\n",
    "    'social_security': 'social_target',\n",
    "    'housing': 'housing_target',\n",
    "    'food': 'food_target'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4379940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Features available for LASSO selection: 39\n"
     ]
    }
   ],
   "source": [
    "# get features to use (excluding targets, state, year)\n",
    "def get_all_feature_columns(data, target_columns, exclude_cols=['state', 'year']):\n",
    "    return [col for col in data.columns if col not in target_columns + exclude_cols and data[col].dtype in [np.float64, np.int64]]\n",
    "\n",
    "# define a list of all possible features to use - we do it only once since the features are the same for both years\n",
    "all_features = get_all_feature_columns(combined_data, list(POVERTY_DIMENSIONS.values()))\n",
    "\n",
    "print(f\" Features available for LASSO selection: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a9c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape (2022 test set): (32, 47)\n"
     ]
    }
   ],
   "source": [
    "# extract only 2022 data for evaluation - this is identical for both in-sample and out-of-sample evaluation\n",
    "df_test = combined_data[combined_data['year'] == 2022].copy()\n",
    "print(f\"Test data shape (2022 test set): {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19155e",
   "metadata": {},
   "source": [
    "The test sample has 47 columns while with the `get_all_feature_columns` function we selected 39 features, and this is correct since:\n",
    "- we removed the target columns (1 per dimension, so 6 in total)\n",
    "- we removed the year and state columns \n",
    "\n",
    "47 - 8 = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f80958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled dataset shape: (64, 47)\n",
      "income\n",
      "Selected 15 / 39 features\n",
      "health\n",
      "Selected 14 / 39 features\n",
      "education\n",
      "Selected 5 / 39 features\n",
      "social_security\n",
      "Selected 14 / 39 features\n",
      "housing\n",
      "Selected 11 / 39 features\n",
      "food\n",
      "Selected 8 / 39 features\n"
     ]
    }
   ],
   "source": [
    "# SELECT FEATURES WITH LASSO USING THE FULL DATASET\n",
    "\n",
    "# copy the full dataset for scaling\n",
    "df_full = combined_data.copy()\n",
    "\n",
    "# standardize features\n",
    "scaler_global = StandardScaler()\n",
    "X_full_scaled = scaler_global.fit_transform(df_full[all_features])\n",
    "\n",
    "# create a new DataFrame with scaled features\n",
    "df_scaled = pd.DataFrame(X_full_scaled, columns=all_features, index=df_full.index)\n",
    "# add the target columns AND other necessary columns to the scaled DataFrame\n",
    "for dim, target_col in POVERTY_DIMENSIONS.items():\n",
    "    df_scaled[target_col] = df_full[target_col]\n",
    "\n",
    "# add state and year columns for later filtering\n",
    "df_scaled['state'] = df_full['state']\n",
    "df_scaled['year'] = df_full['year']\n",
    "\n",
    "print(f\"Scaled dataset shape: {df_scaled.shape}\")\n",
    "\n",
    "selected_features_in_sample = {}\n",
    "\n",
    "for dim, target in POVERTY_DIMENSIONS.items():\n",
    "    print(f\"{dim}\")\n",
    "    \n",
    "    # use scaled data directly\n",
    "    X_scaled = df_scaled[all_features].values\n",
    "    y = df_scaled[target].values\n",
    "    \n",
    "    # apply LASSO\n",
    "    lasso = Lasso(\n",
    "        random_state=42,\n",
    "        alpha=1,\n",
    "        max_iter=10000\n",
    "    ).fit(X_scaled, y)\n",
    "    \n",
    "    # select features\n",
    "    selected_mask = lasso.coef_ != 0\n",
    "    selected_vars = np.array(all_features)[selected_mask]\n",
    "    selected_features_in_sample[dim] = selected_vars.tolist()\n",
    "    \n",
    "    print(f\"Selected {len(selected_vars)} / {len(all_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f7ffa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacking model for income\n",
      "Results for income:\n",
      "   R² Score: 0.8858\n",
      "   MAE: 3.1034\n",
      "   RF R^2: 0.8735\n",
      "   PLS R^2: 0.6585\n",
      "   Stacking R^2 improvement: 0.0123\n",
      "   RF MAE: 3.5436\n",
      "   PLS MAE: 6.2970\n",
      "   Stacking MAE improvement: 0.4403\n",
      "\n",
      "Stacking model for health\n",
      "Results for health:\n",
      "   R² Score: 0.7761\n",
      "   MAE: 4.8073\n",
      "   RF R^2: 0.8422\n",
      "   PLS R^2: 0.7118\n",
      "   Stacking R^2 improvement: -0.0662\n",
      "   RF MAE: 4.0613\n",
      "   PLS MAE: 5.3771\n",
      "   Stacking MAE improvement: -0.7461\n",
      "\n",
      "Stacking model for education\n",
      "Results for education:\n",
      "   R² Score: 0.7532\n",
      "   MAE: 1.9939\n",
      "   RF R^2: 0.8451\n",
      "   PLS R^2: 0.5678\n",
      "   Stacking R^2 improvement: -0.0919\n",
      "   RF MAE: 1.4137\n",
      "   PLS MAE: 2.7926\n",
      "   Stacking MAE improvement: -0.5803\n",
      "\n",
      "Stacking model for social_security\n",
      "Results for social_security:\n",
      "   R² Score: 0.8791\n",
      "   MAE: 3.7397\n",
      "   RF R^2: 0.8933\n",
      "   PLS R^2: 0.7198\n",
      "   Stacking R^2 improvement: -0.0141\n",
      "   RF MAE: 3.7416\n",
      "   PLS MAE: 5.9417\n",
      "   Stacking MAE improvement: 0.0019\n",
      "\n",
      "Stacking model for housing\n",
      "Results for housing:\n",
      "   R² Score: 0.9337\n",
      "   MAE: 1.9972\n",
      "   RF R^2: 0.9375\n",
      "   PLS R^2: 0.6533\n",
      "   Stacking R^2 improvement: -0.0038\n",
      "   RF MAE: 1.8671\n",
      "   PLS MAE: 4.8738\n",
      "   Stacking MAE improvement: -0.1300\n",
      "\n",
      "Stacking model for food\n",
      "Results for food:\n",
      "   R² Score: 0.8070\n",
      "   MAE: 2.0025\n",
      "   RF R^2: 0.8289\n",
      "   PLS R^2: 0.5790\n",
      "   Stacking R^2 improvement: -0.0219\n",
      "   RF MAE: 1.9560\n",
      "   PLS MAE: 3.3566\n",
      "   Stacking MAE improvement: -0.0466\n"
     ]
    }
   ],
   "source": [
    "# build the stacking model for in-sample validation\n",
    "results_in_sample = {}\n",
    "stacking_models_in_sample = {}\n",
    "\n",
    "for dim, features in selected_features_in_sample.items():\n",
    "    \n",
    "    print(f\"\\nStacking model for {dim}\")\n",
    "    \n",
    "    # prepare training data (2020+2022 combined)\n",
    "    X_train = df_scaled[features].values\n",
    "    y_train = df_scaled[POVERTY_DIMENSIONS[dim]].values\n",
    "    \n",
    "    # prepare test data (2022 only) \n",
    "    df_test_scaled = df_scaled[df_scaled['year'] == 2022]\n",
    "    X_test_scaled = df_test_scaled[features].values\n",
    "    y_test = df_test_scaled[POVERTY_DIMENSIONS[dim]].values\n",
    "    states = df_test_scaled['state'].values\n",
    "    \n",
    "    # define base learners for stacking\n",
    "    base_learners = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, max_depth=4, min_samples_leaf=2, random_state=42)),\n",
    "        ('pls', PLSRegression(n_components=2))]\n",
    "    \n",
    "    # define meta-model\n",
    "    meta_model = LinearRegression()\n",
    "    \n",
    "    # create StackingRegressor, which automatically handles cross-validation to do \n",
    "    # out-of-fold predictions to prevent data leakage\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_learners,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5, \n",
    "        n_jobs=-1)\n",
    "    \n",
    "    # train the stacking model \n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions on test set \n",
    "    y_pred = stacking_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # calculate metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Results for {dim}:\")\n",
    "    print(f\"   R² Score: {r2:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    \n",
    "    # compare with individual models\n",
    "    rf_individual = RandomForestRegressor(n_estimators=100, max_depth=4, min_samples_leaf=2, random_state=42)\n",
    "    pls_individual = PLSRegression(n_components=2)\n",
    "    \n",
    "    rf_individual.fit(X_train, y_train)\n",
    "    pls_individual.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf_individual.predict(X_test_scaled)\n",
    "    y_pred_pls = pls_individual.predict(X_test_scaled)\n",
    "    if len(y_pred_pls.shape) > 1:\n",
    "        y_pred_pls = y_pred_pls.flatten()\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "    r2_pls = r2_score(y_test, y_pred_pls)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    mae_pls = mean_absolute_error(y_test, y_pred_pls)\n",
    "    \n",
    "    print(f\"   RF R^2: {r2_rf:.4f}\")\n",
    "    print(f\"   PLS R^2: {r2_pls:.4f}\")\n",
    "    print(f\"   Stacking R^2 improvement: {r2 - max(r2_rf, r2_pls):.4f}\")\n",
    "    print(f\"   RF MAE: {mae_rf:.4f}\")\n",
    "    print(f\"   PLS MAE: {mae_pls:.4f}\")\n",
    "    print(f\"   Stacking MAE improvement: {min(mae_rf, mae_pls) - mae:.4f}\")\n",
    "    \n",
    "    # store results\n",
    "    results_in_sample[dim] = {\n",
    "        'states': states,\n",
    "        'y_true': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'r2': r2,\n",
    "        'mae': mae}\n",
    "    \n",
    "    # store the model\n",
    "    stacking_models_in_sample[dim] = {\n",
    "        'model': stacking_regressor,\n",
    "        'feature_cols': features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5402585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save metrics, predictions, plots, and LASSO selected features\n",
    "def save_rf_results(results_dict, models_dict, folder_name, selected_features_dict=None):\n",
    "    # create output folder if it doesn't exist\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    # 1. save predictions\n",
    "    # create a DataFrame with true and predicted values for each dimension\n",
    "    preds = {'state': next(iter(results_dict.values()))['states']}  # Extract state list from one example\n",
    "    for dim, res in results_dict.items():\n",
    "        preds[f'{dim}_actual'] = res['y_true']\n",
    "        preds[f'{dim}_predicted'] = res['y_pred']\n",
    "\n",
    "    pd.DataFrame(preds).to_csv(f\"{folder_name}/results.csv\", index=False)\n",
    "\n",
    "    # 2. save metrics and LASSO selected features\n",
    "    rows = []\n",
    "    for dim, res in results_dict.items():\n",
    "        features_used = models_dict[dim]['feature_cols']\n",
    "\n",
    "        # prepare row data\n",
    "        row_data = {\n",
    "            'dimension': dim,\n",
    "            'r2': round(res['r2'], 4),\n",
    "            'mae': round(res['mae'], 4),\n",
    "            'n_selected_features': len(features_used),\n",
    "            'selected_features': ', '.join(features_used)}\n",
    "        rows.append(row_data)\n",
    "\n",
    "    pd.DataFrame(rows).to_csv(f\"{folder_name}/metrics.csv\", index=False)\n",
    "  \n",
    "    # 5. save plots of true vs predicted values for each dimension\n",
    "    for dim, res in results_dict.items():\n",
    "        y_true = res['y_true']\n",
    "        y_pred = res['y_pred']\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.scatter(\n",
    "            y_true, y_pred,\n",
    "            color='royalblue',\n",
    "            edgecolor='black',\n",
    "            s=250,\n",
    "            alpha=0.9)\n",
    "\n",
    "        # diagonal line for perfect predictions\n",
    "        min_val = min(min(y_true), min(y_pred))\n",
    "        max_val = max(max(y_true), max(y_pred))\n",
    "        plt.plot([min_val, max_val], [min_val, max_val],\n",
    "                 'r--', linewidth=3, label='Perfect prediction')\n",
    "\n",
    "        plt.xlabel(\"CONEVAL's statistics\", fontsize=30, fontweight='bold')\n",
    "        plt.ylabel(\"Predicted Values\", fontsize=30, fontweight='bold')\n",
    "        \n",
    "        # title with R² value\n",
    "        title_text = f\"{dim.replace('_', ' ').title()}\\nR² = {res['r2']:.3f}\"\n",
    "        \n",
    "        plt.title(title_text, fontsize=35, fontweight='bold')\n",
    "\n",
    "        plt.xticks(fontsize=20, fontweight='bold')\n",
    "        plt.yticks(fontsize=20, fontweight='bold')\n",
    "        plt.legend(fontsize=25)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(f\"{folder_name}/{dim}_plot.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "save_rf_results(results_in_sample, stacking_models_in_sample, folder_name='in_sample_val',\n",
    "                selected_features_dict=selected_features_in_sample)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de17805",
   "metadata": {},
   "source": [
    "## Out-of-Sample Validation\n",
    "\n",
    "To assess the model’s **true generalization capacity**, we adopt an **out-of-sample validation strategy**, where training is performed exclusively on 2020 data and predictions are evaluated on 2022.\n",
    "\n",
    "This approach simulates a realistic scenario in which we aim to **nowcast multidimensional poverty** using recent data, but the official CONEVAL statistics for the current year are not yet available. In such cases, we must rely on available statistics about previous years to train the model and then apply it to newer, unlabeled observations.\n",
    "\n",
    "Beyond its practical relevance, this setup also provides a meaningful **robustness check**: can a model trained on one year generalize to a different temporal context, especially when social and economic conditions have changed?\n",
    "\n",
    "This question is particularly important in our setting, as the two years under consideration — 2020 and 2022 — are structurally different. **The year 2020 was dominated by the COVID-19 pandemic**, with widespread disruptions to health systems, labor markets, and mobility. In contrast, **2022 reflects a post-pandemic recovery phase**, where most economic and social indicators began to stabilize. \n",
    "\n",
    "By testing our models across such heterogeneous contexts, we can assess whether they are merely fitting year-specific noise, or whether they are capturing **deeper, structural patterns of poverty** that persist despite short-term shocks. In this sense, out-of-sample validation serves not only as a forecast test, but also as a diagnostic tool for evaluating the temporal robustness of the modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27aca1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled 2020 dataset shape: (32, 45)\n",
      "income\n",
      "Selected 11 / 39 features\n",
      "health\n",
      "Selected 10 / 39 features\n",
      "education\n",
      "Selected 8 / 39 features\n",
      "social_security\n",
      "Selected 14 / 39 features\n",
      "housing\n",
      "Selected 17 / 39 features\n",
      "food\n",
      "Selected 7 / 39 features\n"
     ]
    }
   ],
   "source": [
    "# SELECT FEATURES WITH LASSO USING ONLY 2020 DATA\n",
    "\n",
    "# copy the 2020 dataset for scaling\n",
    "df_full_2020 = data_2020.copy()\n",
    "\n",
    "# standardize features using only 2020 data\n",
    "scaler_global_2020 = StandardScaler()\n",
    "X_full_scaled_2020 = scaler_global_2020.fit_transform(df_full_2020[all_features])\n",
    "\n",
    "# create a new DataFrame with scaled features (only 2020 data)\n",
    "df_scaled_2020 = pd.DataFrame(X_full_scaled_2020, columns=all_features, index=df_full_2020.index)\n",
    "# add the target columns to the scaled DataFrame\n",
    "for dim, target_col in POVERTY_DIMENSIONS.items():\n",
    "    df_scaled_2020[target_col] = df_full_2020[target_col]\n",
    "\n",
    "print(f\"Scaled 2020 dataset shape: {df_scaled_2020.shape}\")\n",
    "\n",
    "# feature selection using LASSO on 2020 data only\n",
    "selected_features_out_sample = {}\n",
    "\n",
    "for dim, target in POVERTY_DIMENSIONS.items():\n",
    "    print(f\"{dim}\")\n",
    "    \n",
    "    # use scaled 2020 data only\n",
    "    X_scaled = df_scaled_2020[all_features].values\n",
    "    y = df_scaled_2020[target].values\n",
    "    \n",
    "    # apply LASSO \n",
    "    lasso = Lasso(\n",
    "        random_state=42,\n",
    "        alpha=1,  \n",
    "        max_iter=10000\n",
    "    ).fit(X_scaled, y)\n",
    "    \n",
    "    # select features\n",
    "    selected_mask = lasso.coef_ != 0\n",
    "    selected_vars = np.array(all_features)[selected_mask]\n",
    "    selected_features_out_sample[dim] = selected_vars.tolist()\n",
    "    \n",
    "    print(f\"Selected {len(selected_vars)} / {len(all_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3372ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacking model for income\n",
      "Results for income:\n",
      "   R² Score: 0.1905\n",
      "   MAE: 9.4415\n",
      "   RF R^2: 0.1278\n",
      "   PLS R^2: -0.2666\n",
      "   Stacking R^2 improvement: 0.0627\n",
      "   RF MAE: 10.1872\n",
      "   PLS MAE: 12.3105\n",
      "   Stacking MAE improvement: 0.7456\n",
      "\n",
      "Stacking model for health\n",
      "Results for health:\n",
      "   R² Score: -0.5593\n",
      "   MAE: 11.4766\n",
      "   RF R^2: -0.6139\n",
      "   PLS R^2: -0.3913\n",
      "   Stacking R^2 improvement: -0.1680\n",
      "   RF MAE: 11.9381\n",
      "   PLS MAE: 10.7933\n",
      "   Stacking MAE improvement: -0.6833\n",
      "\n",
      "Stacking model for education\n",
      "Results for education:\n",
      "   R² Score: 0.3689\n",
      "   MAE: 3.2688\n",
      "   RF R^2: 0.2882\n",
      "   PLS R^2: 0.2226\n",
      "   Stacking R^2 improvement: 0.0807\n",
      "   RF MAE: 3.4427\n",
      "   PLS MAE: 3.5592\n",
      "   Stacking MAE improvement: 0.1738\n",
      "\n",
      "Stacking model for social_security\n",
      "Results for social_security:\n",
      "   R² Score: 0.3371\n",
      "   MAE: 8.9727\n",
      "   RF R^2: 0.2670\n",
      "   PLS R^2: 0.2785\n",
      "   Stacking R^2 improvement: 0.0586\n",
      "   RF MAE: 9.9654\n",
      "   PLS MAE: 9.5260\n",
      "   Stacking MAE improvement: 0.5533\n",
      "\n",
      "Stacking model for housing\n",
      "Results for housing:\n",
      "   R² Score: 0.5586\n",
      "   MAE: 5.3072\n",
      "   RF R^2: 0.6086\n",
      "   PLS R^2: -0.0763\n",
      "   Stacking R^2 improvement: -0.0500\n",
      "   RF MAE: 4.8644\n",
      "   PLS MAE: 8.6148\n",
      "   Stacking MAE improvement: -0.4428\n",
      "\n",
      "Stacking model for food\n",
      "Results for food:\n",
      "   R² Score: 0.1231\n",
      "   MAE: 4.3816\n",
      "   RF R^2: 0.1708\n",
      "   PLS R^2: -0.1159\n",
      "   Stacking R^2 improvement: -0.0478\n",
      "   RF MAE: 4.2302\n",
      "   PLS MAE: 5.1696\n",
      "   Stacking MAE improvement: -0.1514\n"
     ]
    }
   ],
   "source": [
    "# build the stacking model for out-of-sample validation \n",
    "results_out_sample = {}\n",
    "stacking_models_out_sample = {}\n",
    "\n",
    "for dim, features in selected_features_out_sample.items():\n",
    "    \n",
    "    print(f\"\\nStacking model for {dim}\")\n",
    "    \n",
    "    # prepare training data \n",
    "    X_train = df_scaled_2020[features].values  \n",
    "    y_train = df_scaled_2020[POVERTY_DIMENSIONS[dim]].values\n",
    "    \n",
    "    # prepare test data \n",
    "    X_test_original = df_test[features].values\n",
    "    y_test = df_test[POVERTY_DIMENSIONS[dim]].values\n",
    "    states = df_test['state'].values\n",
    "    \n",
    "    # scale test data using the 2020-only scaler\n",
    "    X_test_all_scaled = scaler_global_2020.transform(df_test[all_features])\n",
    "    \n",
    "    # select only the features needed for this dimension - according to LASSO selection\n",
    "    feature_indices = [all_features.index(f) for f in features]\n",
    "    X_test_scaled = X_test_all_scaled[:, feature_indices]\n",
    "    \n",
    "    # define base learners\n",
    "    base_learners = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, max_depth=4, min_samples_leaf=2, random_state=42)),\n",
    "        ('pls', PLSRegression(n_components=2))]\n",
    "    \n",
    "    # define meta-model\n",
    "    meta_model = LinearRegression()\n",
    "    \n",
    "    # create StackingRegressor \n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_learners,\n",
    "        final_estimator=meta_model,\n",
    "        cv=5,  \n",
    "        n_jobs=-1)\n",
    "    \n",
    "    # train the stacking model on 2020 data only\n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions on 2022 test set\n",
    "    y_pred = stacking_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # calculate metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Results for {dim}:\")\n",
    "    print(f\"   R² Score: {r2:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    \n",
    "    # compare with individual models \n",
    "    rf_individual = RandomForestRegressor(n_estimators=100, max_depth=4, min_samples_leaf=2, random_state=42)\n",
    "    pls_individual = PLSRegression(n_components=2)\n",
    "    \n",
    "    rf_individual.fit(X_train, y_train)\n",
    "    pls_individual.fit(X_train, y_train)\n",
    "    \n",
    "    # predict on 2022 test set\n",
    "    y_pred_rf = rf_individual.predict(X_test_scaled)\n",
    "    y_pred_pls = pls_individual.predict(X_test_scaled)\n",
    "    if len(y_pred_pls.shape) > 1:\n",
    "        y_pred_pls = y_pred_pls.flatten()\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_pred_rf)\n",
    "    r2_pls = r2_score(y_test, y_pred_pls)\n",
    "    mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "    mae_pls = mean_absolute_error(y_test, y_pred_pls)\n",
    "    \n",
    "    print(f\"   RF R^2: {r2_rf:.4f}\")\n",
    "    print(f\"   PLS R^2: {r2_pls:.4f}\")\n",
    "    print(f\"   Stacking R^2 improvement: {r2 - max(r2_rf, r2_pls):.4f}\")\n",
    "    print(f\"   RF MAE: {mae_rf:.4f}\")\n",
    "    print(f\"   PLS MAE: {mae_pls:.4f}\") \n",
    "    print(f\"   Stacking MAE improvement: {min(mae_rf, mae_pls) - mae:.4f}\")\n",
    "    \n",
    "    # store results\n",
    "    results_out_sample[dim] = {\n",
    "        'states': states,\n",
    "        'y_true': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'r2': r2,\n",
    "        'mae': mae}\n",
    "    \n",
    "    # store model\n",
    "    stacking_models_out_sample[dim] = {\n",
    "        'model': stacking_regressor,\n",
    "        'feature_cols': features}\n",
    "\n",
    "save_rf_results(results_out_sample, stacking_models_out_sample, folder_name='out_sample_val',\n",
    "                selected_features_dict=selected_features_out_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afaa52b",
   "metadata": {},
   "source": [
    "# Construction of the *Social Cohesion* Index (2022) using PCA\n",
    "\n",
    "Since we do not have a direct target variable to measure social cohesion, we apply an **unsupervised method** based on **Principal Component Analysis (PCA)** to extract a latent index that summarizes the information from a set of proxy variables.\n",
    "\n",
    "## Data Selection and Preprocessing\n",
    "\n",
    "We select all variables in the dataset whose names contain the word `\"cohesion\"`. These are the components we previously constructed from different textual data sources (YouTube, Telegram, News, Google Trends) to capture aspects of social cohesion. Each of these variables reflects a proxy derived from textual analysis, so these are not raw inputs but already-processed indicators explicitly built to inform the social cohesion dimension. \n",
    "\n",
    "To ensure comparability across variables and to satisfy PCA assumptions, we standardize the selected features using `StandardScaler`, which centers them around zero and rescales them to unit variance.\n",
    "\n",
    "## PCA: Extracting the Latent Dimension\n",
    "\n",
    "We perform a PCA and retain only the **first principal component (PC1)**. This component captures the direction of maximum variance in the standardized feature space. Since all selected features aim to reflect some aspect of social cohesion, PC1 can be interpreted as a **latent index** summarizing the shared signal across them.\n",
    "\n",
    "We chose this approach because:\n",
    "\n",
    "- By reducing dimensionality, we capture the dominant underlying pattern in a single score.\n",
    "- Since we don't have a target for this dimension, our possibilities were limited but we still believe this approach allows to define weights in a robust and non-arbitrary way\n",
    "- Reflects the empirical correlation structure of the data, which is appropriate in the absence of a predefined ground truth.\n",
    "\n",
    "## Handle the Sign\n",
    "\n",
    "One limitation of PCA is that the sign of the components is not uniquely identified — multiplying all loadings and scores by -1 yields an equivalent solution.\n",
    "\n",
    "To ensure consistency in interpretation (i.e., **higher scores mean worse social cohesion**), we compute the **sum of the loadings** for the first component:\n",
    "- If the sum is **negative**, it means that high raw scores are associated with **better** social cohesion. In this case, we **invert the sign** of the PCA scores so that higher values reflect **higher deprivation**.\n",
    "- If the sum is **positive**, we keep the scores as they are.\n",
    "\n",
    "This correction guarantees that a value of 100 consistently means \"lowest social cohesion\" — in line with the interpretation of other poverty indicators.\n",
    "\n",
    "## Normalization to a 0–100 Scale\n",
    "\n",
    "After sign correction, the scores are normalized to a 0–100 scale using `MinMaxScaler`. This is aligned with the conventions adopted by CONEVAL and our other dimensional estimates, which express deprivation as a **percentage of the population** affected.\n",
    "\n",
    "The resulting index can thus be interpreted as a relative measure of social cohesion deprivation, comparable across Mexican states.\n",
    "\n",
    "## Observed Anomalies: 5 States with Extreme Values\n",
    "\n",
    "In the final normalized scores, we observe the presence of unrealistic values:\n",
    "- One state receives a score of exactly **0**.\n",
    "- Four states have scores **above 80**, with one state reaching exactly **100**.\n",
    "\n",
    "While these results are not computationally incorrect, they may appear questionable — especially given that we do not observe such extreme values in any of the other dimensions. However, several technical factors can explain this behavior:\n",
    "\n",
    "- **Outliers in the original features**: some states may exhibit near-zero values across multiple cohesion-related components, particularly in cases where textual data coverage was sparse or unbalanced. This can drive their PCA score toward the lower bound of the distribution.\n",
    "\n",
    "- **High-leverage observations**: PCA is inherently sensitive to atypical combinations of feature values. A single state with an unusual profile — even if not extreme in any single component — can strongly influence the orientation of the principal component and receive a disproportionately high or low score.\n",
    "\n",
    "- **Scaling effects**: the use of `MinMaxScaler` maps the minimum and maximum PCA scores to 0 and 100 by design. As a result, there will always be at least one state assigned **0** and one assigned **100**, regardless of how realistic those values are in substantive terms.\n",
    "\n",
    "Ultimately, these extreme scores should be interpreted as **relative positions**: they indicate how a state ranks within the empirical distribution of social cohesion *as captured by the PCA*, rather than representing absolute levels of deprivation. A score of 100 does not imply that 100% of the population experiences cohesion poverty — it simply reflects that the state ranks at the very bottom in relative terms.\n",
    "\n",
    "To avoid producing exact 0 and 100 values, one option would have been to restrict the output range during normalization, for example:\n",
    "\n",
    "```python\n",
    "scaler_pct = MinMaxScaler(feature_range=(5, 80))\n",
    "````\n",
    "\n",
    "However, we opted not to implement this adjustment, for two main reasons:\n",
    "\n",
    "- The choice of an alternative range would have been arbitrary and thus methodologically debatable;\n",
    "- Compressing the score range would have reduced the spread of the values, limiting the model's ability to differentiate between intermediate cases.\n",
    "\n",
    "We therefore retained the full [0, 100] scale, acknowledging that the extremes reflect model mechanics as much as underlying variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da9c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA loadings (PC1):\n",
      "cohesion_gt: -0.382\n",
      "social_cohesion_avg_sentiment: -0.373\n",
      "social_cohesion_pct_yt: 0.619\n",
      "social_cohesion_pct_tg: 0.576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>social_cohesion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2022</td>\n",
       "      <td>34.618119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baja California</td>\n",
       "      <td>2022</td>\n",
       "      <td>88.612437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baja California Sur</td>\n",
       "      <td>2022</td>\n",
       "      <td>43.232871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Campeche</td>\n",
       "      <td>2022</td>\n",
       "      <td>16.569366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coahuila</td>\n",
       "      <td>2022</td>\n",
       "      <td>41.210944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colima</td>\n",
       "      <td>2022</td>\n",
       "      <td>31.376835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chiapas</td>\n",
       "      <td>2022</td>\n",
       "      <td>92.302337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>2022</td>\n",
       "      <td>24.930064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>2022</td>\n",
       "      <td>24.701380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Durango</td>\n",
       "      <td>2022</td>\n",
       "      <td>36.179750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 state  year  social_cohesion_score\n",
       "0       Aguascalientes  2022              34.618119\n",
       "1      Baja California  2022              88.612437\n",
       "2  Baja California Sur  2022              43.232871\n",
       "3             Campeche  2022              16.569366\n",
       "4             Coahuila  2022              41.210944\n",
       "5               Colima  2022              31.376835\n",
       "6              Chiapas  2022              92.302337\n",
       "7            Chihuahua  2022              24.930064\n",
       "8     Ciudad de México  2022              24.701380\n",
       "9              Durango  2022              36.179750"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select social cohesion features\n",
    "social_features = [col for col in data_2022.columns if 'cohesion' in col.lower()]\n",
    "X_social_2022 = data_2022[social_features].dropna()\n",
    "\n",
    "# standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_2022 = scaler.fit_transform(X_social_2022)\n",
    "\n",
    "# PCA to extract the first component\n",
    "pca = PCA(n_components=1)\n",
    "social_cohesion_score_2022 = pca.fit_transform(X_scaled_2022)\n",
    "\n",
    "# get and print loadings \n",
    "loadings = dict(zip(social_features, pca.components_[0]))\n",
    "print(\"PCA loadings (PC1):\")\n",
    "for feature, weight in loadings.items():\n",
    "    print(f\"{feature}: {weight:.3f}\")\n",
    "\n",
    "# invert the sign of the PCA scores if necessary\n",
    "# (this is to ensure that a higher score indicates worse cohesion)\n",
    "# (if the sum of loadings is negative, invert the sign to have: 100 = worst cohesion)\n",
    "if np.sum(pca.components_[0]) < 0:\n",
    "    print(\" inverting sign of PCA scores to have: 100 = worse cohesion\")\n",
    "    social_cohesion_score_2022 = -social_cohesion_score_2022\n",
    "\n",
    "# normalize the scores to a 0-100 scale\n",
    "scaler_pct = MinMaxScaler(feature_range=(0, 100))\n",
    "social_cohesion_normalized = scaler_pct.fit_transform(social_cohesion_score_2022)\n",
    "\n",
    "# final df \n",
    "cohesion_df = data_2022.loc[X_social_2022.index, ['state', 'year']].copy()\n",
    "cohesion_df['social_cohesion_score'] = social_cohesion_normalized\n",
    "\n",
    "# save \n",
    "os.makedirs(\"PCA\", exist_ok=True)\n",
    "cohesion_df.to_csv(\"PCA/score.csv\", index=False)\n",
    "\n",
    "cohesion_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
