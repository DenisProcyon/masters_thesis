{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef996967",
   "metadata": {},
   "source": [
    "# YouTube Analysis for Multidimensional Poverty Classification in Mexico\n",
    "\n",
    "This implementation creates a text classification system to analyze YouTube comments and categorize content according to multidimensional poverty dimensions. The analysis follows CONEVAL's (Consejo Nacional de Evaluación de la Política de Desarrollo Social) framework with adaptations for real-time social media data.\n",
    "\n",
    "We examine seven key dimensions of multidimensional poverty:\n",
    "\n",
    "- **Income**: Employment status, wages, economic instability, unemployment\n",
    "- **Access to Health Services**: Healthcare availability, medical infrastructure, health insurance\n",
    "- **Educational Lag**: School dropout rates, educational access, academic delays\n",
    "- **Access to Social Security**: Labor protection, social benefits, pension systems\n",
    "- **Housing**: Living conditions, basic utilities (water, electricity), housing quality\n",
    "- **Access to Food**: Food security, nutrition, food prices, hunger\n",
    "- **Social Cohesion**: Community integration, discrimination, social exclusion, belonging\n",
    "\n",
    "## Technical Methodology\n",
    "\n",
    "### 1. Data Collection\n",
    "\n",
    "**Search Parameters:**\n",
    "- **Temporal Scope**: Full year analysis (2022: January 1 - December 31)\n",
    "- **Geographic Coverage**: All 32 Mexican states\n",
    "- **Search Terms**: State name + [\"noticias\", \"news\", \"economía\"] (3 queries per state)\n",
    "- **Volume Limits**: 100 videos per query, 300 comments per video\n",
    "- **Language Priority**: Spanish content prioritized via `relevanceLanguage=\"es\"`\n",
    "\n",
    "### 2. Text Preprocessing\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "1. **HTML/Markup Removal**: Strip HTML tags and web links\n",
    "2. **Character Normalization**: Preserve only alphanumeric + Spanish accented characters\n",
    "3. **Whitespace Normalization**: Remove extra spaces, convert to lowercase\n",
    "4. **Length Filtering**: Exclude texts shorter than 10 characters\n",
    "\n",
    "### 3. Embedding and Classification\n",
    "\n",
    "**Embedding Generation:**\n",
    "- **Model**: `paraphrase-multilingual-MiniLM-L12-v2` (768-dimensional embeddings)\n",
    "- **Language Support**: Optimized for Spanish, English, and mixed-language content\n",
    "- **Dimension Preprocessing**: Convert keyword lists to normalized text phrases for embedding\n",
    "\n",
    "**Classification Logic:**\n",
    "1. Generate embeddings for both input text and poverty dimension definitions\n",
    "2. Calculate cosine similarity between text and all dimension embeddings\n",
    "3. Assign text to highest-scoring dimension if score ≥ 0.10 threshold\n",
    "4. Classify as \"OTHER\" if below threshold (filters non-poverty content)\n",
    "\n",
    "### 4. Sentiment Analysis \n",
    "\n",
    "**Model**: `nlptown/bert-base-multilingual-uncased-sentiment`\n",
    "- **Input**: Raw text (max 512 tokens with truncation)\n",
    "- **Output**: 5-star rating scale converted to normalized sentiment\n",
    "- **Normalization**: 1 star = -1.0, 3 stars = 0.0, 5 stars = +1.0\n",
    "\n",
    "### 5. Extracted Components\n",
    "\n",
    "**State-Level Metrics:**\n",
    "- **Dimension Coverage**: Percentage of comments per poverty dimension\n",
    "- **Conditional Sentiment**: Average sentiment score per dimension per state\n",
    "- **General Statistics**: Total videos and comments analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c14129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "YT_API_KEY = os.getenv(\"YT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65254ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping of Mexican states with their corresponding search terms\n",
    "STATES_SEARCH_TERMS = {\n",
    "    \"Aguascalientes\": [\"Aguascalientes noticias\", \"Aguascalientes news\", \"Aguascalientes economía\"],\n",
    "    \"Baja California\": [\"Baja California noticias\", \"Baja California news\", \"Baja California economía\"],\n",
    "    \"Baja California Sur\": [\"Baja California Sur noticias\", \"Baja California Sur news\", \"Baja California Sur economía\"],\n",
    "    \"Campeche\": [\"Campeche noticias\", \"Campeche news\", \"Campeche economía\"],\n",
    "    \"Chiapas\": [\"Chiapas noticias\", \"Chiapas news\", \"Chiapas economía\"],\n",
    "    \"Chihuahua\": [\"Chihuahua noticias\", \"Chihuahua news\", \"Chihuahua economía\"],\n",
    "    \"Ciudad de México\": [\"Ciudad de México noticias\", \"Ciudad de México news\", \"Ciudad de México economía\"],\n",
    "    \"Coahuila\": [\"Coahuila noticias\", \"Coahuila news\", \"Coahuila economía\"],\n",
    "    \"Colima\": [\"Colima noticias\", \"Colima news\", \"Colima economía\"],\n",
    "    \"Durango\": [\"Durango noticias\", \"Durango news\", \"Durango economía\"],\n",
    "    \"Estado de México\": [\"Estado de México noticias\", \"Estado de México news\", \"Estado de México economía\"],\n",
    "    \"Guanajuato\": [\"Guanajuato noticias\", \"Guanajuato news\", \"Guanajuato economía\"],\n",
    "    \"Guerrero\": [\"Guerrero noticias\", \"Guerrero news\", \"Guerrero economía\"],\n",
    "    \"Hidalgo\": [\"Hidalgo noticias\", \"Hidalgo news\", \"Hidalgo economía\"],\n",
    "    \"Jalisco\": [\"Jalisco noticias\", \"Jalisco news\", \"Jalisco economía\"],\n",
    "    \"Michoacán\": [\"Michoacán noticias\", \"Michoacán news\", \"Michoacán economía\"],\n",
    "    \"Morelos\": [\"Morelos noticias\", \"Morelos news\", \"Morelos economía\"],\n",
    "    \"Nayarit\": [\"Nayarit noticias\", \"Nayarit news\", \"Nayarit economía\"],\n",
    "    \"Nuevo León\": [\"Nuevo León noticias\", \"Nuevo León news\", \"Nuevo León economía\"],\n",
    "    \"Oaxaca\": [\"Oaxaca noticias\", \"Oaxaca news\", \"Oaxaca economía\"],\n",
    "    \"Puebla\": [\"Puebla noticias\", \"Puebla news\", \"Puebla economía\"],\n",
    "    \"Querétaro\": [\"Querétaro noticias\", \"Querétaro news\", \"Querétaro economía\"],\n",
    "    \"Quintana Roo\": [\"Quintana Roo noticias\", \"Quintana Roo news\", \"Quintana Roo economía\"],\n",
    "    \"San Luis Potosí\": [\"San Luis Potosí noticias\", \"San Luis Potosí news\", \"San Luis Potosí economía\"],\n",
    "    \"Sinaloa\": [\"Sinaloa noticias\", \"Sinaloa news\", \"Sinaloa economía\"],\n",
    "    \"Sonora\": [\"Sonora noticias\", \"Sonora news\", \"Sonora economía\"],\n",
    "    \"Tabasco\": [\"Tabasco noticias\", \"Tabasco news\", \"Tabasco economía\"],\n",
    "    \"Tamaulipas\": [\"Tamaulipas noticias\", \"Tamaulipas news\", \"Tamaulipas economía\"],\n",
    "    \"Tlaxcala\": [\"Tlaxcala noticias\", \"Tlaxcala news\", \"Tlaxcala economía\"],\n",
    "    \"Veracruz\": [\"Veracruz noticias\", \"Veracruz news\", \"Veracruz economía\"],\n",
    "    \"Yucatán\": [\"Yucatán noticias\", \"Yucatán news\", \"Yucatán economía\"],\n",
    "    \"Zacatecas\": [\"Zacatecas noticias\", \"Zacatecas news\", \"Zacatecas economía\"]}\n",
    "\n",
    "# Poverty dimension definitions with keywords. Each dimension contains a mix of formal Spanish terms, \n",
    "# Mexican slang, and English words to capture the diverse jargon used in YouTube comments\n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"\"\"\n",
    "    empleo trabajo salario ingresos dinero economía sueldo ahorro impuestos\n",
    "    chamba lana nómina billete jale job salary income money\n",
    "    \"\"\",\n",
    "    \n",
    "    \"ACCESS TO HEALTH SERVICES\": \"\"\"\n",
    "    salud médico hospital medicina tratamiento atención clínica seguro\n",
    "    sistema de salud servicios médicos doctor cuidado ir al doctor health insurance\n",
    "    seguro médico doctor particular ir a consulta healthcare medical treatment \n",
    "    \"\"\",\n",
    "    \n",
    "    \"EDUCATIONAL LAG\": \"\"\"\n",
    "    educación escuela universidad maestro estudiante aprendizaje escuela pública\n",
    "    clases formación conocimiento título bachillerato preparatoria escuela secundaria\n",
    "    \"\"\",\n",
    "    \n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"\"\"\n",
    "    seguridad social pensión jubilación contrato derechos laborales\n",
    "    prestaciones protección IMSS ISSSTE afore finiquito ahorro para retiro\n",
    "    cotizar retirement benefits social security worker rights informal job\n",
    "    \"\"\",\n",
    "    \n",
    "    \"HOUSING\": \"\"\"\n",
    "    vivienda casa habitación hogar alquiler renta depa housing utilities\n",
    "    servicios agua luz gas electricidad construcción propiedad rent \n",
    "    techo colonia vecindario urbanización asentamiento cuartito mortgage\n",
    "    \"\"\",\n",
    "    \n",
    "    \"ACCESS TO FOOD\": \"\"\"\n",
    "    alimentación comida nutrición alimentos dieta cocinar recetas\n",
    "    canasta básica food security nutrition meal groceries\n",
    "    comida saludable dieta balanceada comida rápida comida chatarra\n",
    "    \"\"\",\n",
    "    \n",
    "    \"SOCIAL COHESION\": \"\"\"\n",
    "    comunidad sociedad integración participación convivencia barrio raza community\n",
    "    respeto diversidad solidaridad inclusión pertenencia \n",
    "    vecinos apoyo redes sociales confianza belonging inclusion\n",
    "    \"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1255cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence threshold: comments with similarity scores below this threshold will be classified as 'OTHER'\n",
    "MIN_DIMENSION_CONFIDENCE = 0.10\n",
    "\n",
    "# define constants for YouTube API usage\n",
    "MAX_VIDEOS_PER_SEARCH = 100  \n",
    "MAX_COMMENTS_PER_VIDEO = 300  \n",
    "API_SLEEP_TIME = 0.5  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679289b8",
   "metadata": {},
   "source": [
    "### SimpleTextProcessor\n",
    "**Purpose**: Handles text preprocessing, dimension classification, and sentiment analysis\n",
    "\n",
    "**Key Methods:**\n",
    "- `clean_text()`: Normalizes and cleans input text\n",
    "- `classify_dimension()`: Assigns text to poverty dimensions using embeddings\n",
    "- `get_sentiment_score()`: Computes normalized sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59091d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  preprocess the text, classify into dimensions, compute conditional sentiment score. \n",
    "class SimpleTextProcessor:\n",
    "    def __init__(self):\n",
    "        # initialize the multilingual sentence transformer. This model works well with Spanish, English, and mixed-language content.\n",
    "        self.embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        \n",
    "        # load pre-trained sentiment analysis model. This model outputs a score between 1 and 5, which we normalize to the scale -1 to 1.\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "        \n",
    "        # prepare dimension names and their corresponding keyword phrases\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.dimension_texts = []\n",
    "        \n",
    "        # clean formatting: remove extra spaces and handle indentation\n",
    "        for keywords in POVERTY_DIMENSIONS.values():\n",
    "            word_list = keywords.strip().split()\n",
    "            phrase = \" \".join(word_list)\n",
    "            self.dimension_texts.append(phrase)\n",
    "        \n",
    "        # pre-compute embeddings for all poverty dimensions\n",
    "        self.dimension_embeddings = self.embedder.encode(self.dimension_texts, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        # remove HTML tags \n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        \n",
    "        # remove URLs and links\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        \n",
    "        # keep only word characters, spaces, and Spanish accented characters\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        \n",
    "        # normalize whitespace and convert to lowercase\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "\n",
    "\n",
    "    def classify_dimension(self, text):\n",
    "        if not text:\n",
    "            return \"OTHER\", 0.0\n",
    "        \n",
    "        # generate embedding for the input text\n",
    "        embedding = self.embedder.encode(text, convert_to_tensor=True)\n",
    "        \n",
    "        # calculate cosine similarity with all dimension embeddings\n",
    "        cosine_scores = util.cos_sim(embedding, self.dimension_embeddings)[0]\n",
    "        \n",
    "        # find the dimension with highest similarity\n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        max_score = cosine_scores[max_idx].item()\n",
    "        \n",
    "        # apply confidence threshold to filter out irrelevant content - assign \"OTHER\" if score is too low\n",
    "        if max_score < MIN_DIMENSION_CONFIDENCE:\n",
    "            return \"OTHER\", max_score\n",
    "        \n",
    "        return self.dimension_names[max_idx], max_score\n",
    "\n",
    "    def get_sentiment_score(self, text):\n",
    "        if not text:\n",
    "            return 0.0\n",
    "        \n",
    "        # tokenize input with truncation to handle long texts\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # get model predictions without gradient computation\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # convert logits to star rating (1-5 stars)\n",
    "        stars = torch.argmax(outputs.logits, dim=1).item() + 1\n",
    "        \n",
    "        # normalize to sentiment score: 1 star = -1, 3 stars = 0, 5 stars = 1\n",
    "        return (stars - 3) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a851e",
   "metadata": {},
   "source": [
    "### SimpleYouTubeAnalyzer  \n",
    "**Purpose**: Manages YouTube API interactions and orchestrates analysis pipeline\n",
    "\n",
    "**Key Methods:**\n",
    "- `search_videos()`: Retrieves videos based on search terms and date range\n",
    "- `get_video_comments()`: Extracts comments from individual videos\n",
    "- `analyze_state_by_keywords()`: Processes complete state analysis workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle YouTube API interactions and content analysis. \n",
    "class SimpleYouTubeAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "        self.processor = SimpleTextProcessor()\n",
    "\n",
    "    # search for videos on YouTube based on a query and date range\n",
    "    def search_videos(self, query, published_after, published_before, max_results=100):\n",
    "        videos = []\n",
    "        next_page_token = None\n",
    "        \n",
    "        try:\n",
    "            while len(videos) < max_results:\n",
    "                # request videos from YouTube API with pagination\n",
    "                response = self.youtube.search().list(\n",
    "                    q=query,\n",
    "                    part=\"snippet\",\n",
    "                    maxResults=min(50, max_results - len(videos)),  # API limit is 50 per request\n",
    "                    pageToken=next_page_token,\n",
    "                    type=\"video\",\n",
    "                    order=\"relevance\",\n",
    "                    publishedAfter=published_after,\n",
    "                    publishedBefore=published_before,\n",
    "                    relevanceLanguage=\"es\"  # prioritize Spanish content\n",
    "                ).execute()\n",
    "                \n",
    "                # extract video information from API response\n",
    "                for item in response.get(\"items\", []):\n",
    "                    if item[\"id\"][\"kind\"] == \"youtube#video\":\n",
    "                        videos.append({\n",
    "                            \"id\": item[\"id\"][\"videoId\"],\n",
    "                            \"title\": item[\"snippet\"][\"title\"],\n",
    "                            \"description\": item[\"snippet\"].get(\"description\", \"\"),\n",
    "                            \"published_at\": item[\"snippet\"][\"publishedAt\"]\n",
    "                        })\n",
    "                \n",
    "                # check if more pages are available\n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token or len(videos) >= max_results:\n",
    "                    break\n",
    "                \n",
    "                # small pause to avoid quota issues\n",
    "                sleep(API_SLEEP_TIME)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{query}': {e}\")\n",
    "        \n",
    "        print(f\"Found {len(videos)} videos for query '{query}'\")\n",
    "        return videos\n",
    "\n",
    "    # retrieve comments for a specific video\n",
    "    def get_video_comments(self, video_id, max_comments=300):\n",
    "        comments = []\n",
    "        next_page_token = None\n",
    "        \n",
    "        try:\n",
    "            while len(comments) < max_comments:\n",
    "                # request comments with pagination support\n",
    "                response = self.youtube.commentThreads().list(\n",
    "                    part=\"snippet\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=min(100, max_comments - len(comments)),  # API limit is 100 per request\n",
    "                    pageToken=next_page_token\n",
    "                ).execute()\n",
    "                \n",
    "                # extract comment text from API response\n",
    "                for item in response.get(\"items\", []):\n",
    "                    comment_text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                    comments.append(comment_text)\n",
    "                \n",
    "                # check for additional pages\n",
    "                next_page_token = response.get(\"nextPageToken\")\n",
    "                if not next_page_token or len(comments) >= max_comments:\n",
    "                    break\n",
    "                \n",
    "                # pause to avoid quota issues \n",
    "                sleep(API_SLEEP_TIME)\n",
    "                \n",
    "        except Exception as e:\n",
    "            # hanlde videos that have disabled comments\n",
    "            pass\n",
    "        \n",
    "        return comments\n",
    "\n",
    "    def analyze_state_by_keywords(self, state_name, search_terms, date_range):\n",
    "        print(f\"\\nAnalyzing {state_name}...\")\n",
    "        \n",
    "        # initialize statistics tracking for all categories and 'OTHER'\n",
    "        all_categories = list(POVERTY_DIMENSIONS.keys()) + [\"OTHER\"]\n",
    "        dimension_stats = {cat: {\"sentiment_sum\": 0.0, \"count\": 0} for cat in all_categories}\n",
    "        \n",
    "        total_videos = 0\n",
    "        total_comments = 0\n",
    "        classification_stats = {cat: 0 for cat in all_categories}\n",
    "        \n",
    "        # process each search term for the current state\n",
    "        for search_term in search_terms:\n",
    "            print(f\"  Searching for '{search_term}'...\")\n",
    "            \n",
    "            # get relevant videos for this search term\n",
    "            videos = self.search_videos(\n",
    "                query=search_term,\n",
    "                published_after=date_range[\"published_after\"],\n",
    "                published_before=date_range[\"published_before\"],\n",
    "                max_results=MAX_VIDEOS_PER_SEARCH\n",
    "            )\n",
    "            \n",
    "            if not videos:\n",
    "                continue\n",
    "                \n",
    "            total_videos += len(videos)\n",
    "            \n",
    "            # process each video and its comments\n",
    "            for video in tqdm(videos, desc=f\"Processing videos for '{search_term}'\"):\n",
    "                # extract comments from the current video\n",
    "                comments = self.get_video_comments(video[\"id\"], MAX_COMMENTS_PER_VIDEO)\n",
    "                total_comments += len(comments)\n",
    "                \n",
    "                # combine video metadata with comments\n",
    "                all_texts = [video[\"title\"] + \". \" + video[\"description\"]] + comments\n",
    "                \n",
    "                # analyze each piece of text individually\n",
    "                for text in all_texts:\n",
    "                    clean = self.processor.clean_text(text)\n",
    "                    \n",
    "                    # skip very short texts \n",
    "                    if len(clean) < 10:\n",
    "                        continue\n",
    "                    \n",
    "                    # classify text into poverty dimensions or 'OTHER'\n",
    "                    category, confidence = self.processor.classify_dimension(clean)\n",
    "                    \n",
    "                    # update classification statistics for reporting\n",
    "                    classification_stats[category] += 1\n",
    "                    \n",
    "                    # calculate sentiment score for all classified texts\n",
    "                    sentiment = self.processor.get_sentiment_score(clean)\n",
    "                    dimension_stats[category][\"sentiment_sum\"] += sentiment\n",
    "                    dimension_stats[category][\"count\"] += 1\n",
    "        \n",
    "        # print classification statistics for this state\n",
    "        total_texts = sum(classification_stats.values())\n",
    "        print(f\"  Classification statistics for {state_name}:\")\n",
    "        for category, count in classification_stats.items():\n",
    "            percentage = (count / total_texts * 100) if total_texts > 0 else 0\n",
    "            print(f\"    {category}: {count} texts ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"  Analyzed {total_videos} videos and {total_comments} comments for {state_name}\")\n",
    "        return dimension_stats, total_videos, total_comments, classification_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2dc361",
   "metadata": {},
   "source": [
    "## Output Files\n",
    "\n",
    "Results are saved as CSV files in `yt_data_2022/` directory:\n",
    "- One file per state: `{state_name}.csv`\n",
    "- Aggregated statistics across all dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da711bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noemilucchi/miniforge3/envs/new/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Sinaloa...\n",
      "  Searching for 'Sinaloa noticias'...\n",
      "Found 100 videos for query 'Sinaloa noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sinaloa noticias': 100%|██████████| 100/100 [03:18<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Sinaloa news'...\n",
      "Found 100 videos for query 'Sinaloa news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sinaloa news': 100%|██████████| 100/100 [05:45<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Sinaloa economía'...\n",
      "Found 100 videos for query 'Sinaloa economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sinaloa economía': 100%|██████████| 100/100 [01:58<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Sinaloa:\n",
      "    INCOME: 4119 texts (38.9%)\n",
      "    ACCESS TO HEALTH SERVICES: 668 texts (6.3%)\n",
      "    EDUCATIONAL LAG: 1798 texts (17.0%)\n",
      "    ACCESS TO SOCIAL SECURITY: 285 texts (2.7%)\n",
      "    HOUSING: 562 texts (5.3%)\n",
      "    ACCESS TO FOOD: 647 texts (6.1%)\n",
      "    SOCIAL COHESION: 979 texts (9.2%)\n",
      "    OTHER: 1528 texts (14.4%)\n",
      "  Analyzed 300 videos and 11108 comments for Sinaloa\n",
      "Saved results to yt_data_2022/sinaloa.csv\n",
      "\n",
      "Analyzing Sonora...\n",
      "  Searching for 'Sonora noticias'...\n",
      "Found 100 videos for query 'Sonora noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sonora noticias': 100%|██████████| 100/100 [02:32<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Sonora news'...\n",
      "Found 100 videos for query 'Sonora news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sonora news': 100%|██████████| 100/100 [04:41<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Sonora economía'...\n",
      "Found 100 videos for query 'Sonora economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Sonora economía': 100%|██████████| 100/100 [00:25<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Sonora:\n",
      "    INCOME: 2774 texts (34.7%)\n",
      "    ACCESS TO HEALTH SERVICES: 436 texts (5.5%)\n",
      "    EDUCATIONAL LAG: 1517 texts (19.0%)\n",
      "    ACCESS TO SOCIAL SECURITY: 370 texts (4.6%)\n",
      "    HOUSING: 288 texts (3.6%)\n",
      "    ACCESS TO FOOD: 456 texts (5.7%)\n",
      "    SOCIAL COHESION: 847 texts (10.6%)\n",
      "    OTHER: 1303 texts (16.3%)\n",
      "  Analyzed 300 videos and 8216 comments for Sonora\n",
      "Saved results to yt_data_2022/sonora.csv\n",
      "\n",
      "Analyzing Tabasco...\n",
      "  Searching for 'Tabasco noticias'...\n",
      "Found 100 videos for query 'Tabasco noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tabasco noticias': 100%|██████████| 100/100 [01:48<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tabasco news'...\n",
      "Found 100 videos for query 'Tabasco news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tabasco news': 100%|██████████| 100/100 [04:31<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tabasco economía'...\n",
      "Found 100 videos for query 'Tabasco economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tabasco economía': 100%|██████████| 100/100 [02:11<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Tabasco:\n",
      "    INCOME: 3455 texts (41.4%)\n",
      "    ACCESS TO HEALTH SERVICES: 474 texts (5.7%)\n",
      "    EDUCATIONAL LAG: 1393 texts (16.7%)\n",
      "    ACCESS TO SOCIAL SECURITY: 209 texts (2.5%)\n",
      "    HOUSING: 561 texts (6.7%)\n",
      "    ACCESS TO FOOD: 570 texts (6.8%)\n",
      "    SOCIAL COHESION: 598 texts (7.2%)\n",
      "    OTHER: 1083 texts (13.0%)\n",
      "  Analyzed 300 videos and 8406 comments for Tabasco\n",
      "Saved results to yt_data_2022/tabasco.csv\n",
      "\n",
      "Analyzing Tamaulipas...\n",
      "  Searching for 'Tamaulipas noticias'...\n",
      "Found 100 videos for query 'Tamaulipas noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tamaulipas noticias': 100%|██████████| 100/100 [02:17<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tamaulipas news'...\n",
      "Found 100 videos for query 'Tamaulipas news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tamaulipas news': 100%|██████████| 100/100 [05:57<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tamaulipas economía'...\n",
      "Found 100 videos for query 'Tamaulipas economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tamaulipas economía': 100%|██████████| 100/100 [02:52<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Tamaulipas:\n",
      "    INCOME: 4403 texts (39.5%)\n",
      "    ACCESS TO HEALTH SERVICES: 571 texts (5.1%)\n",
      "    EDUCATIONAL LAG: 1949 texts (17.5%)\n",
      "    ACCESS TO SOCIAL SECURITY: 340 texts (3.0%)\n",
      "    HOUSING: 475 texts (4.3%)\n",
      "    ACCESS TO FOOD: 838 texts (7.5%)\n",
      "    SOCIAL COHESION: 1218 texts (10.9%)\n",
      "    OTHER: 1356 texts (12.2%)\n",
      "  Analyzed 300 videos and 11411 comments for Tamaulipas\n",
      "Saved results to yt_data_2022/tamaulipas.csv\n",
      "\n",
      "Analyzing Tlaxcala...\n",
      "  Searching for 'Tlaxcala noticias'...\n",
      "Found 100 videos for query 'Tlaxcala noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tlaxcala noticias': 100%|██████████| 100/100 [01:17<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tlaxcala news'...\n",
      "Found 100 videos for query 'Tlaxcala news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tlaxcala news': 100%|██████████| 100/100 [02:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Tlaxcala economía'...\n",
      "Found 100 videos for query 'Tlaxcala economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Tlaxcala economía': 100%|██████████| 100/100 [01:53<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Tlaxcala:\n",
      "    INCOME: 1715 texts (34.8%)\n",
      "    ACCESS TO HEALTH SERVICES: 345 texts (7.0%)\n",
      "    EDUCATIONAL LAG: 969 texts (19.7%)\n",
      "    ACCESS TO SOCIAL SECURITY: 113 texts (2.3%)\n",
      "    HOUSING: 148 texts (3.0%)\n",
      "    ACCESS TO FOOD: 360 texts (7.3%)\n",
      "    SOCIAL COHESION: 685 texts (13.9%)\n",
      "    OTHER: 587 texts (11.9%)\n",
      "  Analyzed 300 videos and 4850 comments for Tlaxcala\n",
      "Saved results to yt_data_2022/tlaxcala.csv\n",
      "\n",
      "Analyzing Veracruz...\n",
      "  Searching for 'Veracruz noticias'...\n",
      "Found 100 videos for query 'Veracruz noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Veracruz noticias': 100%|██████████| 100/100 [01:45<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Veracruz news'...\n",
      "Found 100 videos for query 'Veracruz news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Veracruz news': 100%|██████████| 100/100 [03:52<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Veracruz economía'...\n",
      "Found 100 videos for query 'Veracruz economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Veracruz economía': 100%|██████████| 100/100 [05:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Veracruz:\n",
      "    INCOME: 3760 texts (37.7%)\n",
      "    ACCESS TO HEALTH SERVICES: 582 texts (5.8%)\n",
      "    EDUCATIONAL LAG: 1946 texts (19.5%)\n",
      "    ACCESS TO SOCIAL SECURITY: 225 texts (2.3%)\n",
      "    HOUSING: 559 texts (5.6%)\n",
      "    ACCESS TO FOOD: 703 texts (7.1%)\n",
      "    SOCIAL COHESION: 929 texts (9.3%)\n",
      "    OTHER: 1262 texts (12.7%)\n",
      "  Analyzed 300 videos and 10213 comments for Veracruz\n",
      "Saved results to yt_data_2022/veracruz.csv\n",
      "\n",
      "Analyzing Yucatán...\n",
      "  Searching for 'Yucatán noticias'...\n",
      "Found 100 videos for query 'Yucatán noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Yucatán noticias': 100%|██████████| 100/100 [00:58<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Yucatán news'...\n",
      "Found 100 videos for query 'Yucatán news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Yucatán news': 100%|██████████| 100/100 [04:07<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Yucatán economía'...\n",
      "Found 100 videos for query 'Yucatán economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Yucatán economía': 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Yucatán:\n",
      "    INCOME: 1578 texts (30.7%)\n",
      "    ACCESS TO HEALTH SERVICES: 302 texts (5.9%)\n",
      "    EDUCATIONAL LAG: 972 texts (18.9%)\n",
      "    ACCESS TO SOCIAL SECURITY: 126 texts (2.5%)\n",
      "    HOUSING: 737 texts (14.4%)\n",
      "    ACCESS TO FOOD: 321 texts (6.3%)\n",
      "    SOCIAL COHESION: 522 texts (10.2%)\n",
      "    OTHER: 575 texts (11.2%)\n",
      "  Analyzed 300 videos and 5027 comments for Yucatán\n",
      "Saved results to yt_data_2022/yucatán.csv\n",
      "\n",
      "Analyzing Zacatecas...\n",
      "  Searching for 'Zacatecas noticias'...\n",
      "Found 100 videos for query 'Zacatecas noticias'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Zacatecas noticias': 100%|██████████| 100/100 [03:51<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Zacatecas news'...\n",
      "Found 100 videos for query 'Zacatecas news'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Zacatecas news': 100%|██████████| 100/100 [11:16<00:00,  6.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Searching for 'Zacatecas economía'...\n",
      "Found 100 videos for query 'Zacatecas economía'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos for 'Zacatecas economía': 100%|██████████| 100/100 [04:31<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classification statistics for Zacatecas:\n",
      "    INCOME: 6907 texts (38.0%)\n",
      "    ACCESS TO HEALTH SERVICES: 1122 texts (6.2%)\n",
      "    EDUCATIONAL LAG: 2963 texts (16.3%)\n",
      "    ACCESS TO SOCIAL SECURITY: 537 texts (3.0%)\n",
      "    HOUSING: 708 texts (3.9%)\n",
      "    ACCESS TO FOOD: 1211 texts (6.7%)\n",
      "    SOCIAL COHESION: 2445 texts (13.4%)\n",
      "    OTHER: 2293 texts (12.6%)\n",
      "  Analyzed 300 videos and 18448 comments for Zacatecas\n",
      "Saved results to yt_data_2022/zacatecas.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#  main execution function that processes all Mexican states\n",
    "def analyze_all_states_simple():\n",
    "    # initialize the YouTube analyzer with API credentials\n",
    "    analyzer = SimpleYouTubeAnalyzer(YT_API_KEY)\n",
    "    \n",
    "    # define the analysis time period (2022 full year in this case)\n",
    "    date_range = {\n",
    "        \"published_after\": \"2022-01-01T00:00:00Z\",\n",
    "        \"published_before\": \"2022-12-31T23:59:59Z\"\n",
    "    }\n",
    "    \n",
    "    # create output directory for results\n",
    "    os.makedirs(\"yt_data_2022\", exist_ok=True)\n",
    "    \n",
    "    # initialize lists for aggregated results\n",
    "    all_results = []\n",
    "    overall_classification_stats = {}\n",
    "    \n",
    "    # process each Mexican state individually\n",
    "    for state, search_terms in STATES_SEARCH_TERMS.items():\n",
    "        # analyze the current state using its specific search terms\n",
    "        stats, total_videos, total_comments, classification_stats = analyzer.analyze_state_by_keywords(\n",
    "            state_name=state,\n",
    "            search_terms=search_terms,\n",
    "            date_range=date_range\n",
    "        )\n",
    "        \n",
    "        # accumulate classification statistics across all states\n",
    "        for category, count in classification_stats.items():\n",
    "            overall_classification_stats[category] = overall_classification_stats.get(category, 0) + count\n",
    "        \n",
    "        # prepare structured data for this state\n",
    "        df_rows = []\n",
    "        for category, v in stats.items():\n",
    "            df_rows.append({\n",
    "                \"state\": state,\n",
    "                \"dimension\": category.replace(\"_\", \" \").title(),\n",
    "                \"avg_sentiment\": v[\"sentiment_sum\"] / v[\"count\"] if v[\"count\"] > 0 else 0,\n",
    "                \"mentions_count\": v[\"count\"],\n",
    "                \"percentage_of_total\": (v[\"count\"] / sum([s[\"count\"] for s in stats.values()]) * 100) if sum([s[\"count\"] for s in stats.values()]) > 0 else 0,\n",
    "                \"videos_analyzed\": total_videos,\n",
    "                \"comments_analyzed\": total_comments})\n",
    "        \n",
    "        # create DataFrame for this state's results\n",
    "        df = pd.DataFrame(df_rows)\n",
    "        \n",
    "        # save state-specific results to CSV file\n",
    "        output_file = f\"yt_data_2022/{state.replace(' ', '_').lower()}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved results to {output_file}\")\n",
    "        \n",
    "        # add to aggregated results collection\n",
    "        all_results.append(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_all_states_simple()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
