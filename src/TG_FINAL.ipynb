{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Analysis for Multidimensional Poverty Classification in Mexico\n",
    "\n",
    "This notebook implements a text classification system to analyze Telegram posts from Mexican news channels and categorize their content according to the seven dimensions of multidimensional poverty we are considering. The dimensions of poverty we consider are those identified by CONEVAL (Consejo Nacional de Evaluación de la Política de Desarrollo Social), with some minor modifications. \n",
    "\n",
    "Precisely, we consider:\n",
    "   - **Income**: Employment, wages, economic instability\n",
    "   - **Access to Health Services**: Healthcare availability, medical infrastructure\n",
    "   - **Educational Lag**: School dropout, educational access, academic delays\n",
    "   - **Access to Social Security**: Labor protection, social benefits, pension systems\n",
    "   - **Housing**: Living conditions, basic services, housing quality\n",
    "   - **Access to Food**: Food security, nutrition, food prices\n",
    "   - **Social Cohesion**: Discrimination, social exclusion, community tensions\n",
    "\n",
    "## Methodology Implemented\n",
    "\n",
    "The analysis follows these key steps:\n",
    "\n",
    "1. **Data Collection**: Extract posts from 10 major Mexican news channels on Telegram for a given year,\n",
    "2. **Geographic Classification**: Assign posts to Mexican states based on textual mentions of state names,\n",
    "3. **Poverty Dimension Classification**: Use sentence embeddings and cosine similarity to classify posts into the corresponding dimension,\n",
    "4. **Output Generation**: Produce counts and percentages of posts per poverty dimension for each of the 32 Mexican states.\n",
    "\n",
    "## Technical Approach\n",
    "\n",
    "### Text Preprocessing \n",
    "\n",
    "- **HTML/Markup Removal**: Strip HTML tags and web links from Telegram posts\n",
    "- **Character Normalization**: Keep only letters, numbers, and Spanish accented characters\n",
    "- **Whitespace Normalization**: Clean extra spaces and convert to lowercase\n",
    "- **Length Filtering**: Exclude very short texts (< 10 characters)\n",
    "\n",
    "### Embeddings and Classification\n",
    "\n",
    "We used the pre-trained model `hiiamsid/sentence_similarity_spanish_es`, which is a sentence transformer suited for Spanish language. This model converts each text (both posts and poverty dimension definitions) into a 768-dimensional numerical vector that captures the semantic meaning of the text, so similar concepts have similar vector representations. \n",
    "\n",
    "So we create embeddings for each of the 7 poverty dimension definition and for each Telegram post, and we compute cosine similarity between the post embedding and each dimension embedding. After, each post is assigned to the dimension with highest similarity score, but only if the score exceeds 0.10 threshold. If a post does not meet this requirement, it falls into the 'other' category, meaning that the post is not talking about any of the poverty dimension. \n",
    "\n",
    "We believe this approach is adapt to our classification task since considers the full context of the text, not just individual words (like as simple word matching would do). Also, having the 0.10 threshold ensures we only classify posts that are actually related to poverty topics, avoiding missclassifications due to pure noise. \n",
    "\n",
    "### Geographic Classification\n",
    "\n",
    "We use regex to find exact state name mentions in post text, and so to assign posts to their state. Posts mentioning multiple states are counted for each mentioned state.\n",
    "\n",
    "### Extracted Components \n",
    "\n",
    "The final output provides quantitative measures of how frequently each poverty dimension is discussed in relation to each Mexican state, serving as a real-time indicator for multidimensional poverty analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from mongo_wrapper.mongo_wrapper import MongoWrapper\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define states to categorize\n",
    "STATES = [\n",
    "    \"Aguascalientes\", \"Baja California\", \"Baja California Sur\", \"Campeche\", \"Chiapas\", \"Chihuahua\",\n",
    "    \"Ciudad de México\", \"Coahuila\", \"Colima\", \"Durango\", \"Estado de México\", \"Guanajuato\", \n",
    "    \"Guerrero\", \"Hidalgo\", \"Jalisco\", \"Michoacán\", \"Morelos\", \"Nayarit\", \"Nuevo León\", \"Oaxaca\", \n",
    "    \"Puebla\", \"Querétaro\", \"Quintana Roo\", \"San Luis Potosí\", \"Sinaloa\", \"Sonora\", \"Tabasco\", \n",
    "    \"Tamaulipas\", \"Tlaxcala\", \"Veracruz\", \"Yucatán\", \"Zacatecas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels to analyze - these are the channels that have been previosly scraped and stored in Mongo database \n",
    "# the collecctions name is the channel name and the year of the scrape\n",
    "TARGET_CHANNELS = [\n",
    "    \"elpaismexico_2020\",\n",
    "    \"ElUniversalOnline_2020\",\n",
    "    \"proceso_unofficial_2020\",\n",
    "    \"politicomx_2020\",\n",
    "    \"lajornada_unofficial_2020\",\n",
    "    \"larazondemexico_2020\",\n",
    "    \"sinembargomx_2020\",\n",
    "    \"elpaisamerica_2020\",\n",
    "    \"animalpolitico_2020\",\n",
    "    \"ElEconomista_MTY_2020\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by definying the seven poverty dimensions using carefully selected Spanish keywords and phrases that capture the linguistic patterns associated with discussions about each particular aspect of poverty. These serve as semantic anchors for the classification algorithm.\n",
    "Given the nature of the data we are analyzing, we maintained formal journalistic jargon, including only standard words and phrases in Spanish rather than colloquial expressions.\n",
    "\n",
    "We extensively worked on building these lists, as initially some dimensions were overrepresented while others were underrepresented. We found that in some cases (for example, the housing dimension) it was optimal to include fewer words, as otherwise an unrealistic percentage of posts would fall into this dimension.\n",
    "\n",
    "Through different analyses, we discovered that dimensions need to be handled differently, in the sense that some are easier to capture linguistically while others prove more challenging. Regardless of the specific analysis conducted, a crucial component is properly defining these word lists, since they largely determine the quality of the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dimensions of poverty \n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"\"\"\n",
    "    desempleo salario mínimo bajos ingresos deudas familiares pobreza laboral\n",
    "    pérdida de empleo ingreso insuficiente precariedad laboral empleo informal\n",
    "    falta de oportunidades laborales reducción de salario inestabilidad económica\n",
    "    recesión subempleo despidos masivos contratos temporales informalidad\n",
    "    costos de vida elevados falta de empleo formal insuficiencia salarial\n",
    "    \"\"\",\n",
    "\n",
    "    \"ACCESS TO HEALTH SERVICES\": \"\"\"\n",
    "    falta de acceso a servicios de salud hospitales saturados escasez de medicamentos \n",
    "    deficiencias en la atención médica carencia de personal médico emergencia sanitaria\n",
    "    costos elevados de tratamientos cierre de centros de salud lista de espera prolongada\n",
    "    equipos médicos inoperantes desabasto de vacunas falta de atención especializada\n",
    "    \"\"\",\n",
    "\n",
    "    \"EDUCATIONAL_LAG\": \"\"\"\n",
    "    deserción escolar suspensión de clases carencia de docentes  \n",
    "    dificultades de acceso a la educación educación interrumpida rezago académico \n",
    "    falta de recursos escolares acceso desigual a la educación deficiencias en formación \n",
    "    básica carencia de materiales educativos \n",
    "    \"\"\",\n",
    "\n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"\"\"\n",
    "    empleo informal ausencia de prestaciones sociales falta de contrato laboral \n",
    "    exclusión del sistema de pensiones carencia de protección social trabajo precario \n",
    "    derechos laborales no garantizados falta de cotización al sistema desprotección estructural\n",
    "    dificultades para acceder al seguro social informalidad laboral empleo sin afiliación\n",
    "    \"\"\",\n",
    "\n",
    "    \"HOUSING\": \"\"\"\n",
    "    vivienda precaria hacinamiento falta de servicios básicos \n",
    "    infraestructura deteriorada zonas marginadas viviendas inseguras\n",
    "    \"\"\",\n",
    "    \n",
    "    \"ACCESS TO FOOD\": \"\"\"\n",
    "    inseguridad alimentaria acceso limitado a alimentos inflación precios\n",
    "    raciones insuficientes pobreza alimentaria aumento de precios comeder comunitario\n",
    "    canasta básica crisis alimentaria comida pobre ayuda alimentaria \n",
    "    insuficiencia nutricional alimentación deficiente encarecimiento de alimentos\n",
    "    inflación en alimentos carencia alimentaria productos básicos banco de alimentos\n",
    "    alimentos inaccesibles gasto alimentario elevado programas alimentarios\n",
    "    \"\"\",\n",
    "\n",
    "    \"SOCIAL_COHESION\": \"\"\"\n",
    "    discriminación étnica marginación social exclusión comunidades vulnerables\n",
    "    conflictos intercomunitarios tensiones sociales barreras sociales \n",
    "    desigualdad aislamiento social\n",
    "    \"\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PovertyDimensionClassifier` class implements the core classification task through three steps:\n",
    "\n",
    "**Initialization:**\n",
    "- Loads a Spanish-optimized sentence transformer model (`hiiamsid/sentence_similarity_spanish_es`)\n",
    "- Precomputes embeddings for all seven poverty dimension definitions\n",
    "- Represents each poverty concept in a 768-dimensional vector space\n",
    "\n",
    "**Text Preprocessing:**\n",
    "- Removes HTML tags, URLs, and special characters\n",
    "- Converts to lowercase and normalize whitespaces\n",
    "- Filters out posts shorter than 10 characters \n",
    "\n",
    "**Classification Process:**\n",
    "- Converts cleaned text into a 768-dimensional embedding vector \n",
    "- Computes cosine similarity between the post embedding and each pre-computed dimension embedding\n",
    "- Selects the dimension with highest similarity score\n",
    "- Applies a 0.10 threshold to only classify posts with meaningful semantic overlap, and so to reduce the false positives \n",
    "- Classifies posts below the threshold as unrelated to poverty topics, falling into the 'other' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classifier with Spanish sentence embeddings model and precompute embeddings for all poverty dimensions\n",
    "class PovertyDimensionClassifier:\n",
    "    def __init__(self):\n",
    "        # load Spanish sentence transformer model optimized for semantic similarity\n",
    "        self.model = SentenceTransformer('hiiamsid/sentence_similarity_spanish_es')\n",
    "        \n",
    "        # store dimension names for easy reference\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        \n",
    "        # precompute embeddings for all poverty dimension descriptions\n",
    "        self.dimension_embeddings = self.model.encode(\n",
    "            list(POVERTY_DIMENSIONS.values()), \n",
    "            convert_to_tensor=True)\n",
    "    \n",
    "    # clean and preprocess text for better embedding quality\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # remove HTML tags that might appear in Telegram posts\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        \n",
    "        # remove URLs and links\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        \n",
    "        # keep only alphanumeric characters and Spanish accented letters\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        \n",
    "        # normalize whitespace and convert to lowercase\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    \n",
    "    # classify text into poverty dimensions using semantic similarity\n",
    "    def classify_text(self, text, threshold=0.10):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        \n",
    "        # clean the input text\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        \n",
    "        # skip very short texts as they might lack semantic content\n",
    "        if len(cleaned_text) < 10:\n",
    "            return None, 0.0\n",
    "        \n",
    "        # generate embedding for the input text\n",
    "        text_embedding = self.model.encode(cleaned_text, convert_to_tensor=True)\n",
    "        \n",
    "        # compute cosine similarity between text and all poverty dimensions\n",
    "        cosine_scores = util.cos_sim(text_embedding, self.dimension_embeddings)[0]\n",
    "        \n",
    "        # find the dimension with highest similarity score\n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        max_score = cosine_scores[max_idx].item()\n",
    "        \n",
    "        # classify into one of the dimension only if similarity exceeds threshold\n",
    "        if max_score >= threshold:\n",
    "            return self.dimension_names[max_idx], max_score\n",
    "        else:\n",
    "            return None, max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function handles the data extraction and geographic classification pipeline:\n",
    "\n",
    "- **Database Connection:** Connects to MongoDB and filter from all available collections only those of interest (i.e., target channels and year)\n",
    "\n",
    "- **Geographic Classification:** Creates regex patterns, with word boundaries (`\\b`) to prevent partial matches, to classify posts depending on the State they talk about. \n",
    "\n",
    "**Pipeline and Output:**\n",
    "- Iterates through each channel\n",
    "- Retrieves all posts from MongoDB collections\n",
    "- Searches each post for state name mentions using regex patterns\n",
    "- Stores posts for each mentioned state\n",
    "- Returns dictionary with state names as keys\n",
    "- Each value is a DataFrame containing posts mentioning that state\n",
    "- Single posts can appear in multiple states if they mention multiple locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Telegram posts from MongoDB and classify them by Mexican states\n",
    "def load_state_posts():\n",
    "    # connect to MongoDB\n",
    "    mongo_client = MongoWrapper(\n",
    "        db=os.getenv(\"MONGO_DB\"),\n",
    "        user=os.getenv(\"MONGO_USERNAME\"),\n",
    "        password=os.getenv(\"MONGO_PASSWORD\"),\n",
    "        ip=os.getenv(\"MONGO_IP\"),\n",
    "        port=os.getenv(\"MONGO_PORT\"))\n",
    "    \n",
    "    # get all available collections and filter for those of interest\n",
    "    all_channels = mongo_client.get_all_collections()\n",
    "    available_target_channels = [\n",
    "        channel for channel in TARGET_CHANNELS \n",
    "        if channel in all_channels]\n",
    "    \n",
    "    # initialize dictionary to store posts categorized by state\n",
    "    state_posts = {state: [] for state in STATES}\n",
    "    \n",
    "    # create regex patterns for each state to identify mentions in posts - match complete state names, not partial matches\n",
    "    state_patterns = {\n",
    "        state: re.compile(r'\\b' + re.escape(state) + r'\\b', re.IGNORECASE) \n",
    "        for state in STATES}\n",
    "    \n",
    "    # process each available target channel\n",
    "    for channel in tqdm(available_target_channels, desc=\"Loading channels\"):\n",
    "        # retrieve all posts from the current channel\n",
    "        posts = mongo_client.get_collection_entries(collection=channel)\n",
    "        print(f\"Channel: {channel} - {len(posts)} posts found\")\n",
    "        # process each post in the channel\n",
    "        for post in tqdm(posts, desc=f\"Analyzing {channel}\", leave=False):\n",
    "            post_text = post.get('text', '')\n",
    "            # check if post mentions any of the Mexican states   \n",
    "            for state, pattern in state_patterns.items():\n",
    "                if pattern.search(post_text):\n",
    "                    # store post if state is mentioned\n",
    "                    state_posts[state].append(post_text)  \n",
    "    \n",
    "    # convert to df \n",
    "    for state in STATES:\n",
    "        if state_posts[state]:\n",
    "            state_posts[state] = pd.DataFrame(state_posts[state], columns=['text'])\n",
    "        else:\n",
    "            state_posts[state] = pd.DataFrame(columns=['text'])\n",
    "    \n",
    "    return state_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function classifies posts into multidimensional poverty categories, across Mexican states. \n",
    "\n",
    "- The process begins by initializing the classifier to processe posts on a state-by-state basis, classifying each one according to its semantic similarity to predefined poverty dimension categories. As said before, posts having a similarity score lower than 0.10 are labeled as \"other\".\n",
    "\n",
    "- As it runs, the function tracks the number of posts classified under each dimension, to calculate both the absolute counts and the percentage distribution of posts across dimensions.\n",
    "\n",
    "- The output is a dataframe, where each row corresponds to a single poverty dimension for a given state. It includes the number of matching posts, their percentage share, and the total number of posts analyzed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze all posts for each state and classify them into poverty dimensions\n",
    "def analyze_poverty_dimensions(state_posts):\n",
    "    # initialize the classifier\n",
    "    classifier = PovertyDimensionClassifier()\n",
    "    \n",
    "    # store results for all states and dimensions\n",
    "    results = []\n",
    "\n",
    "    # process each state individually\n",
    "    for state, df in state_posts.items():\n",
    "        print(f\"\\nAnalyzing {state} ({len(df)} posts)...\")\n",
    "    \n",
    "        # initialize counters for each poverty dimension plus the \"other\" category - fallback for posts not related to \n",
    "        # any dimension or posts that do not exceed the threshold\n",
    "        dimension_counts = {dim: 0 for dim in POVERTY_DIMENSIONS.keys()}\n",
    "        dimension_counts[\"OTHER\"] = 0  \n",
    "    \n",
    "        # classify each post in the current state\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Classifying {state}\"):\n",
    "            text = row['text']\n",
    "        \n",
    "            # get classification result from the classifier\n",
    "            dimension, score = classifier.classify_text(text)\n",
    "        \n",
    "            # increment counter for the identified dimension or \"other\"\n",
    "            if dimension:\n",
    "                dimension_counts[dimension] += 1\n",
    "            else:\n",
    "                dimension_counts[\"OTHER\"] += 1\n",
    "        \n",
    "        # calculate statistics and print statistics\n",
    "        total_posts = len(df)\n",
    "        dimension_percentages = {\n",
    "            dim: (count / total_posts) * 100 \n",
    "            for dim, count in dimension_counts.items()}\n",
    "        print(f\"\\nResults for {state}:\")\n",
    "        print(f\"Total posts: {total_posts}\")\n",
    "        print(\"\\nDistribution of posts across poverty dimensions:\")\n",
    "        \n",
    "        for dim, count in dimension_counts.items():\n",
    "            dim_name = dim if dim != \"OTHER\" else \"Non-poverty posts\"\n",
    "            pct = dimension_percentages[dim]\n",
    "            print(f\"- {dim_name}: {count} posts ({pct:.1f}%)\")\n",
    "        \n",
    "        # store results \n",
    "        for dim in list(POVERTY_DIMENSIONS.keys()) + [\"OTHER\"]:\n",
    "            results.append({\n",
    "                'state': state,\n",
    "                'dimension': dim,\n",
    "                'count': dimension_counts[dim],\n",
    "                'percentage': dimension_percentages[dim],\n",
    "                'total_posts': total_posts})\n",
    "    \n",
    "    # convert to df \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function that implements the whole pipeline\n",
    "def main():\n",
    "    # load and geographically classify posts from MongoDB\n",
    "    state_posts = load_state_posts()\n",
    "    \n",
    "    # analyze posts for poverty dimensions\n",
    "    results = analyze_poverty_dimensions(state_posts)\n",
    "    \n",
    "    # export results to CSV for further analysis\n",
    "    results.to_csv(\"tg_2020.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
