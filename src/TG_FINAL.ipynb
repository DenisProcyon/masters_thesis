{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 09:00:37,383 WARNING Logger Mongo was configured with True console stream\n",
      "2025-05-12 09:00:37,671 INFO Connected to thesis database on 206.81.16.39\n",
      "loading channels:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: elpaismexico - 1750 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  12%|█▎        | 1/8 [00:00<00:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: ElUniversalOnline - 2435 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  25%|██▌       | 2/8 [00:02<00:06,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: proceso_unofficial - 3141 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  38%|███▊      | 3/8 [00:02<00:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: politicomx - 5103 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  50%|█████     | 4/8 [00:02<00:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: lajornada_unofficial - 18673 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  62%|██████▎   | 5/8 [00:03<00:02,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: larazondemexico - 4248 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  75%|███████▌  | 6/8 [00:04<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: sinembargomx - 9525 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels:  88%|████████▊ | 7/8 [00:05<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: elpaisamerica - 1411 post found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading channels: 100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "/Users/noemilucchi/miniforge3/envs/new/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "analyzing Guanajuato (219 posts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Guanajuato: 100%|██████████| 219/219 [00:21<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results for Guanajuato:\n",
      "total posts: 219\n",
      "\n",
      "distribution of posts across dimensions of poverty:\n",
      "- INCOME: 91 post (41.6%)\n",
      "- ACCESS TO HEALTH SERVICES: 3 post (1.4%)\n",
      "- EDUCATIONAL_LAG: 7 post (3.2%)\n",
      "- ACCESS TO SOCIAL SECURITY: 60 post (27.4%)\n",
      "- HOUSING: 50 post (22.8%)\n",
      "- ACCESS TO FOOD: 1 post (0.5%)\n",
      "- SOCIAL_COHESION: 1 post (0.5%)\n",
      "- non-poverty posts: 6 post (2.7%)\n",
      "\n",
      "analyzing Michoacán (317 posts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Michoacán: 100%|██████████| 317/317 [00:33<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results for Michoacán:\n",
      "total posts: 317\n",
      "\n",
      "distribution of posts across dimensions of poverty:\n",
      "- INCOME: 72 post (22.7%)\n",
      "- ACCESS TO HEALTH SERVICES: 23 post (7.3%)\n",
      "- EDUCATIONAL_LAG: 15 post (4.7%)\n",
      "- ACCESS TO SOCIAL SECURITY: 130 post (41.0%)\n",
      "- HOUSING: 59 post (18.6%)\n",
      "- ACCESS TO FOOD: 3 post (0.9%)\n",
      "- SOCIAL_COHESION: 6 post (1.9%)\n",
      "- non-poverty posts: 9 post (2.8%)\n",
      "\n",
      "analyzing Sinaloa (265 posts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Sinaloa: 100%|██████████| 265/265 [00:40<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results for Sinaloa:\n",
      "total posts: 265\n",
      "\n",
      "distribution of posts across dimensions of poverty:\n",
      "- INCOME: 95 post (35.8%)\n",
      "- ACCESS TO HEALTH SERVICES: 9 post (3.4%)\n",
      "- EDUCATIONAL_LAG: 11 post (4.2%)\n",
      "- ACCESS TO SOCIAL SECURITY: 134 post (50.6%)\n",
      "- HOUSING: 8 post (3.0%)\n",
      "- ACCESS TO FOOD: 3 post (1.1%)\n",
      "- SOCIAL_COHESION: 2 post (0.8%)\n",
      "- non-poverty posts: 3 post (1.1%)\n",
      "\n",
      "analyzing Chihuahua (230 posts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Chihuahua: 100%|██████████| 230/230 [00:29<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results for Chihuahua:\n",
      "total posts: 230\n",
      "\n",
      "distribution of posts across dimensions of poverty:\n",
      "- INCOME: 48 post (20.9%)\n",
      "- ACCESS TO HEALTH SERVICES: 3 post (1.3%)\n",
      "- EDUCATIONAL_LAG: 35 post (15.2%)\n",
      "- ACCESS TO SOCIAL SECURITY: 98 post (42.6%)\n",
      "- HOUSING: 27 post (11.7%)\n",
      "- ACCESS TO FOOD: 5 post (2.2%)\n",
      "- SOCIAL_COHESION: 4 post (1.7%)\n",
      "- non-poverty posts: 10 post (4.3%)\n",
      "\n",
      "analyzing Guerrero (343 posts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Guerrero:  13%|█▎        | 44/343 [00:12<01:24,  3.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 258\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pivot_percentages\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 258\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 245\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    243\u001b[0m     state_posts \u001b[38;5;241m=\u001b[39m load_state_posts()\n\u001b[0;32m--> 245\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_poverty_dimensions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_posts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtg_results_reduced.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    249\u001b[0m     pivot_counts \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mpivot(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 212\u001b[0m, in \u001b[0;36manalyze_poverty_dimensions\u001b[0;34m(state_posts)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifying \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    210\u001b[0m     text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 212\u001b[0m     dimension, score \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dimension:\n\u001b[1;32m    215\u001b[0m         dimension_counts[dimension] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[1], line 138\u001b[0m, in \u001b[0;36mPovertyDimensionClassifier.classify_text\u001b[0;34m(self, text, threshold)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cleaned_text) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:  \u001b[38;5;66;03m# avoid too short texts\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 138\u001b[0m text_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# compute cosine similarity\u001b[39;00m\n\u001b[1;32m    141\u001b[0m cosine_scores \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mcos_sim(text_embedding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimension_embeddings)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:357\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    354\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 357\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    360\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1026\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1014\u001b[0m     embedding_output,\n\u001b[1;32m   1015\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1024\u001b[0m )\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpooler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (sequence_output, pooled_output) \u001b[38;5;241m+\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:659\u001b[0m, in \u001b[0;36mBertPooler.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# We \"pool\" the model by simply taking the hidden state corresponding\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;66;03m# to the first token.\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     first_token_tensor \u001b[38;5;241m=\u001b[39m hidden_states[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 659\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_token_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(pooled_output)\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pooled_output\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/new/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from mongo_wrapper.mongo_wrapper import MongoWrapper\n",
    "\n",
    "# states to categorize\n",
    "STATES = [\n",
    "    \"Guanajuato\",\n",
    "    \"Michoacán\",\n",
    "    \"Sinaloa\",\n",
    "    \"Chihuahua\",\n",
    "    \"Guerrero\",\n",
    "    \"Tamaulipas\",\n",
    "    \"Baja California\",\n",
    "    \"Zacatecas\",\n",
    "    \"Colima\",\n",
    "    \"Jalisco\",\n",
    "    \"Aguascalientes\",\n",
    "    \"Baja California Sur\",\n",
    "    \"Campeche\",\n",
    "    \"Coahuila\",\n",
    "    \"Durango\",\n",
    "    \"Hidalgo\",\n",
    "    \"Estado de México\",\n",
    "    \"Ciudad de México\",\n",
    "    \"Morelos\",\n",
    "    \"Nayarit\",\n",
    "    \"Nuevo León\",\n",
    "    \"Oaxaca\",\n",
    "    \"Puebla\",\n",
    "    \"Querétaro\",\n",
    "    \"Quintana Roo\",\n",
    "    \"San Luis Potosí\",\n",
    "    \"Sonora\",\n",
    "    \"Tabasco\",\n",
    "    \"Tlaxcala\",\n",
    "    \"Veracruz\",\n",
    "    \"Yucatán\",\n",
    "    \"Chiapas\"]\n",
    "\n",
    "\n",
    "# channels to analyze \n",
    "TARGET_CHANNELS = [\n",
    "    \"elpaismexico\",\n",
    "    \"ElUniversalOnline\",\n",
    "    \"proceso_unofficial\",\n",
    "    \"politicomx\",\n",
    "    \"lajornada_unofficial\",\n",
    "    \"larazondemexico\",\n",
    "    \"sinembargomx\",\n",
    "    \"elpaisamerica\"]\n",
    "\n",
    "# define dimensions of poverty \n",
    "POVERTY_DIMENSIONS = {\n",
    "    \"INCOME\": \"\"\"\n",
    "    desempleo, sueldo mínimo, salario bajo, deudas, pobreza, falta de chamba, \n",
    "    pérdida de empleo, no hay trabajo, sin chamba, salario miserable, quedarse sin trabajo, \n",
    "    sin dinero, poco dinero, ingreso insuficiente, no alcanza, trabajo mal pagado, subempleo, \n",
    "    bajos ingresos, sustento familiar, ganar poco, sin ahorros, trabajo informal, \n",
    "    trabajo precario, dificultad para pagar \n",
    "    \"\"\",\n",
    "\n",
    "    \"ACCESS TO HEALTH SERVICES\": \"\"\"\n",
    "    sin medicinas, hospital lejano, sin seguro, mala atención, enfermedad crónica, \n",
    "    rechazado, sin tratamiento, medicinas caras, sin doctores, seguro médico, \n",
    "    sistema de salud deficiente, falta de médicos, hospitales saturados, \n",
    "    emergencias médicas, clínicas rurales, falta de especialistas, citas médicas, \n",
    "    tratamientos costosos, sin acceso a medicamentos, sin posibilidad de tratamiento, \n",
    "    colapso hospitalario, saturación médica, falta de camas, desabastecimiento de medicinas,\n",
    "    atención médica, falta de atención, salud pública, servicio médico malo, \n",
    "    no hay doctores, no hay medicina, atención deficiente, centro de salud cerrado, \n",
    "    consultorio cerrado, urgencias sin cupo, hospital sin personal, médicos ausentes, \n",
    "    morir esperando, negligencia médica, hospital sin insumos, no hay ambulancias\n",
    "    \"\"\",\n",
    "\n",
    "    \"EDUCATIONAL_LAG\": \"\"\"\n",
    "    sin escuela, analfabetismo, deserción, escuela lejana, sin útiles, ausentismo, \n",
    "    sin maestros, rezago escolar, bachillerato incompleto, primaria incompleta, \n",
    "    baja escolaridad, educación deficiente, escuelas sin recursos, sin materiales escolares, \n",
    "    fracaso escolar, repetir curso, escuelas rurales, transporte escolar, sin computadoras, \n",
    "    sin internet, brecha digital, sin educación, alfabetización, estudiantes vulnerables,\n",
    "    no puede estudiar, abandono escolar, escuela cerrada, maestros faltantes, \n",
    "    escuela sin luz, escuela sin agua, escuela insegura, clases suspendidas, \n",
    "    educación interrumpida, niños sin clases, jóvenes sin estudio, no hay educación, \n",
    "    falta de acceso a la educación, no terminé la escuela, no pude estudiar\n",
    "    \"\"\",\n",
    "\n",
    "    \"ACCESS TO SOCIAL SECURITY\": \"\"\"\n",
    "    sin contrato, economía informal, sin pensión, sin derechos, sin ahorro, \n",
    "    sin prestaciones, desprotección, trabajo ilegal, sin seguro, IMSS, \n",
    "    informal job, desprotección social, trabajo sin contrato, empleo informal, \n",
    "    sin cotizar, sin jubilación, sistema de pensiones, derechos laborales, \n",
    "    protección laboral, trabajo en negro, trabajo sin seguridad social, \n",
    "    precariedad laboral, aportes sociales, trabajadores vulnerables\n",
    "    \"\"\",\n",
    "    \n",
    "    \"HOUSING\": \"\"\"\n",
    "    vivienda precaria, sin techo, casa insegura, sin baño, techos de lámina, cuartos de cartón, \n",
    "    viviendas improvisadas, viviendas informales, vivienda inadecuada, vivienda indigna,\n",
    "    barrios marginales, asentamientos irregulares, colonias populares, \n",
    "    terrenos irregulares, viviendas sin servicios básicos, casas abandonadas, \n",
    "    desalojos forzosos, ocupación ilegal, chabolas, tugurios, slum, bad housing\n",
    "    \"\"\",\n",
    "\n",
    "    \"ACCESS TO FOOD\": \"\"\"\n",
    "    hambre, desnutrición, comida escasa, sin alimentos, comida cara, ayuda alimentaria, \n",
    "    dieta pobre, inseguridad alimentaria, canasta básica, acceso a alimentos, nutrición infantil,\n",
    "    desnutrición crónica, malnutrición, hambruna, bancos de alimentos, comedores sociales,\n",
    "    comedores populares, comedores comunitarios, programas alimentarios, despensas,\n",
    "    ayuda alimenticia, costo de alimentos, suministro de alimentos, canasta alimentaria,\n",
    "    seguridad alimentaria, crisis alimentaria, hambre infantil, falta de comida,\n",
    "    no hay comida, no alcanza para comer, solo arroz y frijoles, sin cena, sin desayuno,\n",
    "    comer una vez al día, raciones reducidas, niños con hambre, pasar hambre, \n",
    "    no puedo comprar comida, sobrevivir con poco, falta de leche, comida vencida,\n",
    "    comida donada, filas por comida, buscar comida en la basura, mendigar comida,\n",
    "    pedir comida, trueque por comida, robar por hambre, sin acceso a comida nutritiva\n",
    "    \"\"\",\n",
    "\n",
    "    \"SOCIAL_COHESION\": \"\"\"\n",
    "    exclusión social, discriminación, conflicto, desconfianza, marginalización, \n",
    "    estigmatización, segregación, grupos vulnerables, minorías, sentido de comunidad, \n",
    "    cohesión comunitaria, aislamiento social, marginación, racismo, clasismo, xenofobia, \n",
    "    discriminación étnica, discriminación racial, pueblos indígenas, afrodescendientes, \n",
    "    migrantes, desplazados, refugiados\n",
    "    \"\"\"}\n",
    "\n",
    "\n",
    "class PovertyDimensionClassifier:\n",
    "    def __init__(self):\n",
    "        # sentence embedding\n",
    "        self.model = SentenceTransformer('hiiamsid/sentence_similarity_spanish_es')\n",
    "        \n",
    "        # create embeddings for poverty dimensions\n",
    "        self.dimension_names = list(POVERTY_DIMENSIONS.keys())\n",
    "        self.dimension_embeddings = self.model.encode(list(POVERTY_DIMENSIONS.values()), convert_to_tensor=True)\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', ' ', text)\n",
    "        return re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    \n",
    "    # classify the text into a poverty dimension using sentence embeddings\n",
    "    def classify_text(self, text, threshold=0.10):\n",
    "        if not text:\n",
    "            return None, 0.0\n",
    "        \n",
    "        cleaned_text = self.clean_text(text)\n",
    "        if len(cleaned_text) < 10:  # avoid too short texts\n",
    "            return None, 0.0\n",
    "        \n",
    "        text_embedding = self.model.encode(cleaned_text, convert_to_tensor=True)\n",
    "        \n",
    "        # compute cosine similarity\n",
    "        cosine_scores = util.cos_sim(text_embedding, self.dimension_embeddings)[0]\n",
    "        \n",
    "        # find dimension with highest similarity \n",
    "        max_idx = torch.argmax(cosine_scores).item()\n",
    "        max_score = cosine_scores[max_idx].item()\n",
    "        if max_score >= threshold:\n",
    "            return self.dimension_names[max_idx], max_score\n",
    "        else:\n",
    "            return None, max_score\n",
    "\n",
    "# load only data of interest from MongoDB\n",
    "def load_state_posts():\n",
    "    \n",
    "    MONGO_IP = os.getenv(\"MONGO_IP\")\n",
    "    MONGO_PORT = os.getenv(\"MONGO_PORT\")\n",
    "    MONGO_DB = os.getenv(\"MONGO_DB\")\n",
    "    MONGO_USERNAME = os.getenv(\"MONGO_USERNAME\")\n",
    "    MONGO_PASSWORD = os.getenv(\"MONGO_PASSWORD\")\n",
    "    \n",
    "    mongo_client = MongoWrapper(\n",
    "        db=MONGO_DB,\n",
    "        user=MONGO_USERNAME,\n",
    "        password=MONGO_PASSWORD,\n",
    "        ip=MONGO_IP,\n",
    "        port=MONGO_PORT)\n",
    "    \n",
    "    all_channels = mongo_client.get_all_collections()\n",
    "    available_target_channels = [channel for channel in TARGET_CHANNELS if channel in all_channels]\n",
    "    \n",
    "    # initialize a dictionary to store posts for each state\n",
    "    state_posts = {state: [] for state in STATES}\n",
    "    \n",
    "    # classify posts by using regex patterns - if a post contains a state name, it will be classified as that state\n",
    "    state_patterns = {state: re.compile(r'\\b' + re.escape(state) + r'\\b', re.IGNORECASE) for state in STATES}\n",
    "    \n",
    "    for channel in tqdm(available_target_channels, desc=\"loading channels\"):\n",
    "        posts = mongo_client.get_collection_entries(collection=channel)\n",
    "        \n",
    "        print(f\"channel: {channel} - {len(posts)} post found\")\n",
    "        \n",
    "        for post in tqdm(posts, desc=f\"analysis {channel}\", leave=False):\n",
    "            post_text = post.get('text', '')\n",
    "                \n",
    "            for state, pattern in state_patterns.items():\n",
    "                if pattern.search(post_text):\n",
    "                    state_posts[state].append({\n",
    "                        'text': post_text,\n",
    "                        'author': post.get('author', ''),\n",
    "                        'posting_ts': post.get('posting_ts', ''),\n",
    "                        'channel': channel})\n",
    "    \n",
    "    for state in STATES:\n",
    "        state_posts[state] = pd.DataFrame(state_posts[state])\n",
    "    \n",
    "    return state_posts\n",
    "\n",
    "# classify posts by dimensions of poverty \n",
    "def analyze_poverty_dimensions(state_posts):\n",
    "    classifier = PovertyDimensionClassifier()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for state, df in state_posts.items():\n",
    "        print(f\"\\nanalyzing {state} ({len(df)} posts)...\")\n",
    "    \n",
    "        dimension_counts = {dim: 0 for dim in POVERTY_DIMENSIONS.keys()}\n",
    "        dimension_counts[\"OTHER\"] = 0  # other types of posts \n",
    "    \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Classifying {state}\"):\n",
    "            text = row['text']\n",
    "        \n",
    "            dimension, score = classifier.classify_text(text)\n",
    "        \n",
    "            if dimension:\n",
    "                dimension_counts[dimension] += 1\n",
    "            else:\n",
    "                dimension_counts[\"OTHER\"] += 1\n",
    "        \n",
    "        total_posts = len(df)\n",
    "        dimension_percentages = {dim: (count / total_posts) * 100 for dim, count in dimension_counts.items()}\n",
    "        \n",
    "        print(f\"\\nresults for {state}:\")\n",
    "        print(f\"total posts: {total_posts}\")\n",
    "        print(\"\\ndistribution of posts across dimensions of poverty:\")\n",
    "        \n",
    "        for dim, count in dimension_counts.items():\n",
    "            dim_name = dim if dim != \"OTHER\" else \"non-poverty posts\"\n",
    "            pct = dimension_percentages[dim]\n",
    "            print(f\"- {dim_name}: {count} post ({pct:.1f}%)\")\n",
    "        \n",
    "        for dim in list(POVERTY_DIMENSIONS.keys()) + [\"OTHER\"]:\n",
    "            results.append({\n",
    "                'state': state,\n",
    "                'dimension': dim,\n",
    "                'count': dimension_counts[dim],\n",
    "                'percentage': dimension_percentages[dim],\n",
    "                'total_posts': total_posts})\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def main():\n",
    "    state_posts = load_state_posts()\n",
    "    \n",
    "    results = analyze_poverty_dimensions(state_posts)\n",
    "    \n",
    "    results.to_csv(\"tg_results_reduced.csv\", index=False)\n",
    "    \n",
    "    pivot_counts = results.pivot(index='state', columns='dimension', values='count')\n",
    "    print(\"\\ncount of posts per dimension:\")\n",
    "    print(pivot_counts)\n",
    "    \n",
    "    pivot_percentages = results.pivot(index='state', columns='dimension', values='percentage')\n",
    "    print(\"\\npercentage of posts per dimension:\")\n",
    "    print(pivot_percentages.round(1))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
